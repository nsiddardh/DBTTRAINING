{"nodes": {"model.dbttraining.product": {"raw_sql": "{{\r\n\r\n    config(\r\n        materialized='incremental',\r\n        unique_key='product_id'\r\n    )\r\n}}\r\n\r\nselect * from {{ ref('stg_product') }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "cdc", "product"], "unique_id": "model.dbttraining.product", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "cdc\\product.sql", "original_file_path": "models\\cdc\\product.sql", "name": "product", "resource_type": "model", "alias": "product", "checksum": {"name": "sha256", "checksum": "798d7cfdbb973909ff3641202892131d50d8012990358a45231dff084e0a8ebf"}, "config": {"enabled": true, "materialized": "incremental", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "unique_key": "product_id"}, "tags": [], "refs": [["stg_product"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.stg_product"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.stg_product": {"raw_sql": "select * from {{ source('product_schema', 'product_src') }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "cdc", "stg_product"], "unique_id": "model.dbttraining.stg_product", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "cdc\\stg_product.sql", "original_file_path": "models\\cdc\\stg_product.sql", "name": "stg_product", "resource_type": "model", "alias": "stg_product", "checksum": {"name": "sha256", "checksum": "fd6cbe539f7627f3065a7baad5195887c0c305081378ce492b0e78f68fbece86"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [["product_schema", "product_src"]], "depends_on": {"macros": [], "nodes": ["source.dbttraining.product_schema.product_src"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.CTransformerStage": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\r\n{% set sv_trim_lanenumber = 'TRIM(LANE_NUMBER)' %}\r\n{% set sv_tot_serv_window_dur = '(case when SERVICE_WINDOW_DURATION is null then TOTAL_SPEED_OF_SERVICE_DURATION else SERVICE_WINDOW_DURATION end)' %}\r\n\r\n\r\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"lkp_day_part\"\r\nfilter_conditions: \" DW_STOREID is not null \"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'TRIM(CLOSE_TIME)'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: {{ sv_tot_serv_window_dur }}\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: {{ sv_trim_lanenumber }}\r\n    TBC_LANE: 'TBC_LANE'\r\n    CREATE_ID: '!JOBNAME'\r\n    CREATE_TMSTMP: 'CURRENT_TIMESTAMP'\r\n    UPDT_ID: '!JOBNAME'\r\n    UPDT_TMSTMP: 'CURRENT_TIMESTAMP'\r\n\r\n\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ CTransformerStage_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "CTransformerStage"], "unique_id": "model.dbttraining.CTransformerStage", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\CTransformerStage.sql", "original_file_path": "models\\dsstage_models\\CTransformerStage.sql", "name": "CTransformerStage", "resource_type": "model", "alias": "CTransformerStage", "checksum": {"name": "sha256", "checksum": "11289d26180e67adb133c8e876f33197df38c655017f5f4cdf6aafe38b76dded"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTransformerStage_macro"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.CTransformerStage_multiinput": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\r\n{% set sv_trim_lanenumber = 'TRIM(LANE_NUMBER)' %}\r\n{% set sv_tot_serv_window_dur = '(case when SERVICE_WINDOW_DURATION is null then TOTAL_SPEED_OF_SERVICE_DURATION else SERVICE_WINDOW_DURATION end)' %}\r\n\r\n\r\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"lkp_busi_dt\"\r\nlkp_models: [\"odbc_time_day_dim\",\"odbc_time_day_dim\"]\r\njoin_type: [\"left outer join\",\"left outer join\"]\r\njoin_conidtions: [\" lkp_busi_dt.business_date = odbc_time_day_dim.BUSIDAYDT \",\" lkp_busi_dt.TRANSACTION_DATE = odbc_time_day_dim.BUSIDAYDT \"]\r\nderived_columns:\r\n    DW_BUSI_DAY: \"lkp_busi_dt.DW_BUSI_DAY\"\r\n    DW_TRANS_DAY: \"odbc_time_day_dim.DW_DAY\"\r\n    STORE_ID: \"lkp_busi_dt.STORE_ID\"\r\n    DW_STOREID: \"lkp_busi_dt.DW_STOREID\"\r\n    BUSINESS_DATE: \"lkp_busi_dt.BUSINESS_DATE\"\r\n    OPEN_TIME: \"lkp_busi_dt.OPEN_TIME\"\r\n    CLOSE_TIME: \"lkp_busi_dt.CLOSE_TIME\"\r\n    TRANSACTION_DATE: \"lkp_busi_dt.TRANSACTION_DATE\"\r\n    TRANS_DATE_TXT: \"lkp_busi_dt.TRANS_DATE_TXT\"\r\n    TRANSACTION_TIME: \"lkp_busi_dt.TRANSACTION_TIME\"\r\n    GREET_DELAY: \"lkp_busi_dt.GREET_DELAY\"\r\n    MENU_BOARD_DURATION: \"lkp_busi_dt.MENU_BOARD_DURATION\"\r\n    QUEUE_DURATION: \"lkp_busi_dt.QUEUE_DURATION\"\r\n    CASHIER_WINDOW_DURATION: \"lkp_busi_dt.CASHIER_WINDOW_DURATION\"\r\n    BOOTH_QUEUE_DURATION: \"lkp_busi_dt.BOOTH_QUEUE_DURATION\"\r\n    SERVICE_WINDOW_DURATION: \"lkp_busi_dt.SERVICE_WINDOW_DURATION\"\r\n    TOTAL_BOOTH_DURATION: \"lkp_busi_dt.TOTAL_BOOTH_DURATION\"\r\n    WAITING_AREA_DURATION: \"lkp_busi_dt.WAITING_AREA_DURATION\"\r\n    TRANSACTION_TIME_LKP: \"lkp_busi_dt.TRANSACTION_TIME_LKP\"\r\n    TOTAL_SPEED_OF_SERVICE_DURATION: {{ sv_tot_serv_window_dur }}\r\n    LANE_NUMBER: {{ sv_trim_lanenumber }}\r\n    TBC_LANE: \"lkp_busi_dt.TBC_LANE\"\r\n\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ CTrasaformerStage_multipleinputs_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "CTransformerStage_multiinput"], "unique_id": "model.dbttraining.CTransformerStage_multiinput", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\CTransformerStage_multiinput.sql", "original_file_path": "models\\dsstage_models\\CTransformerStage_multiinput.sql", "name": "CTransformerStage_multiinput", "resource_type": "model", "alias": "CTransformerStage_multiinput", "checksum": {"name": "sha256", "checksum": "1a8398a80ab209eeb342f185b6fdae2869521af16ce9faa614502a9cceb9f0cb"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_busi_dt"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTrasaformerStage_multipleinputs_macro"], "nodes": ["model.dbttraining.lkp_busi_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.DB_input": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"SRC_SEQ_HME_DETAIL\"\r\nsource_columns: \"STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,TRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,CASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,WAITING_AREA_DURATION,TRANSACTION_TIME_LKP,TOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE\"\r\nsource_query_override: \"select * from SRC_SEQ_HME_DETAIL\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ DB_input_macro(metadata_dict)}}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "DB_input"], "unique_id": "model.dbttraining.DB_input", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\DB_input.sql", "original_file_path": "models\\dsstage_models\\DB_input.sql", "name": "DB_input", "resource_type": "model", "alias": "DB_input", "checksum": {"name": "sha256", "checksum": "690c4e13252c19122a4200d2fe7f9d013e13bd925501239efd185de7493594d8"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.DB_input_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxCopy": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"lkp_day_part\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxCopy_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxCopy"], "unique_id": "model.dbttraining.PxCopy", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxCopy.sql", "original_file_path": "models\\dsstage_models\\PxCopy.sql", "name": "PxCopy", "resource_type": "model", "alias": "PxCopy", "checksum": {"name": "sha256", "checksum": "3827f2e8279d724d7db2a101ceea3768b3d1b674391a774b9fee5883a29d8ada"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxCopy_macro"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxDataset": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\n\r\nsource_table: \"SRC_SEQ_HME_DETAIL\"\r\nsource_columns: \"STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,TRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,CASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,WAITING_AREA_DURATION,TRANSACTION_TIME_LKP,TOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE\"\r\n\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxDataset_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxDataset"], "unique_id": "model.dbttraining.PxDataset", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxDataset.sql", "original_file_path": "models\\dsstage_models\\PxDataset.sql", "name": "PxDataset", "resource_type": "model", "alias": "PxDataset", "checksum": {"name": "sha256", "checksum": "d3f3b1007268d44a8a25350427c381e8fb38c383e8d2fb936a6d3045367e5163"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxDataset_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxFilter": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"lkp_day_part\"\r\nfilter_conditions: \" lkp_day_part.DW_STOREID is not null\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxFilter_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxFilter"], "unique_id": "model.dbttraining.PxFilter", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxFilter.sql", "original_file_path": "models\\dsstage_models\\PxFilter.sql", "name": "PxFilter", "resource_type": "model", "alias": "PxFilter", "checksum": {"name": "sha256", "checksum": "0e803b6bff15f01f1807a6025e360b071363f0f618d5a4d7b568c975d7b586d0"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxFilter_macro"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxFunnel": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_models: [\"lkp_day_part\",\"lkp_day_part\"]\r\n\r\nsource_columns_1:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\nsource_columns_2:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_TRANS_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxFunnel_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxFunnel"], "unique_id": "model.dbttraining.PxFunnel", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxFunnel.sql", "original_file_path": "models\\dsstage_models\\PxFunnel.sql", "name": "PxFunnel", "resource_type": "model", "alias": "PxFunnel", "checksum": {"name": "sha256", "checksum": "a1697babf8ff5e3536de21598a922487df75fe9997e1fa780cfdc47d0014965d"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"], ["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxFunnel_macro"], "nodes": ["model.dbttraining.lkp_day_part", "model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.Pxjoin": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"lkp_busi_dt\"\r\nlkp_models: [\"odbc_time_day_dim\"]\r\njoin_type: [\"left outer join\"]\r\njoin_conditions: [\" lkp_busi_dt.TRANSACTION_DATE = odbc_time_day_dim.BUSIDAYDT \"]\r\nderived_columns:\r\n    DW_BUSI_DAY: \"lkp_busi_dt.DW_BUSI_DAY\"\r\n    DW_TRANS_DAY: \"odbc_time_day_dim.DW_DAY\"\r\n    STORE_ID: \"lkp_busi_dt.STORE_ID\"\r\n    DW_STOREID: \"lkp_busi_dt.DW_STOREID\"\r\n    BUSINESS_DATE: \"lkp_busi_dt.BUSINESS_DATE\"\r\n    OPEN_TIME: \"lkp_busi_dt.OPEN_TIME\"\r\n    CLOSE_TIME: \"lkp_busi_dt.CLOSE_TIME\"\r\n    TRANSACTION_DATE: \"lkp_busi_dt.TRANSACTION_DATE\"\r\n    TRANS_DATE_TXT: \"lkp_busi_dt.TRANS_DATE_TXT\"\r\n    TRANSACTION_TIME: \"lkp_busi_dt.TRANSACTION_TIME\"\r\n    GREET_DELAY: \"lkp_busi_dt.GREET_DELAY\"\r\n    MENU_BOARD_DURATION: \"lkp_busi_dt.MENU_BOARD_DURATION\"\r\n    QUEUE_DURATION: \"lkp_busi_dt.QUEUE_DURATION\"\r\n    CASHIER_WINDOW_DURATION: \"lkp_busi_dt.CASHIER_WINDOW_DURATION\"\r\n    BOOTH_QUEUE_DURATION: \"lkp_busi_dt.BOOTH_QUEUE_DURATION\"\r\n    SERVICE_WINDOW_DURATION: \"lkp_busi_dt.SERVICE_WINDOW_DURATION\"\r\n    TOTAL_BOOTH_DURATION: \"lkp_busi_dt.TOTAL_BOOTH_DURATION\"\r\n    WAITING_AREA_DURATION: \"lkp_busi_dt.WAITING_AREA_DURATION\"\r\n    TRANSACTION_TIME_LKP: \"lkp_busi_dt.TRANSACTION_TIME_LKP\"\r\n    TOTAL_SPEED_OF_SERVICE_DURATION: \"lkp_busi_dt.TOTAL_SPEED_OF_SERVICE_DURATION\"\r\n    LANE_NUMBER: \"lkp_busi_dt.LANE_NUMBER\"\r\n    TBC_LANE: \"lkp_busi_dt.TBC_LANE\"\r\n\r\n{% endset %}\r\n\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ Pxjoin_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "Pxjoin"], "unique_id": "model.dbttraining.Pxjoin", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\Pxjoin.sql", "original_file_path": "models\\dsstage_models\\Pxjoin.sql", "name": "Pxjoin", "resource_type": "model", "alias": "Pxjoin", "checksum": {"name": "sha256", "checksum": "6509137ac2f61bf6d7e397191e7002419e3aab91fc924916f9c861777d06b992"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_busi_dt"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.Pxjoin_macro"], "nodes": ["model.dbttraining.lkp_busi_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxLookup": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"\"\r\nlkp_models: [\"lkp_trans_dt\",\"odbc_time_day_part\",\"odbc_time_day_dim\"]\r\nlkp_conditions: [\" lkp_trans_dt.TRANSACTION_TIME_LKP BETWEEN odbc_time_day_part.DAYPART_BGN_TM AND odbc_time_day_part.DAYPART_END_TM\",\"lkp_trans_dt.BUSINESS_DATE=odbc_time_day_dim.busidaydt\"]\r\nderived_columns:\r\n    DW_BUSI_DAY: \"lkp_trans_dt.DW_BUSI_DAY\"\r\n    DW_TRANS_DAY: \"lkp_trans_dt.DW_TRANS_DAY\"\r\n    DW_DAYPART: \"odbc_time_day_part.DW_DAYPART\"\r\n    STORE_ID: \"lkp_trans_dt.STORE_ID\"\r\n    DW_STOREID: \"lkp_trans_dt.DW_STOREID\"\r\n    BUSINESS_DATE: \"lkp_trans_dt.BUSINESS_DATE\"\r\n    OPEN_TIME: \"lkp_trans_dt.OPEN_TIME\"\r\n    CLOSE_TIME: \"lkp_trans_dt.CLOSE_TIME\"\r\n    TRANSACTION_DATE: \"lkp_trans_dt.TRANSACTION_DATE\"\r\n    TRANS_DATE_TXT: \"lkp_trans_dt.TRANS_DATE_TXT\"\r\n    TRANSACTION_TIME: \"lkp_trans_dt.TRANSACTION_TIME\"\r\n    GREET_DELAY: \"lkp_trans_dt.GREET_DELAY\"\r\n    MENU_BOARD_DURATION: \"MENU_BOARD_DURATION\"\r\n    QUEUE_DURATION: \"lkp_trans_dt.QUEUE_DURATION\"\r\n    CASHIER_WINDOW_DURATION: \"lkp_trans_dt.CASHIER_WINDOW_DURATION\"\r\n    BOOTH_QUEUE_DURATION: \"lkp_trans_dt.BOOTH_QUEUE_DURATION\"\r\n    SERVICE_WINDOW_DURATION: \"lkp_trans_dt.SERVICE_WINDOW_DURATION\"\r\n    TOTAL_BOOTH_DURATION: \"lkp_trans_dt.TOTAL_BOOTH_DURATION\"\r\n    WAITING_AREA_DURATION: \"lkp_trans_dt.WAITING_AREA_DURATION\"\r\n    TRANSACTION_TIME_LKP: \"lkp_trans_dt.TRANSACTION_TIME_LKP\"\r\n    TOTAL_SPEED_OF_SERVICE_DURATION: \"lkp_trans_dt.TOTAL_SPEED_OF_SERVICE_DURATION\"\r\n    LANE_NUMBER: \"lkp_trans_dt.LANE_NUMBER\"\r\n    TBC_LANE: \"lkp_trans_dt.TBC_LANE\"\r\n\r\n{% endset %}\r\n\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxLookup_macro_bkp(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxLookup"], "unique_id": "model.dbttraining.PxLookup", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxLookup.sql", "original_file_path": "models\\dsstage_models\\PxLookup.sql", "name": "PxLookup", "resource_type": "model", "alias": "PxLookup", "checksum": {"name": "sha256", "checksum": "55069f8d2d116d9d5141a15558ed242c52836749b3a4d2f18566733255fdfc0a"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_trans_dt"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxLookup_macro_bkp"], "nodes": ["model.dbttraining.lkp_trans_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxLookup_multiple_lkp": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"\"\r\nlkp_models: [\"lkp_busi_dt\",\"odbc_time_day_dim\",\"odbc_time_minute_det\"]\r\nlkp_conditions: [\"lkp_busi_dt.BUSINESS_DATE=odbc_time_day_dim.busidaydt\",\"lkp_busi_dt.OPEN_TIME=odbc_time_minute_det.minutetm\"]\r\npartition_by_field: [\"BUSIDAYDT\",\"minutetm\"]\r\nlkp_field: [\"DW_DAY,DW_FISCALPERIOD\",\"DW_MINUTE,dw_hour\"]\r\nderived_columns:\r\n    DW_MINUTE: \"odbc_time_minute_det.DW_MINUTE\"\r\n    DW_BUSI_DAY: \"odbc_time_day_dim.DW_DAY\"\r\n    STORE_ID: \"lkp_busi_dt.STORE_ID\"\r\n    DW_STOREID: \"lkp_busi_dt.DW_STOREID\"\r\n    BUSINESS_DATE: \"lkp_busi_dt.BUSINESS_DATE\"\r\n    OPEN_TIME: \"lkp_busi_dt.OPEN_TIME\"\r\n    CLOSE_TIME: \"lkp_busi_dt.CLOSE_TIME\"\r\n    TRANSACTION_DATE: \"lkp_busi_dt.TRANSACTION_DATE\"\r\n    TRANS_DATE_TXT: \"lkp_busi_dt.TRANS_DATE_TXT\"\r\n    TRANSACTION_TIME: \"lkp_busi_dt.TRANSACTION_TIME\"\r\n    GREET_DELAY: \"lkp_busi_dt.GREET_DELAY\"\r\n    MENU_BOARD_DURATION: \"lkp_busi_dt.MENU_BOARD_DURATION\"\r\n    QUEUE_DURATION: \"lkp_busi_dt.QUEUE_DURATION\"\r\n    CASHIER_WINDOW_DURATION: \"lkp_busi_dt.CASHIER_WINDOW_DURATION\"\r\n    BOOTH_QUEUE_DURATION: \"lkp_busi_dt.BOOTH_QUEUE_DURATION\"\r\n    SERVICE_WINDOW_DURATION: \"lkp_busi_dt.SERVICE_WINDOW_DURATION\"\r\n    TOTAL_BOOTH_DURATION: \"lkp_busi_dt.TOTAL_BOOTH_DURATION\"\r\n    WAITING_AREA_DURATION: \"lkp_busi_dt.WAITING_AREA_DURATION\"\r\n    TRANSACTION_TIME_LKP: \"lkp_busi_dt.TRANSACTION_TIME_LKP\"\r\n    TOTAL_SPEED_OF_SERVICE_DURATION: \"lkp_busi_dt.TOTAL_SPEED_OF_SERVICE_DURATION\"\r\n    LANE_NUMBER: \"lkp_busi_dt.LANE_NUMBER\"\r\n    TBC_LANE: \"lkp_busi_dt.TBC_LANE\"\r\n\r\n{% endset %}\r\n\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxLookup_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxLookup_multiple_lkp"], "unique_id": "model.dbttraining.PxLookup_multiple_lkp", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxLookup_multiple_lkp.sql", "original_file_path": "models\\dsstage_models\\PxLookup_multiple_lkp.sql", "name": "PxLookup_multiple_lkp", "resource_type": "model", "alias": "PxLookup_multiple_lkp", "checksum": {"name": "sha256", "checksum": "e68cf092c71ea7ab8d3789d4862ba0f37baa244ed1eaa430a4987542435c7fa0"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_busi_dt"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxLookup_macro"], "nodes": ["model.dbttraining.lkp_busi_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxModify": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"lkp_day_part\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'cast(TBC_LANE as varchar(100))'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxCopy_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxModify"], "unique_id": "model.dbttraining.PxModify", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxModify.sql", "original_file_path": "models\\dsstage_models\\PxModify.sql", "name": "PxModify", "resource_type": "model", "alias": "PxModify", "checksum": {"name": "sha256", "checksum": "0cde13df6bc831c650e24a4dae7584c94d3f4d327a7d97b9c1279bf3f335206b"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxCopy_macro"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxPivot": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"monthly_sales\"\r\npivot_type: \"Vertical\"\r\ngroup_column: \"empid\"\r\nagg_column: \"amount\"\r\npivot_column: [\"month\",\"year\"]\r\narray_index: 4\r\n\r\nderived_columns:\r\n    emp_id: 'empid'\r\n    month: 'month'\r\n    Month_1: 'Month_1'\r\n    Month_2: 'Month_2'\r\n    Month_3: 'Month_3'\r\n    year: 'year'\r\n    Year_1: 'Year_1'\r\n    Year_2: 'Year_2'\r\n    Year_3: 'Year_3'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n\r\n{{ PxPivot_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxPivot"], "unique_id": "model.dbttraining.PxPivot", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxPivot.sql", "original_file_path": "models\\dsstage_models\\PxPivot.sql", "name": "PxPivot", "resource_type": "model", "alias": "PxPivot", "checksum": {"name": "sha256", "checksum": "4b08bc9535e6a8a0ae0201e99ec2d2aaf72b7c2399086093c30ec0ef4f29ed32"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["monthly_sales"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxPivot_macro"], "nodes": ["model.dbttraining.monthly_sales"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxPivot_1": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"monthly_sales\"\r\npivot_type: \"Vertical\"\r\ngroup_column: \"empid\"\r\nagg_column: \"amount\"\r\npivot_column: \"month\"\r\narray_index: 3\r\n\r\nderived_columns:\r\n    emp_id: 'empid'\r\n    Month_1: 'Month'\r\n    Month_2: 'Month_1'\r\n    Month_3: 'Month_2'\r\n\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set pivot_columns = metadata_dict['pivot_columns'] %}\r\n{% set agg_column = metadata_dict['agg_column'] %}\r\n{% set pivot_column = metadata_dict['pivot_column'] %}\r\n{% set group_column = metadata_dict['group_column'] %}\r\n{% set array_index = metadata_dict['array_index'] %}\r\n\r\n{%- call statement('my_statement', fetch_result=True) -%}\r\n      SELECT distinct month FROM {{ source_model }}\r\n{%- endcall -%}\r\n\r\n{% set j= array_index+1 %}\r\n\r\nwith pivot_data as (\r\nselect distinct {{group_column}}\r\n{% for _ in range(1, j) %}\r\n    {% if loop.index == 1 %}\r\n    ,nth_value({{ pivot_column }}, {{loop.index}}) over (partition by {{ group_column }} order by (select 1)) as {{pivot_column}}\r\n    {% endif %} \r\n\r\n    {% if loop.index != 1 %}\r\n    {% set i= loop.index - 1 %}\r\n    ,nth_value({{ pivot_column }}, {{loop.index}}) over (partition by {{ group_column }} order by (select 1)) as {{pivot_column~'_'~i}}\r\n    {% endif %} \r\n\r\n{% endfor %}\r\nfrom {{ source_model}}\r\n)\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom pivot_data", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxPivot_1"], "unique_id": "model.dbttraining.PxPivot_1", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxPivot_1.sql", "original_file_path": "models\\dsstage_models\\PxPivot_1.sql", "name": "PxPivot_1", "resource_type": "model", "alias": "PxPivot_1", "checksum": {"name": "sha256", "checksum": "454f66b866d5f155dfb82502141ba2fb07de4b2e66ebaeaf261edce696457baf"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["monthly_sales"]], "sources": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbttraining.create_alias"], "nodes": ["model.dbttraining.monthly_sales"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxRemDup": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"i_tbc_hme_timer_detail\"\r\ndup_method: \"first\"\r\nkey_columns: \"DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME_TXT'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME_TXT'\r\n    TRANS_TIME_TXT: 'TRANS_TIME_TXT'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY_DUR_SEC'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DELAY_DUR_SEC'\r\n    QUEUE_DUR_SEC: 'QUEUE_DUR_SEC'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DUR_SEC'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DUR_SEC'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERV_WINDOW_QUEUE_DUR_SEC'\r\n    TOT_BOOTH_DUR_SEC: 'TOT_BOOTH_DUR_SEC'\r\n    WAIT_AREA_DUR_SEC: 'WAIT_AREA_DUR_SEC'\r\n    TOT_SOS_DUR_SECONDS: \"TOT_SOS_DUR_SECONDS\"\r\n    DRIVE_THRU_LANE_NBR: \"DRIVE_THRU_LANE_NBR\"\r\n    TBC_LANE: \"TBC_LANE\"\r\n    CREATE_ID: \"CREATE_ID\"\r\n    CREATE_TMSTMP: 'CREATE_TMSTMP'\r\n    UPDT_ID: 'UPDT_ID'\r\n    UPDT_TMSTMP: 'UPDT_TMSTMP'\r\n\r\n\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{% set key_columns = metadata_dict['key_columns'] %}\r\n{% set source_model = metadata_dict['source_model'] %}\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set dup_method = metadata_dict['dup_method'] %}\r\n\r\n\r\n\r\nwith source_data as (\r\nSELECT  DISTINCT {{ create_alias(  source_model=source_model, derived_columns=derived_columns) }}\r\n, ROW_NUMBER() OVER (PARTITION BY {{key_columns}} order by {{key_columns}}) AS rn\r\nFROM {{source_model}} as XFM_HME\r\n)\r\n\r\nselect * from source_data WHERE rn = 1", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxRemDup"], "unique_id": "model.dbttraining.PxRemDup", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxRemDup.sql", "original_file_path": "models\\dsstage_models\\PxRemDup.sql", "name": "PxRemDup", "resource_type": "model", "alias": "PxRemDup", "checksum": {"name": "sha256", "checksum": "0a11fb77678a678b230c7e639483095578f1418e5792238fa71705d21b1b47ff"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["i_tbc_hme_timer_detail"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.create_alias"], "nodes": ["model.dbttraining.i_tbc_hme_timer_detail"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxSequentialFile": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"SRC_SEQ_HME_DETAIL\"\r\nsource_columns: \"STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,TRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,CASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,WAITING_AREA_DURATION,TRANSACTION_TIME_LKP,TOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxSequentialFile"], "unique_id": "model.dbttraining.PxSequentialFile", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxSequentialFile.sql", "original_file_path": "models\\dsstage_models\\PxSequentialFile.sql", "name": "PxSequentialFile", "resource_type": "model", "alias": "PxSequentialFile", "checksum": {"name": "sha256", "checksum": "ae5d4c927c38985e7b5570f484abd32e0d79d9b4f757a988db0ab94085924bba"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxSort": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"i_tbc_hme_timer_detail\"\r\nsort_columns: \"DW_STOREID ASC,DW_TRANS_DAY DESC,TRANS_TIME_TXT ASC\"\r\n\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSort_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dsstage_models", "PxSort"], "unique_id": "model.dbttraining.PxSort", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dsstage_models\\PxSort.sql", "original_file_path": "models\\dsstage_models\\PxSort.sql", "name": "PxSort", "resource_type": "model", "alias": "PxSort", "checksum": {"name": "sha256", "checksum": "f006f90e9d95a3efdfe8ac51c875faf03f73b136206857c1ace65a0873acae52"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSort_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.dup_remove_hme_timer_detail": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT  DISTINCT DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT,\r\nFIRST_VALUE(DW_BUSI_DAY) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS DW_BUSI_DAY,\r\nFIRST_VALUE(DW_DAYPART) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS DW_DAYPART,\r\nFIRST_VALUE(OPEN_TIME_TXT) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS OPEN_TIME_TXT,\r\nFIRST_VALUE(CLOSE_TIME_TXT) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS CLOSE_TIME_TXT,\r\nFIRST_VALUE(GREET_DELAY_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS GREET_DELAY_DUR_SEC,\r\nFIRST_VALUE(MENU_BOARD_DELAY_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS MENU_BOARD_DELAY_DUR_SEC,\r\nFIRST_VALUE(QUEUE_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS QUEUE_DUR_SEC,\r\nFIRST_VALUE(CASHIER_WINDOW_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS CASHIER_WINDOW_DUR_SEC,\r\nFIRST_VALUE(BOOTH_QUEUE_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS BOOTH_QUEUE_DUR_SEC,\r\nFIRST_VALUE(SERV_WINDOW_QUEUE_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS SERV_WINDOW_QUEUE_DUR_SEC,\r\nFIRST_VALUE(TOT_BOOTH_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS TOT_BOOTH_DUR_SEC,\r\nFIRST_VALUE(WAIT_AREA_DUR_SEC) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS WAIT_AREA_DUR_SEC,\r\nFIRST_VALUE(TOT_SOS_DUR_SECONDS) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS TOT_SOS_DUR_SECONDS,\r\nFIRST_VALUE(DRIVE_THRU_LANE_NBR) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS DRIVE_THRU_LANE_NBR,\r\nFIRST_VALUE(TBC_LANE) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS TBC_LANE,\r\nFIRST_VALUE(CREATE_ID) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS CREATE_ID,\r\nFIRST_VALUE(CREATE_TMSTMP) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS CREATE_TMSTMP,\r\nFIRST_VALUE(UPDT_ID) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS UPDT_ID,\r\nFIRST_VALUE(UPDT_TMSTMP) OVER( order by DW_STOREID,DW_TRANS_DAY,TRANS_TIME_TXT) AS UPDT_TMSTMP\r\nFROM {{ ref('xfm_hme') }} as XFM_HME", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "dup_remove_hme_timer_detail"], "unique_id": "model.dbttraining.dup_remove_hme_timer_detail", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\dup_remove_hme_timer_detail.sql", "original_file_path": "models\\dstodbt\\dup_remove_hme_timer_detail.sql", "name": "dup_remove_hme_timer_detail", "resource_type": "model", "alias": "dup_remove_hme_timer_detail", "checksum": {"name": "sha256", "checksum": "2ce0cb923e1b5c9c96115507972276a35c345763dcad0cce33044f403670503c"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["xfm_hme"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.xfm_hme"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.i_tbc_hme_timer_detail": {"raw_sql": "{{ config(materialized='table') }}\r\n\r\nSELECT * \r\nFROM {{ ref('dup_remove_hme_timer_detail') }} as  DUP_REMOVE_HME_TIMER_DETAIL", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "i_tbc_hme_timer_detail"], "unique_id": "model.dbttraining.i_tbc_hme_timer_detail", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\i_tbc_hme_timer_detail.sql", "original_file_path": "models\\dstodbt\\i_tbc_hme_timer_detail.sql", "name": "i_tbc_hme_timer_detail", "resource_type": "model", "alias": "i_tbc_hme_timer_detail", "checksum": {"name": "sha256", "checksum": "ceddbb47b72c416d353625a3b4f4c2934fea22daf6a0763e79765384b7158ccc"}, "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["dup_remove_hme_timer_detail"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.dup_remove_hme_timer_detail"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.lkp_busi_dt": {"raw_sql": "{%- set yaml_metadata -%}\r\n--source_model: \"raw_source\"\r\nsrc_column_list:\r\n    is_hashdiff: true\r\n    columns:\r\n        - 'STORE_ID'\r\n        - 'DW_STOREID'\r\n        - 'BUSINESS_DATE'\r\n        - 'OPEN_TIME'\r\n        - 'CLOSE_TIME' \r\n        - 'TRANSACTION_DATE'\r\n        - 'TRANS_DATE_TXT'\r\n        - 'TRANSACTION_TIME' \r\n        - 'GREET_DELAY'\r\n        - 'MENU_BOARD_DURATION'\r\n        - 'QUEUE_DURATION'\r\n        - 'CASHIER_WINDOW_DURATION'\r\n        - 'BOOTH_QUEUE_DURATION'\r\n        - 'SERVICE_WINDOW_DURATION'\r\n        - 'TOTAL_BOOTH_DURATION'\r\n        - 'WAITING_AREA_DURATION'\r\n        - 'TRANSACTION_TIME_LKP'\r\n        - 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n        - 'LANE_NUMBER'\r\n        - 'TBC_LANE'\r\nlkp_column_list:\r\n    is_hashdiff: true\r\n    columns:\r\n        - 'DW_DAY'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{% set join_operator = '=' %}\r\n{% set join_type = 'I' %}\r\n{% set source_tbl_join_field = 'BUSINESS_DATE' %}\r\n{% set lookup_tbl_join_field = 'BUSIDAYDT' %}\r\n\r\n{% set source_columns = metadata_dict['src_column_list'] %}\r\n\r\n\r\n{% set lkp_columns = metadata_dict['lkp_column_list'] %}\r\n\r\n\r\n--{% set ranked_columns = metadata_dict['ranked_columns'] %}\r\n\r\n {{ config(materialized='view') }}\r\n\r\n {{ generate_lkp_query( ref('seq_hme_detail')  , ref('odbc_time_day_dim') , \r\n join_type, \r\n join_operator, \r\n source_tbl_join_field, \r\n lookup_tbl_join_field ,    \r\n source_columns['columns'], \r\n lkp_columns['columns'] ~ ' as DW_BUSI_DAY' )    \r\n }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "lkp_busi_dt"], "unique_id": "model.dbttraining.lkp_busi_dt", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\lkp_busi_dt.sql", "original_file_path": "models\\dstodbt\\lkp_busi_dt.sql", "name": "lkp_busi_dt", "resource_type": "model", "alias": "lkp_busi_dt", "checksum": {"name": "sha256", "checksum": "f3ed243ad7ff1d13a0f172a09e11f18950b139433ac97017ee9fba71e54ef2bc"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["seq_hme_detail"], ["odbc_time_day_dim"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.generate_lkp_query"], "nodes": ["model.dbttraining.seq_hme_detail", "model.dbttraining.odbc_time_day_dim"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.lkp_day_part": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT LKP_TRANS_DT.* , ODBC_TIME_DAY_PART.DW_DAYPART\r\nFROM {{ ref('lkp_trans_dt') }} as LKP_TRANS_DT INNER JOIN {{ ref('odbc_time_day_part') }} as ODBC_TIME_DAY_PART ON TRANSACTION_TIME_LKP BETWEEN DAYPART_BGN_TM AND DAYPART_END_TM", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "lkp_day_part"], "unique_id": "model.dbttraining.lkp_day_part", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\lkp_day_part.sql", "original_file_path": "models\\dstodbt\\lkp_day_part.sql", "name": "lkp_day_part", "resource_type": "model", "alias": "lkp_day_part", "checksum": {"name": "sha256", "checksum": "63b350181e4fc2c9e524242827f8209dbdc50849acf747ebc8a0d7ff42d6b083"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_trans_dt"], ["odbc_time_day_part"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.lkp_trans_dt", "model.dbttraining.odbc_time_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.lkp_trans_dt": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,\r\nTRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,\r\nCASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,\r\nWAITING_AREA_DURATION, TRANSACTION_TIME_LKP,\r\nTOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE,DW_BUSI_DAY,\r\nCP_TIME_DAY_DIM.DW_DAY AS DW_TRANS_DAY\r\nFROM {{ ref('lkp_busi_dt') }} as LKP_BUSI_DT INNER JOIN {{ ref('odbc_time_day_dim') }} as CP_TIME_DAY_DIM ON  LKP_BUSI_DT.TRANSACTION_DATE = CP_TIME_DAY_DIM.BUSIDAYDT", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "lkp_trans_dt"], "unique_id": "model.dbttraining.lkp_trans_dt", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\lkp_trans_dt.sql", "original_file_path": "models\\dstodbt\\lkp_trans_dt.sql", "name": "lkp_trans_dt", "resource_type": "model", "alias": "lkp_trans_dt", "checksum": {"name": "sha256", "checksum": "d9faa878dcae236790879ee3e680f96295dffb0c5614b0ea56a906fc61278650"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_busi_dt"], ["odbc_time_day_dim"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.lkp_busi_dt", "model.dbttraining.odbc_time_day_dim"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.monthly_sales": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT *\r\nFROM monthly_emp_sales", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "monthly_sales"], "unique_id": "model.dbttraining.monthly_sales", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\monthly_sales.sql", "original_file_path": "models\\dstodbt\\monthly_sales.sql", "name": "monthly_sales", "resource_type": "model", "alias": "monthly_sales", "checksum": {"name": "sha256", "checksum": "bba4b232451f9c77f1b1fb2f36c15e8268fa88fd3f3e94e0afb47e26d3131f11"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.odbc_time_day_dim": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT  DISTINCT  DW_DAY, DW_FISCALPERIOD,FIRST_VALUE(BUSIDAYDT) over(partition by DW_DAY, DW_FISCALPERIOD order by DW_DAY, DW_FISCALPERIOD) AS BUSIDAYDT\r\nFROM TIME_DAY_DIM", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "odbc_time_day_dim"], "unique_id": "model.dbttraining.odbc_time_day_dim", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\odbc_time_day_dim.sql", "original_file_path": "models\\dstodbt\\odbc_time_day_dim.sql", "name": "odbc_time_day_dim", "resource_type": "model", "alias": "odbc_time_day_dim", "checksum": {"name": "sha256", "checksum": "fcb3f2996200a178ef845190b2355f5e12fe290f110e393bac3ceadc5e3c6f36"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.odbc_time_day_part": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT DISTINCT DW_DAYPART, FIRST_VALUE(DAYPARTBGNTM) over(partition by DW_DAYPART order by DW_DAYPART) \r\nAS DAYPART_BGN_TM , FIRST_VALUE(DAYPARTENDTM) over(partition by DW_DAYPART order by DW_DAYPART) AS DAYPART_END_TM\r\nFROM TIME_DAYPART_DET\r\nWHERE \r\nDAYPARTNAME <> 'OFF PREM'\r\nAND  DW_DAYPART IN (1,2,3,4,5,6)", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "odbc_time_day_part"], "unique_id": "model.dbttraining.odbc_time_day_part", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\odbc_time_day_part.sql", "original_file_path": "models\\dstodbt\\odbc_time_day_part.sql", "name": "odbc_time_day_part", "resource_type": "model", "alias": "odbc_time_day_part", "checksum": {"name": "sha256", "checksum": "48fe4cf4684630d27e3d4ca043c9bca39c1aa2911b4fbf5231fb0ee5b6d229a2"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.odbc_time_minute_det": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT  dw_minute\r\n       , dw_currentflag\r\n       , dw_daypart\r\n       , dw_hour\r\n       , daypartname\r\n       , daypartbgntm\r\n       , daypartendtm\r\n       , hourno\r\n       , hourbgntm\r\n       , hourendtm\r\n       , minuteno\r\n       , minutetm\r\nFROM time_minute_dim", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "odbc_time_minute_det"], "unique_id": "model.dbttraining.odbc_time_minute_det", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\odbc_time_minute_det.sql", "original_file_path": "models\\dstodbt\\odbc_time_minute_det.sql", "name": "odbc_time_minute_det", "resource_type": "model", "alias": "odbc_time_minute_det", "checksum": {"name": "sha256", "checksum": "71bae110caaed95d665c27f818443b44e61a3896fcd81d27c86c37389e39a9e1"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxFilter_copy": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"lkp_day_part\"\r\nfilter_conditions: \" lkp_day_part.DW_STOREID is not null\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set filter_conditions = metadata_dict['filter_conditions'] %}\r\n\r\nSELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nFROM {{ source_model }}\r\nwhere {{ filter_conditions }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "PxFilter_copy"], "unique_id": "model.dbttraining.PxFilter_copy", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\PxFilter_copy.sql", "original_file_path": "models\\dstodbt\\PxFilter_copy.sql", "name": "PxFilter_copy", "resource_type": "model", "alias": "PxFilter_copy", "checksum": {"name": "sha256", "checksum": "f11018d18cdba96addd07496bc10b2abdf0500f0d663a4c1361247c759752e43"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.create_alias"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.seq_hme_detail": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT  STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,\r\nTRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,\r\nCASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,\r\nWAITING_AREA_DURATION,TRANSACTION_TIME_LKP,TOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE \r\nFROM SRC_SEQ_HME_DETAIL", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "seq_hme_detail"], "unique_id": "model.dbttraining.seq_hme_detail", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\seq_hme_detail.sql", "original_file_path": "models\\dstodbt\\seq_hme_detail.sql", "name": "seq_hme_detail", "resource_type": "model", "alias": "seq_hme_detail", "checksum": {"name": "sha256", "checksum": "15d89d5c1241d549edf42a7b6f1d91789bc2b38d689ef68815f38f44447c0efa"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xfm_busi_dt": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT STORE_ID, DW_STOREID, BUSINESS_DATE, OPEN_TIME, CLOSE_TIME, TRANSACTION_DATE, TRANS_DATE_TXT, TRANSACTION_TIME, GREET_DELAY, \r\nMENU_BOARD_DURATION, QUEUE_DURATION, CASHIER_WINDOW_DURATION, BOOTH_QUEUE_DURATION, SERVICE_WINDOW_DURATION, TOTAL_BOOTH_DURATION, WAITING_AREA_DURATION, \r\nTRANSACTION_TIME_LKP, TOTAL_SPEED_OF_SERVICE_DURATION, LANE_NUMBER, TBC_LANE ,  DW_BUSI_DAY  \r\nfrom {{ ref(\"lkp_busi_dt\")}}\r\nwhere DW_BUSI_DAY is null", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "xfm_busi_dt"], "unique_id": "model.dbttraining.xfm_busi_dt", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\xfm_busi_dt.sql", "original_file_path": "models\\dstodbt\\xfm_busi_dt.sql", "name": "xfm_busi_dt", "resource_type": "model", "alias": "xfm_busi_dt", "checksum": {"name": "sha256", "checksum": "49f078ae6097e3c5f7c0202cdbc28be52755ca89dabd1737df4ebde1f14c5140"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_busi_dt"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.lkp_busi_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xfm_hme": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT  DW_STOREID,DW_BUSI_DAY,DW_TRANS_DAY,DW_DAYPART,OPEN_TIME AS OPEN_TIME_TXT,CLOSE_TIME AS CLOSE_TIME_TXT,TRANSACTION_TIME AS TRANS_TIME_TXT,\r\nGREET_DELAY AS GREET_DELAY_DUR_SEC,MENU_BOARD_DURATION AS MENU_BOARD_DELAY_DUR_SEC,QUEUE_DURATION AS QUEUE_DUR_SEC,\r\nCASHIER_WINDOW_DURATION AS CASHIER_WINDOW_DUR_SEC,BOOTH_QUEUE_DURATION AS BOOTH_QUEUE_DUR_SEC,\r\nSERVICE_WINDOW_DURATION AS SERV_WINDOW_QUEUE_DUR_SEC,TOTAL_BOOTH_DURATION AS TOT_BOOTH_DUR_SEC,\r\nWAITING_AREA_DURATION AS WAIT_AREA_DUR_SEC,TOTAL_SPEED_OF_SERVICE_DURATION AS TOT_SOS_DUR_SECONDS,LANE_NUMBER AS DRIVE_THRU_LANE_NBR,TBC_LANE,\r\n'JOBNAME' AS CREATE_ID,CURRENT_TIMESTAMP AS CREATE_TMSTMP,'JOBNAME' AS UPDT_ID,'CURRENT_TIMESTAMP' AS UPDT_TMSTMP\r\nFROM {{ ref('lkp_day_part') }} as LKP_DAY_PART", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "xfm_hme"], "unique_id": "model.dbttraining.xfm_hme", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\xfm_hme.sql", "original_file_path": "models\\dstodbt\\xfm_hme.sql", "name": "xfm_hme", "resource_type": "model", "alias": "xfm_hme", "checksum": {"name": "sha256", "checksum": "3c08e0e8073cf564477e953b3743b471794b6577e891116dcb660a0cee406b92"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xfm_hme_trans_stage": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"lkp_day_part\"\r\nderived_columns:\r\n    DW_STOREID: 'DW_STOREID'\r\n    DW_BUSI_DAY: 'DW_BUSI_DAY'\r\n    DW_TRANS_DAY: 'DW_TRANS_DAY'\r\n    DW_DAYPART: 'DW_DAYPART'\r\n    OPEN_TIME_TXT: 'OPEN_TIME'\r\n    CLOSE_TIME_TXT: 'CLOSE_TIME'\r\n    TRANS_TIME_TXT: 'TRANSACTION_TIME'\r\n    GREET_DELAY_DUR_SEC: 'GREET_DELAY'\r\n    MENU_BOARD_DELAY_DUR_SEC: 'MENU_BOARD_DURATION'\r\n    QUEUE_DUR_SEC: 'QUEUE_DURATION'\r\n    CASHIER_WINDOW_DUR_SEC: 'CASHIER_WINDOW_DURATION'\r\n    BOOTH_QUEUE_DUR_SEC: 'BOOTH_QUEUE_DURATION'\r\n    SERV_WINDOW_QUEUE_DUR_SEC: 'SERVICE_WINDOW_DURATION'\r\n    TOT_BOOTH_DUR_SEC: 'TOTAL_BOOTH_DURATION'\r\n    WAIT_AREA_DUR_SEC: 'WAITING_AREA_DURATION'\r\n    TOT_SOS_DUR_SECONDS: 'TOTAL_SPEED_OF_SERVICE_DURATION'\r\n    DRIVE_THRU_LANE_NBRLANE_NUMBER: 'LANE_NUMBER'\r\n    TBC_LANE: 'TBC_LANE'\r\n    CREATE_ID: '!JOBNAME'\r\n    CREATE_TMSTMP: 'CURRENT_TIMESTAMP'\r\n    UPDT_ID: '!JOBNAME'\r\n    UPDT_TMSTMP: 'CURRENT_TIMESTAMP'\r\n\r\n\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n--{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\r\n\r\nWITH staging AS (\r\n{{ dbtvault.stage(include_source_columns=false,\r\n                  source_model=source_model,\r\n                  derived_columns=derived_columns,\r\n                  hashed_columns=none,\r\n                  ranked_columns=none) }}\r\n)\r\n\r\nSELECT *\r\nFROM staging", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "xfm_hme_trans_stage"], "unique_id": "model.dbttraining.xfm_hme_trans_stage", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\xfm_hme_trans_stage.sql", "original_file_path": "models\\dstodbt\\xfm_hme_trans_stage.sql", "name": "xfm_hme_trans_stage", "resource_type": "model", "alias": "xfm_hme_trans_stage", "checksum": {"name": "sha256", "checksum": "d4a4dc3e2988f61000c892cc09bfd78e0e660000f90e45efc449244ca44858b0"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_day_part"]], "sources": [], "depends_on": {"macros": ["macro.dbtvault.stage"], "nodes": ["model.dbttraining.lkp_day_part"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xfm_trans_dt": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nSELECT STORE_ID,DW_STOREID,BUSINESS_DATE,OPEN_TIME,CLOSE_TIME,TRANSACTION_DATE,\r\nTRANS_DATE_TXT,TRANSACTION_TIME,GREET_DELAY,MENU_BOARD_DURATION,QUEUE_DURATION,\r\nCASHIER_WINDOW_DURATION,BOOTH_QUEUE_DURATION,SERVICE_WINDOW_DURATION,TOTAL_BOOTH_DURATION,\r\nWAITING_AREA_DURATION, TRANSACTION_TIME_LKP,\r\nTOTAL_SPEED_OF_SERVICE_DURATION,LANE_NUMBER,TBC_LANE,DW_BUSI_DAY,\r\n DW_TRANS_DAY\r\nFROM {{ ref(\"lkp_trans_dt\")}} \r\nwhere DW_TRANS_DAY is null", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "dstodbt", "xfm_trans_dt"], "unique_id": "model.dbttraining.xfm_trans_dt", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "dstodbt\\xfm_trans_dt.sql", "original_file_path": "models\\dstodbt\\xfm_trans_dt.sql", "name": "xfm_trans_dt", "resource_type": "model", "alias": "xfm_trans_dt", "checksum": {"name": "sha256", "checksum": "20755e91c0933c01fabe4da7743b40977d6abac48b0bd7dba5192226b97b817c"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["lkp_trans_dt"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.lkp_trans_dt"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.my_first_dbt_model": {"raw_sql": "/*\r\n    Welcome to your first dbt model!\r\n    Did you know that you can also configure models directly within SQL files?\r\n    This will override configurations stated in dbt_project.yml\r\n\r\n    Try changing \"table\" to \"view\" below\r\n*/\r\n\r\n{{ config(materialized='table') }}\r\n\r\nwith source_data as (\r\n\r\n    select 1 as id\r\n    union all\r\n    select null as id\r\n\r\n)\r\n\r\nselect *\r\nfrom source_data\r\n\r\n/*\r\n    Uncomment the line below to remove records with null `id` values\r\n*/\r\n\r\n-- where id is not null", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "example", "my_first_dbt_model"], "unique_id": "model.dbttraining.my_first_dbt_model", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "example\\my_first_dbt_model.sql", "original_file_path": "models\\example\\my_first_dbt_model.sql", "name": "my_first_dbt_model", "resource_type": "model", "alias": "my_first_dbt_model", "checksum": {"name": "sha256", "checksum": "15579d5a1617e63faeb848841479ac49d3ef3addbd2783845fe7b39b8f07d50c"}, "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "A starter dbt model", "columns": {"id": {"name": "id", "description": "The primary key for this table", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\example\\schema.yml", "build_path": null, "deferred": false}, "model.dbttraining.my_second_dbt_model": {"raw_sql": "-- Use the `ref` function to select from other models\r\n\r\nselect *\r\nfrom {{ ref('my_first_dbt_model') }}\r\nwhere id = 1", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "example", "my_second_dbt_model"], "unique_id": "model.dbttraining.my_second_dbt_model", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "example\\my_second_dbt_model.sql", "original_file_path": "models\\example\\my_second_dbt_model.sql", "name": "my_second_dbt_model", "resource_type": "model", "alias": "my_second_dbt_model", "checksum": {"name": "sha256", "checksum": "5991c318f711e0315ca534919938c772207dd4f6fa36113e3d804e1af14cc099"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["my_first_dbt_model"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.my_first_dbt_model"]}, "description": "A starter dbt model", "columns": {"id": {"name": "id", "description": "The primary key for this table", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\example\\schema.yml", "build_path": null, "deferred": false}, "model.dbttraining.cpout_second_DSLink13": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\nsource_model: \"Funnel_12_DSLink13\"\nderived_columns:\n    SAME_NAME: 'SAME_NAME'\n    NEW_NAME: 'NEW_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ PxCopy_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "cpout_second_DSLink13"], "unique_id": "model.dbttraining.cpout_second_DSLink13", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\cpout_second_DSLink13.sql", "original_file_path": "models\\fromrobert\\cpout_second_DSLink13.sql", "name": "cpout_second_DSLink13", "resource_type": "model", "alias": "cpout_second_DSLink13", "checksum": {"name": "sha256", "checksum": "348698d9d1150fc67a0c2334497ea6800732af353cac4cb559be3b63a2ffd7e8"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["Funnel_12_DSLink13"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxCopy_macro"], "nodes": ["model.dbttraining.Funnel_12_DSLink13"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.Funnel_12_DSLink13": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\n\nsource_models: [\"Funnel_12_ln_out_tx_first\",\"Funnel_12_ln_out_tx_second\"]\n\nsource_columns_1:\n     SAME_NAME: 'Funnel_12_ln_out_tx_first.SAME_NAME'\n     NEW_NAME: 'Funnel_12_ln_out_tx_first.NEW_NAME'\n\nsource_columns_2:\n     NEW_NAME: 'Funnel_12_ln_out_tx_second.NEW_NAME'\n     SAME_NAME: 'Funnel_12_ln_out_tx_second.SAME_NAME'\n\n \n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ PxFunnel_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "Funnel_12_DSLink13"], "unique_id": "model.dbttraining.Funnel_12_DSLink13", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\Funnel_12_DSLink13.sql", "original_file_path": "models\\fromrobert\\Funnel_12_DSLink13.sql", "name": "Funnel_12_DSLink13", "resource_type": "model", "alias": "Funnel_12_DSLink13", "checksum": {"name": "sha256", "checksum": "20878da0318ed52d318f55125b8b1359a48160e4b0214b832679a78b94088687"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["Funnel_12_ln_out_tx_first"], ["Funnel_12_ln_out_tx_second"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxFunnel_macro"], "nodes": ["model.dbttraining.Funnel_12_ln_out_tx_first", "model.dbttraining.Funnel_12_ln_out_tx_second"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.Funnel_12_ln_out_tx_first": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"tx_poc_ln_out_tx_first\"\n\nfilter_conditions: \"\"\nderived_columns:\n    SAME_NAME: 'SAME_NAME'\n    NEW_NAME: 'NEW_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ Has_Input_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "Funnel_12_ln_out_tx_first"], "unique_id": "model.dbttraining.Funnel_12_ln_out_tx_first", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\Funnel_12_ln_out_tx_first.sql", "original_file_path": "models\\fromrobert\\Funnel_12_ln_out_tx_first.sql", "name": "Funnel_12_ln_out_tx_first", "resource_type": "model", "alias": "Funnel_12_ln_out_tx_first", "checksum": {"name": "sha256", "checksum": "3e7ad38488cb09e3f4760841ac205e9a7d3e831d0406c0e28f9e5db812685005"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_out_tx_first"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.Has_Input_macro"], "nodes": ["model.dbttraining.tx_poc_ln_out_tx_first"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.Funnel_12_ln_out_tx_second": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"tx_poc_ln_out_tx_second\"\n\nfilter_conditions: \"\"\nderived_columns:\n    NEW_NAME: 'NEW_NAME'\n    SAME_NAME: 'SAME_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ Has_Input_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "Funnel_12_ln_out_tx_second"], "unique_id": "model.dbttraining.Funnel_12_ln_out_tx_second", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\Funnel_12_ln_out_tx_second.sql", "original_file_path": "models\\fromrobert\\Funnel_12_ln_out_tx_second.sql", "name": "Funnel_12_ln_out_tx_second", "resource_type": "model", "alias": "Funnel_12_ln_out_tx_second", "checksum": {"name": "sha256", "checksum": "921d72ba2999efa1be11c623125ba9e640a7951bd6fb3bf86ae49bac3c5aeffc"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_out_tx_second"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.Has_Input_macro"], "nodes": ["model.dbttraining.tx_poc_ln_out_tx_second"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.genrows_ln_in_tx": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\n\nsource_table: \"genrows\"\nsource_columns: \"SAME_NAME,ORIG_NAME\"\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "genrows_ln_in_tx"], "unique_id": "model.dbttraining.genrows_ln_in_tx", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\genrows_ln_in_tx.sql", "original_file_path": "models\\fromrobert\\genrows_ln_in_tx.sql", "name": "genrows_ln_in_tx", "resource_type": "model", "alias": "genrows_ln_in_tx", "checksum": {"name": "sha256", "checksum": "d5b690be5ec5ba265444d065aa6f4a0e76874f88d65940156f969afd2865372e"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.jn_srcs_Lnk_pvt_seg": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"jn_srcs_Lnk_pvt_seg\"\r\nsource_columns: \"APP_PKG_ID,PARTY_PD_ID\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "jn_srcs_Lnk_pvt_seg"], "unique_id": "model.dbttraining.jn_srcs_Lnk_pvt_seg", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\jn_srcs_Lnk_pvt_seg.sql", "original_file_path": "models\\fromrobert\\jn_srcs_Lnk_pvt_seg.sql", "name": "jn_srcs_Lnk_pvt_seg", "resource_type": "model", "alias": "jn_srcs_Lnk_pvt_seg", "checksum": {"name": "sha256", "checksum": "99d8ea9bc1c0db54d752c093ea027f0c1ff8ad327e916b59b811afeea318a302"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.jn_srcs_lnk_src_addr": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"jn_srcs_lnk_src_addr\"\r\nsource_columns: \"APP_PKG_ID,PARTY_PD_ID,DEP_CUST_RSK_SCR_SVC_FAIL_CD,DEP_UW_MBR_NR_RESC_CD,MBR_RLTN_VAR_FAIL_CD\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "jn_srcs_lnk_src_addr"], "unique_id": "model.dbttraining.jn_srcs_lnk_src_addr", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\jn_srcs_lnk_src_addr.sql", "original_file_path": "models\\fromrobert\\jn_srcs_lnk_src_addr.sql", "name": "jn_srcs_lnk_src_addr", "resource_type": "model", "alias": "jn_srcs_lnk_src_addr", "checksum": {"name": "sha256", "checksum": "4f574aa6c81a3703660f7e3490b63bfbd9e56907d7a10d6b6bc3c18ea7664fa0"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.jn_srcs_Lnk_src_appl": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"jn_srcs_Lnk_src_appl\"\r\nsource_columns: \"APP_PKG_ID,PARTY_PD_ID\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "jn_srcs_Lnk_src_appl"], "unique_id": "model.dbttraining.jn_srcs_Lnk_src_appl", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\jn_srcs_Lnk_src_appl.sql", "original_file_path": "models\\fromrobert\\jn_srcs_Lnk_src_appl.sql", "name": "jn_srcs_Lnk_src_appl", "resource_type": "model", "alias": "jn_srcs_Lnk_src_appl", "checksum": {"name": "sha256", "checksum": "cda2ae4fcfa41e12fb7722bf398b89a2dc26899acd76ab1a822c3cd14a2a89d3"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.jn_srcs_Lnk_src_nas": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_table: \"jn_srcs_Lnk_src_nas\"\r\nsource_columns: \"APP_PKG_ID,PARTY_PD_ID\"\r\n        \r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ PxSequentialFile_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "jn_srcs_Lnk_src_nas"], "unique_id": "model.dbttraining.jn_srcs_Lnk_src_nas", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\jn_srcs_Lnk_src_nas.sql", "original_file_path": "models\\fromrobert\\jn_srcs_Lnk_src_nas.sql", "name": "jn_srcs_Lnk_src_nas", "resource_type": "model", "alias": "jn_srcs_Lnk_src_nas", "checksum": {"name": "sha256", "checksum": "668a0f16bc46d9f5c81b0776b2e81fbfc7592059720535493fbf11a454cea093"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxSequentialFile_macro"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.PxJoin_new": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n{%- set yaml_metadata -%}\r\n\r\nsource_model: \"jn_srcs_lnk_src_addr\"\r\nlkp_models: [\"jn_srcs_lnk_src_addr\", \"jn_srcs_Lnk_src_nas\",\"jn_srcs_Lnk_src_appl\",\"jn_srcs_Lnk_pvt_seg\"]\r\njoin_type: \"left outer join\"\r\njoin_keys: [\"APP_PKG_ID\",\"PARTY_PD_ID\"]\r\nderived_columns:\r\n    APP_PKG_ID: \"jn_srcs_lnk_src_addr.APP_PKG_ID\"\r\n    PARTY_PD_ID: \"jn_srcs_lnk_src_addr.PARTY_PD_ID\"\r\n    DEP_CUST_RSK_SCR_SVC_FAIL_CD: \"jn_srcs_lnk_src_addr.DEP_CUST_RSK_SCR_SVC_FAIL_CD\"\r\n    DEP_UW_MBR_NR_RESC_CD: \"jn_srcs_lnk_src_addr.DEP_UW_MBR_NR_RESC_CD\"\r\n    MBR_RLTN_VAR_FAIL_CD: \"jn_srcs_lnk_src_addr.MBR_RLTN_VAR_FAIL_CD\"\r\n\r\n{% endset %}\r\n\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ Pxjoin_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "PxJoin_new"], "unique_id": "model.dbttraining.PxJoin_new", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\PxJoin_new.sql", "original_file_path": "models\\fromrobert\\PxJoin_new.sql", "name": "PxJoin_new", "resource_type": "model", "alias": "PxJoin_new", "checksum": {"name": "sha256", "checksum": "620feb27e430eb661e3bc983588a115e81eebe88d1dffd55d00863ad14c706f7"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["jn_srcs_lnk_src_addr"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.Pxjoin_macro"], "nodes": ["model.dbttraining.jn_srcs_lnk_src_addr"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.tx_poc_ln_in_tx": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n{% set sv_SAME_NAME = '' %}\n\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"genrows_ln_in_tx\"\n\nfilter_conditions: \"\"\nderived_columns:\n    SAME_NAME: 'SAME_NAME'\n    ORIG_NAME: 'ORIG_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ CTransformerStage_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "tx_poc_ln_in_tx"], "unique_id": "model.dbttraining.tx_poc_ln_in_tx", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\tx_poc_ln_in_tx.sql", "original_file_path": "models\\fromrobert\\tx_poc_ln_in_tx.sql", "name": "tx_poc_ln_in_tx", "resource_type": "model", "alias": "tx_poc_ln_in_tx", "checksum": {"name": "sha256", "checksum": "d1e4fd3a74a2229334ff7b02c656c664e84dcf451d53b9651a32b582186242d7"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["genrows_ln_in_tx"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTransformerStage_macro"], "nodes": ["model.dbttraining.genrows_ln_in_tx"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.tx_poc_ln_out_tx_agg": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n{% set sv_SAME_NAME = 'ln_in_tx.ORIG_NAME' %}\n\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"tx_poc_ln_in_tx\"\n\nfilter_conditions: \"\"\nderived_columns:\n    SAME_NAME: 'tx_poc_ln_in_tx.ORIG_NAME'\n    NEW_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\n    IN_AGG: 'SUM(DOLLARS)'\n\ngroup_by_columns:\n    SAME_NAME: 'tx_poc_ln_in_tx.ORIG_NAME'\n    NEW_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ PxAggregator_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "tx_poc_ln_out_tx_agg"], "unique_id": "model.dbttraining.tx_poc_ln_out_tx_agg", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\tx_poc_ln_out_tx_agg.sql", "original_file_path": "models\\fromrobert\\tx_poc_ln_out_tx_agg.sql", "name": "tx_poc_ln_out_tx_agg", "resource_type": "model", "alias": "tx_poc_ln_out_tx_agg", "checksum": {"name": "sha256", "checksum": "978b71aac6c7acf98bd5ea0442f93617fe1a17dbef918c7f9473dd521f60618a"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_in_tx"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.PxAggregator_macro"], "nodes": ["model.dbttraining.tx_poc_ln_in_tx"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.tx_poc_ln_out_tx_first": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n{% set sv_SAME_NAME = 'ln_in_tx.ORIG_NAME' %}\n\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"tx_poc_ln_in_tx\"\n\nfilter_conditions: \"\"\nderived_columns:\n    SAME_NAME: 'tx_poc_ln_in_tx.ORIG_NAME'\n    NEW_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ CTransformerStage_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "tx_poc_ln_out_tx_first"], "unique_id": "model.dbttraining.tx_poc_ln_out_tx_first", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\tx_poc_ln_out_tx_first.sql", "original_file_path": "models\\fromrobert\\tx_poc_ln_out_tx_first.sql", "name": "tx_poc_ln_out_tx_first", "resource_type": "model", "alias": "tx_poc_ln_out_tx_first", "checksum": {"name": "sha256", "checksum": "a6de550e5e9d23df98f07d1ccf60618bb0cbcdc1411489db78683d17e0645d00"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_in_tx"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTransformerStage_macro"], "nodes": ["model.dbttraining.tx_poc_ln_in_tx"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.tx_poc_ln_out_tx_second": {"raw_sql": "{{ config(materialized='view') }}\n\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\n{% set sv_SAME_NAME = 'ln_in_tx.SAME_NAME' %}\n\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\n{%- set yaml_metadata -%}\n\nsource_model: \"tx_poc_ln_in_tx\"\n\nfilter_conditions: \"\"\nderived_columns:\n    SAME_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\n    NEW_NAME: 'tx_poc_ln_in_tx.ORIG_NAME'\n\n{% endset %}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ CTransformerStage_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "tx_poc_ln_out_tx_second"], "unique_id": "model.dbttraining.tx_poc_ln_out_tx_second", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\tx_poc_ln_out_tx_second.sql", "original_file_path": "models\\fromrobert\\tx_poc_ln_out_tx_second.sql", "name": "tx_poc_ln_out_tx_second", "resource_type": "model", "alias": "tx_poc_ln_out_tx_second", "checksum": {"name": "sha256", "checksum": "71ac3240639fde701af96f4e575e0f44026538630d84bfb08bff7f829be0f529"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_in_tx"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTransformerStage_macro"], "nodes": ["model.dbttraining.tx_poc_ln_in_tx"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xyz": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n\r\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\r\n{% set svStageVar = 'tx_poc_ln_in_tx.ORIG_NAME' %}\r\n\r\n{% set svStageVar2 = svStageVar %}   /*  Replace Here with <component_name>_<link_name> run pre-cypher */\r\n{% set svStageVar1 = 'Trim(tx_poc_ln_in_tx.ORIG_NAME)' %}\r\n{% set svStageVar3 = '\r\nCASE WHEN\r\n    IsNotNull(tx_poc_ln_in_tx.ORIG_NAME) Then tx_poc_ln_in_tx.ORIG_NAME Else  ' + svStageVar1 + '\r\n END' %}\r\n\r\n{% set svStageVar4 = 'Left(' + svStageVar3 + ',25)' %}   /*  Replace Here with <component_name>_<link_name> run pre-cypher */\r\n\r\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"tx_poc_ln_in_tx\"\r\n\r\ncomponent_name: Transformer_10\r\nlinkName: ln_in_tx\r\nlinkReplaceName: tx_poc_ln_in_tx\r\nfilter_conditions: \"\"\r\nderived_columns:\r\n    SAME_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\r\n    ORIG_NAME: '\r\nCASE WHEN\r\n    IsNotNull({{svStageVar4}}) Then {{svStageVar4}} Else tx_poc_ln_in_tx.ORIG_NAME\r\n END'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}\r\n\r\n{{ CTransformerStage_macro(metadata_dict) }}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "xyz"], "unique_id": "model.dbttraining.xyz", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\xyz.sql", "original_file_path": "models\\fromrobert\\xyz.sql", "name": "xyz", "resource_type": "model", "alias": "xyz", "checksum": {"name": "sha256", "checksum": "43756925d05fed3887292fad86d8355113268781b53b95846398548258710494"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["tx_poc_ln_in_tx"]], "sources": [], "depends_on": {"macros": ["macro.dbttraining.CTransformerStage_macro"], "nodes": ["model.dbttraining.tx_poc_ln_in_tx"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "model.dbttraining.xyz1": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\n{%- set yaml_metadata_sv -%}\r\n/* -------STAGE VARIABLES SECTION--------This section repeats for all output links in transformation stage-----*/\r\nsvStageVar: 'tx_poc_ln_in_tx.ORIG_NAME'\r\nsvStageVar2: '{{svStageVar}}'   /*  Replace Here with <component_name>_<link_name> run pre-cypher */\r\nsvStageVar1: 'Trim(tx_poc_ln_in_tx.ORIG_NAME)' \r\nsvStageVar3: '\r\nCASE WHEN\r\n    IsNotNull(tx_poc_ln_in_tx.ORIG_NAME) Then tx_poc_ln_in_tx.ORIG_NAME Else  {{ svStageVar1 }}\r\n END'\r\nsvStageVar4: 'Left({{svStageVar3}},25)'   /*  Replace Here with <component_name>_<link_name> run pre-cypher */\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict_sv = fromyaml(yaml_metadata_sv) %}\r\n{{metadata_dict_sv}}\r\n\r\n\r\n\r\n/* -------EXPRESSIONS AND TARGET COLUMNS ALIASING SECTION--------*/\r\n\r\n{%- set yaml_metadata -%}\r\nsource_model: \"tx_poc_ln_in_tx\"\r\n\r\ncomponent_name: Transformer_10\r\nlinkName: ln_in_tx\r\nlinkReplaceName: tx_poc_ln_in_tx\r\nfilter_conditions: \"\"\r\nderived_columns:\r\n    SAME_NAME: 'tx_poc_ln_in_tx.SAME_NAME'\r\n    ORIG_NAME: '\r\nCASE WHEN\r\n    IsNotNull({{svStageVar4}}) Then {{svStageVar4}} Else tx_poc_ln_in_tx.ORIG_NAME\r\n END'\r\n\r\n{% endset %}\r\n\r\n{% set metadata_dict = fromyaml(yaml_metadata) %}", "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "fromrobert", "xyz1"], "unique_id": "model.dbttraining.xyz1", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "fromrobert\\xyz1.sql", "original_file_path": "models\\fromrobert\\xyz1.sql", "name": "xyz1", "resource_type": "model", "alias": "xyz1", "checksum": {"name": "sha256", "checksum": "528712a4c9526ebb83c8b231474f5c6e9f522c6072c678a9741cbafe92e551ee"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "snapshot.dbttraining.product_snapshot": {"raw_sql": "\r\n{{\r\n    config(\r\n        target_schema = 'snapshot',\r\n        strategy='check',\r\n        unique_key='product_id',\r\n        check_cols='all'\r\n    )\r\n\r\n}}\r\n\r\nselect \r\n*\r\nfrom {{ ref('stg_product') }}\r\n\r\n", "database": "TESTDBT", "schema": "snapshot", "fqn": ["dbttraining", "product_snapshot", "product_snapshot"], "unique_id": "snapshot.dbttraining.product_snapshot", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "product_snapshot.sql", "original_file_path": "snapshots\\product_snapshot.sql", "name": "product_snapshot", "resource_type": "snapshot", "alias": "product_snapshot", "checksum": {"name": "sha256", "checksum": "d6539746b88fc35c000a325cb128cc34a36026936a8c8cc7aecea6e8a5bcd1c7"}, "config": {"enabled": true, "materialized": "snapshot", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "unique_key": "product_id", "target_schema": "snapshot", "target_database": null, "strategy": "check", "check_cols": "all"}, "tags": [], "refs": [["stg_product"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.dbttraining.stg_product"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false}, "test.dbttraining.unique_my_first_dbt_model_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "id", "model": "{{ ref('my_first_dbt_model') }}"}}, "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "schema_test", "unique_my_first_dbt_model_id"], "unique_id": "test.dbttraining.unique_my_first_dbt_model_id", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "schema_test\\unique_my_first_dbt_model_id.sql", "original_file_path": "models\\example\\schema.yml", "name": "unique_my_first_dbt_model_id", "resource_type": "test", "alias": "unique_my_first_dbt_model_id", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["my_first_dbt_model"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.dbttraining.my_first_dbt_model"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "column_name": "id"}, "test.dbttraining.not_null_my_first_dbt_model_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "id", "model": "{{ ref('my_first_dbt_model') }}"}}, "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "schema_test", "not_null_my_first_dbt_model_id"], "unique_id": "test.dbttraining.not_null_my_first_dbt_model_id", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "schema_test\\not_null_my_first_dbt_model_id.sql", "original_file_path": "models\\example\\schema.yml", "name": "not_null_my_first_dbt_model_id", "resource_type": "test", "alias": "not_null_my_first_dbt_model_id", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["my_first_dbt_model"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.dbttraining.my_first_dbt_model"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "column_name": "id"}, "test.dbttraining.unique_my_second_dbt_model_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "id", "model": "{{ ref('my_second_dbt_model') }}"}}, "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "schema_test", "unique_my_second_dbt_model_id"], "unique_id": "test.dbttraining.unique_my_second_dbt_model_id", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "schema_test\\unique_my_second_dbt_model_id.sql", "original_file_path": "models\\example\\schema.yml", "name": "unique_my_second_dbt_model_id", "resource_type": "test", "alias": "unique_my_second_dbt_model_id", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["my_second_dbt_model"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.dbttraining.my_second_dbt_model"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "column_name": "id"}, "test.dbttraining.not_null_my_second_dbt_model_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "id", "model": "{{ ref('my_second_dbt_model') }}"}}, "database": "TESTDBT", "schema": "DBT_SNAMBURI", "fqn": ["dbttraining", "schema_test", "not_null_my_second_dbt_model_id"], "unique_id": "test.dbttraining.not_null_my_second_dbt_model_id", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "schema_test\\not_null_my_second_dbt_model_id.sql", "original_file_path": "models\\example\\schema.yml", "name": "not_null_my_second_dbt_model_id", "resource_type": "test", "alias": "not_null_my_second_dbt_model_id", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["my_second_dbt_model"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.dbttraining.my_second_dbt_model"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "column_name": "id"}}, "sources": {"source.dbttraining.product_schema.product_src": {"fqn": ["dbttraining", "cdc", "product_schema", "product_src"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.product_schema.product_src", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\cdc\\schema.yml", "original_file_path": "models\\cdc\\schema.yml", "name": "product_src", "source_name": "product_schema", "source_description": "Product CDC", "loader": "", "identifier": "product_src", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.show_stopper.time_day_dim": {"fqn": ["dbttraining", "dstodbt", "show_stopper", "time_day_dim"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.show_stopper.time_day_dim", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "time_day_dim", "source_name": "show_stopper", "source_description": "showstopper", "loader": "", "identifier": "time_day_dim", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.show_stopper.TIME_DAYPART_DET": {"fqn": ["dbttraining", "dstodbt", "show_stopper", "TIME_DAYPART_DET"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.show_stopper.TIME_DAYPART_DET", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "TIME_DAYPART_DET", "source_name": "show_stopper", "source_description": "showstopper", "loader": "", "identifier": "TIME_DAYPART_DET", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.show_stopper.SRC_SEQ_HME_DETAIL": {"fqn": ["dbttraining", "dstodbt", "show_stopper", "SRC_SEQ_HME_DETAIL"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.show_stopper.SRC_SEQ_HME_DETAIL", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "SRC_SEQ_HME_DETAIL", "source_name": "show_stopper", "source_description": "showstopper", "loader": "", "identifier": "SRC_SEQ_HME_DETAIL", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.show_stopper.monthly_emp_sales": {"fqn": ["dbttraining", "dstodbt", "show_stopper", "monthly_emp_sales"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.show_stopper.monthly_emp_sales", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "monthly_emp_sales", "source_name": "show_stopper", "source_description": "showstopper", "loader": "", "identifier": "monthly_emp_sales", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.show_stopper.time_minute_dim": {"fqn": ["dbttraining", "dstodbt", "show_stopper", "time_minute_dim"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.show_stopper.time_minute_dim", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "time_minute_dim", "source_name": "show_stopper", "source_description": "showstopper", "loader": "", "identifier": "time_minute_dim", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.LINEITEM": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "LINEITEM"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.LINEITEM", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "LINEITEM", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "LINEITEM", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.CUSTOMER": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "CUSTOMER"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.CUSTOMER", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "CUSTOMER", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "CUSTOMER", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.ORDERS": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "ORDERS"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.ORDERS", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "ORDERS", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "ORDERS", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.PARTSUPP": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "PARTSUPP"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.PARTSUPP", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "PARTSUPP", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "PARTSUPP", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.SUPPLIER": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "SUPPLIER"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.SUPPLIER", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "SUPPLIER", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "SUPPLIER", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.PART": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "PART"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.PART", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "PART", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "PART", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.NATION": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "NATION"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.NATION", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "NATION", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "NATION", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.tpch_sample.REGION": {"fqn": ["dbttraining", "dstodbt", "tpch_sample", "REGION"], "database": "SNOWFLAKE_SAMPLE_DATA", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.tpch_sample.REGION", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\dstodbt\\schema.yml", "original_file_path": "models\\dstodbt\\schema.yml", "name": "REGION", "source_name": "tpch_sample", "source_description": "", "loader": "", "identifier": "REGION", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.time_day_dim": {"fqn": ["dbttraining", "fromrobert", "USAA", "time_day_dim"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.time_day_dim", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "time_day_dim", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "time_day_dim", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.TIME_DAYPART_DET": {"fqn": ["dbttraining", "fromrobert", "USAA", "TIME_DAYPART_DET"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.TIME_DAYPART_DET", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "TIME_DAYPART_DET", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "TIME_DAYPART_DET", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.SRC_SEQ_HME_DETAIL": {"fqn": ["dbttraining", "fromrobert", "USAA", "SRC_SEQ_HME_DETAIL"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.SRC_SEQ_HME_DETAIL", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "SRC_SEQ_HME_DETAIL", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "SRC_SEQ_HME_DETAIL", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.monthly_emp_sales": {"fqn": ["dbttraining", "fromrobert", "USAA", "monthly_emp_sales"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.monthly_emp_sales", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "monthly_emp_sales", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "monthly_emp_sales", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.genrows": {"fqn": ["dbttraining", "fromrobert", "USAA", "genrows"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.genrows", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "genrows", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "genrows", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {"SAME_NAME": {"name": "SAME_NAME", "description": "The primary key for this table", "meta": {}, "data_type": null, "quote": null, "tags": []}, "ORIG_NAME": {"name": "ORIG_NAME", "description": "The primary key for this table", "meta": {}, "data_type": null, "quote": null, "tags": []}}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.jn_srcs_lnk_src_addr": {"fqn": ["dbttraining", "fromrobert", "USAA", "jn_srcs_lnk_src_addr"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.jn_srcs_lnk_src_addr", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "jn_srcs_lnk_src_addr", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "jn_srcs_lnk_src_addr", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.jn_srcs_Lnk_pvt_seg": {"fqn": ["dbttraining", "fromrobert", "USAA", "jn_srcs_Lnk_pvt_seg"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.jn_srcs_Lnk_pvt_seg", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "jn_srcs_Lnk_pvt_seg", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "jn_srcs_Lnk_pvt_seg", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.jn_srcs_Lnk_src_nas": {"fqn": ["dbttraining", "fromrobert", "USAA", "jn_srcs_Lnk_src_nas"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.jn_srcs_Lnk_src_nas", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "jn_srcs_Lnk_src_nas", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "jn_srcs_Lnk_src_nas", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.USAA.jn_srcs_Lnk_src_appl": {"fqn": ["dbttraining", "fromrobert", "USAA", "jn_srcs_Lnk_src_appl"], "database": "TESTDBT", "schema": "DBT_SNAMBURI", "unique_id": "source.dbttraining.USAA.jn_srcs_Lnk_src_appl", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\fromrobert\\schema.yml", "original_file_path": "models\\fromrobert\\schema.yml", "name": "jn_srcs_Lnk_src_appl", "source_name": "USAA", "source_description": "showstopper", "loader": "", "identifier": "jn_srcs_Lnk_src_appl", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}, "source.dbttraining.snowflake_sample_data.store_sales": {"fqn": ["dbttraining", "snowflake_smaple_data", "snowflake_sample_data", "store_sales"], "database": "snowflake_sample_data", "schema": "TPCDS_SF10TCL", "unique_id": "source.dbttraining.snowflake_sample_data.store_sales", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "models\\snowflake_smaple_data\\schema.yml", "original_file_path": "models\\snowflake_smaple_data\\schema.yml", "name": "store_sales", "source_name": "snowflake_sample_data", "source_description": "A sample data provided by snowflake", "loader": "", "identifier": "store_sales", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": null, "error_after": null, "filter": null}, "external": null, "description": "details about the sales in the store", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null}}, "macros": {"macro.dbttraining.create_alias": {"unique_id": "macro.dbttraining.create_alias", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\create_alias.sql", "original_file_path": "macros\\create_alias.sql", "name": "create_alias", "macro_sql": "{%- macro create_alias(source_model=none,  derived_columns=none) -%}\r\n\r\n{% if (source_model is none) and execute %}\r\n\r\n    {%- set error_message -%}\r\n    \"Staging error: Missing source_model configuration. A source model name must be provided.\r\n    e.g. \r\n    [REF STYLE]\r\n    source_model: model_name\r\n    OR\r\n    [SOURCES STYLE]\r\n    source_model:\r\n        source_name: source_table_name\"\r\n    {%- endset -%}\r\n\r\n    {{- exceptions.raise_compiler_error(error_message) -}}\r\n{%- endif -%}\r\n\r\n{#- Check for source format or ref format and create relation object from source_model -#}\r\n{% if source_model is mapping and source_model is not none -%}\r\n\r\n    {%- set source_name = source_model | first -%}\r\n    {%- set source_table_name = source_model[source_name] -%}\r\n\r\n    {%- set source_relation = source(source_name, source_table_name) -%}\r\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\r\n{%- elif source_model is not mapping and source_model is not none -%}\r\n\r\n    {%- set source_relation = ref(source_model) -%}\r\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\r\n{%- else -%}\r\n\r\n    {%- set all_source_columns = [] -%}\r\n{%- endif -%}\r\n\r\n{%- set derived_column_names = dbtvault.extract_column_names(derived_columns) -%}\r\n\r\n{{ dbtvault.derive_columns_only(source_relation=source_relation, columns=derived_columns) | indent(4) }}\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.CTransformerStage_macro": {"unique_id": "macro.dbttraining.CTransformerStage_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\CTransformerStage_macro.sql", "original_file_path": "macros\\CTransformerStage_macro.sql", "name": "CTransformerStage_macro", "macro_sql": "{%- macro CTransformerStage_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\r\n\r\n{% set filter_conditions = metadata_dict['filter_conditions'] %}\r\n\r\nSELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nFROM {{ source_model }}\r\n{% if filter_conditions != \"\" %}\r\n    where {{ filter_conditions }}\r\n    {%- endif -%}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.CTrasaformerStage_multipleinputs_macro": {"unique_id": "macro.dbttraining.CTrasaformerStage_multipleinputs_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\CTransformerStage_multipleinputs_macro.sql", "original_file_path": "macros\\CTransformerStage_multipleinputs_macro.sql", "name": "CTrasaformerStage_multipleinputs_macro", "macro_sql": "{%- macro CTrasaformerStage_multipleinputs_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set lkp_models = metadata_dict['lkp_models'] %}\r\n{% set lkp_conidtions = metadata_dict['lkp_conidtions'] %}\r\n{% set join_type = metadata_dict['join_type'] %}\r\n{% set join_conidtions = metadata_dict['join_conidtions'] %}\r\n\r\n\r\n\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom {{ source_model }} as {{ source_model }}  \r\n\r\n{% for lookup_model in lkp_models %}\r\n {% set i = loop.index %}\r\n{{ join_type[i-1] }}   {{ lkp_models[i-1] }} as {{ lkp_models[i-1] }} on {{ join_conidtions[i-1] }}\r\n{% endfor %}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.DB_input_macro": {"unique_id": "macro.dbttraining.DB_input_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\DB_input_macro.sql", "original_file_path": "macros\\DB_input_macro.sql", "name": "DB_input_macro", "macro_sql": "{%- macro DB_input_macro(metadata_dict=none) -%}\r\n\r\n\r\n{% set source_columns = metadata_dict['source_columns'] %}\r\n{% set source_table = metadata_dict['source_table'] %}\r\n{% set source_query_override = metadata_dict['source_query_override'] %}\r\n\r\n\r\n\r\n    {%- if source_query_override is not none -%}\r\n\r\n       select {{ source_columns }} from {{ source_table }} \r\n\r\n    {%- else -%}\r\n\r\n       {{ source_query_override }}\r\n\r\n    {%- endif -%}\r\n     \r\n      \r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.generate_lkp_query": {"unique_id": "macro.dbttraining.generate_lkp_query", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\ds_lkp.sql", "original_file_path": "macros\\ds_lkp.sql", "name": "generate_lkp_query", "macro_sql": "{% macro generate_lkp_query(src_tbl,lkp_tbl,jointype,joinoperator,srcfield,tgtfield,src_field_names,lkp_field_names) %}\r\n\r\n--{% set jointype=  join_type | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\")  %}\r\n{% set joinoperator=  joinoperator | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\") %}\r\n{% set srcfield=  srcfield | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\") %}\r\n{% set tgtfield=  tgtfield | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\") %}\r\n{% set src_field_names=  src_field_names | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\") %}\r\n{% set lkp_field_names=  lkp_field_names | replace(\"[\", \"\") | replace(\"]\", \"\") | replace(\"'\",\"\") %}\r\n\r\n    {%- if jointype == 'I' -%}\r\n   (SELECT {{src_field_names}} , {{lkp_field_names}} from ({{src_tbl}}) as src_tbl INNER JOIN ({{lkp_tbl}}) as lkp_tbl on {{srcfield}}  {{joinoperator}} {{tgtfield}})\r\n        \r\n\r\n    {%- elif jointype == 'L' -%}\r\n   (SELECT {{src_field_names}} , {{lkp_field_names}}  from ({{src_tbl}}) as src_tbl LEFT OUTER JOIN ({{lkp_tbl}}) as lkp_tbl on {{srcfield}}  {{joinoperator}} {{tgtfield}} )\r\n        \r\n\r\n    {%- elif jointype == 'R' -%}\r\n   (SELECT {{src_field_names}} , {{lkp_field_names}}  from ({{src_tbl}}) as src_tbl RIGHT OUTER JOIN ({{lkp_tbl}}) as lkp_tbl on {{srcfield}}  {{joinoperator}} {{tgtfield}} )\r\n        \r\n\r\n    {%- elif jointype == 'F' -%}\r\n   (SELECT {{src_field_names}} , {{lkp_field_names}}  from ({{src_tbl}}) as src_tbl FULL OUTER JOIN ({{lkp_tbl}}) as lkp_tbl on {{srcfield}}  {{joinoperator}} {{tgtfield}} )\r\n\r\n\r\n    {%- else -%}\r\n    (SELECT {{src_field_names}} , {{lkp_field_names}}  from ({{src_tbl}}) as src_tbl , ({{lkp_tbl}}) as lkp_tbl where {{srcfield}}  {{joinoperator}} {{tgtfield}})\r\n    {%- endif -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.generate_schema_name": {"unique_id": "macro.dbttraining.generate_schema_name", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\generate_schema_name.sql", "original_file_path": "macros\\generate_schema_name.sql", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name, node) -%}\r\n\r\n    {%- set default_schema = target.schema -%}\r\n    {%- if custom_schema_name is none -%}\r\n\r\n        {{ default_schema }}\r\n\r\n    {%- else -%}\r\n\r\n        {{ custom_schema_name | trim }}\r\n\r\n    {%- endif -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.Has_Input_macro": {"unique_id": "macro.dbttraining.Has_Input_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\Has_Input_macro.sql", "original_file_path": "macros\\Has_Input_macro.sql", "name": "Has_Input_macro", "macro_sql": "{%- macro Has_Input_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\r\n\r\n{% set filter_conditions = metadata_dict['filter_conditions'] %}\r\n\r\nSELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nFROM {{ source_model }}\r\n{% if filter_conditions != \"\" %}\r\n    where {{ filter_conditions }}\r\n    {%- endif -%}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxAggregator_macro": {"unique_id": "macro.dbttraining.PxAggregator_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxAggregator_macro.sql", "original_file_path": "macros\\PxAggregator_macro.sql", "name": "PxAggregator_macro", "macro_sql": "{%- macro PxAggregator_macro(metadata_dict=none) -%}\n\n{% set source_model = metadata_dict['source_model'] %}\n\n{% set group_by_columns = metadata_dict['group_by_columns'] %}\n\n{% set derived_columns = metadata_dict['derived_columns'] %}\n\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\n\n{% set filter_conditions = metadata_dict['filter_conditions'] %}\n\nSELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \nFROM {{ source_model }}\n{% if filter_conditions != \"\" %}\nWHERE {{ filter_conditions }}\n    {%- endif -%}\nGROUP BY \n{% for i in range(1, group_by_columns|length + 1) -%}\n{{ i }}{{ ',' if not loop.last }}   \n{%- endfor -%}\n    \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxCopy_macro": {"unique_id": "macro.dbttraining.PxCopy_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxCopy_macro.sql", "original_file_path": "macros\\PxCopy_macro.sql", "name": "PxCopy_macro", "macro_sql": "{%- macro PxCopy_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\r\n\r\nWITH staging AS (\r\n{{ dbtvault.stage(include_source_columns=false,\r\n                  source_model=source_model,\r\n                  derived_columns=derived_columns,\r\n                  hashed_columns=none,\r\n                  ranked_columns=none) }}\r\n)\r\n\r\nSELECT *\r\nFROM staging\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxDataset_macro": {"unique_id": "macro.dbttraining.PxDataset_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxDataset_macro.sql", "original_file_path": "macros\\PxDataset_macro.sql", "name": "PxDataset_macro", "macro_sql": "{%- macro PxDataset_macro(metadata_dict=none) -%}\r\n\r\n\r\n{% set source_columns = metadata_dict['source_columns'] %}\r\n{% set source_table = metadata_dict['source_table'] %}\r\n\r\nselect {{ source_columns }} from {{ source_table }} \r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxFilter_macro": {"unique_id": "macro.dbttraining.PxFilter_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxFilter_macro.sql", "original_file_path": "macros\\PxFilter_macro.sql", "name": "PxFilter_macro", "macro_sql": "{%- macro PxFilter_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set filter_conditions = metadata_dict['filter_conditions'] %}\r\n\r\nSELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nFROM {{ source_model }}\r\nwhere {{ filter_conditions }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxFunnel_macro": {"unique_id": "macro.dbttraining.PxFunnel_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxFunnel_macro.sql", "original_file_path": "macros\\PxFunnel_macro.sql", "name": "PxFunnel_macro", "macro_sql": "{%- macro PxFunnel_macro(metadata_dict=none) -%}\r\n\r\n{% set source_models = metadata_dict['source_models'] %}\r\n\r\n--create below set variables based on no of sources\r\n\r\n{% set i = 0 %}\r\n\r\n\r\n{% for model in source_models %}\r\n {% set i = loop.index %}\r\n \r\n    {% set source_model = source_models[i-1] %}\r\n    {% set derived_columns = metadata_dict['source_columns_' ~ loop.index|string] %}\r\n    \r\n    {% if i == source_models|length %}\r\n\r\n    SELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\n    FROM {{ source_models[i-1] }} \r\n    {%- else -%} \r\n    SELECT {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\n    FROM {{ source_models[i-1] }} \r\n    union all \r\n    {%- endif -%}\r\n{% endfor %}\r\n\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.Pxjoin_macro": {"unique_id": "macro.dbttraining.Pxjoin_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\Pxjoin_macro.sql", "original_file_path": "macros\\Pxjoin_macro.sql", "name": "Pxjoin_macro", "macro_sql": "{%- macro Pxjoin_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set lkp_models = metadata_dict['lkp_models'] %}\r\n\r\n{% set rem_src_model =  lkp_models.pop(0) %}\r\n\r\n{% set join_type = metadata_dict['join_type'] %}\r\n{% set join_keys = metadata_dict['join_keys'] %}\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom {{ source_model }}  \r\n\r\n{% for lookup_model in lkp_models %}\r\n{{join_type}} {{lookup_model}}  on \r\n {% for join_key in join_keys %}\r\n    {% set i = loop.index %}\r\n    {% if i == join_keys|length %}\r\n        {{source_model}}.{{join_key}} = {{lookup_model}}.{{join_key}}\r\n    {% else %}\r\n        {{source_model}}.{{join_key}} = {{lookup_model}}.{{join_key}} and \r\n    {%- endif -%}\r\n\r\n {% endfor %}\r\n {% endfor %}\r\n  \r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxLookup_macro": {"unique_id": "macro.dbttraining.PxLookup_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxLookup_macro.sql", "original_file_path": "macros\\PxLookup_macro.sql", "name": "PxLookup_macro", "macro_sql": "{%- macro PxLookup_macro(metadata_dict=none) -%}\r\n\r\n{%- set source_model = metadata_dict['lkp_models'][0] -%}\r\n\r\n{%- set derived_columns = metadata_dict['derived_columns'] -%}\r\n{%- set lkp_models = metadata_dict['lkp_models'] %}\r\n{%- set lkp_conditions = metadata_dict['lkp_conditions'] -%}\r\n{%- set lkp_field = metadata_dict['lkp_field'] %}\r\n{%- set partition_by_field = metadata_dict['partition_by_field'] -%}\r\n\r\n\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom {{ source_model }} as {{ source_model }} \r\n\r\n{% for lkpcond in lkp_conditions %}\r\n {%- set i = loop.index %}\r\n  \r\n  {%- if i <= lkp_conditions|length %}\r\n     left outer join (select * from (select row_number() over(partition by  {{partition_by_field[i-1] }}  order by {{partition_by_field[i-1] }} ) as rnk,  {{ partition_by_field[i-1] }} ,\r\n     {%- set lkp_fields = lkp_field[i-1].split(',') %}\r\n         {%- for lkp in lkp_fields -%}\r\n            {%- set j = loop.index -%}\r\n            {%- if j < lkp_fields|length -%}\r\n               {{lkp_fields[j-1]}},\r\n            {%- else %}\r\n               {{lkp_fields[j-1]}}\r\n            {%- endif -%}\r\n         {%- endfor %}\r\n     from {{ lkp_models[i] }})\r\n      where rnk=1)  {{ lkp_models[i] }} on \r\n     {{ lkp_conditions[i-1] }}\r\n  {%- endif -%}\r\n   \r\n  \r\n\r\n{%- endfor -%}\r\n\r\n                  \r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxLookup_macro_first": {"unique_id": "macro.dbttraining.PxLookup_macro_first", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxLookup_macro.sql", "original_file_path": "macros\\PxLookup_macro.sql", "name": "PxLookup_macro_first", "macro_sql": "\r\n\r\n{%- macro PxLookup_macro_first(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['lkp_models'][0] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set lkp_models = metadata_dict['lkp_models'] %}\r\n{% set lkp_conditions = metadata_dict['lkp_conditions'] %}\r\n{% set lkp_field = metadata_dict['lkp_field'] %}\r\n{% set partition_by_field = metadata_dict['partition_by_field'] %}\r\n\r\n\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom {{ source_model }} as {{ source_model }}  \r\n\r\n{% for lkpcond in lkp_conditions %}\r\n {% set i = loop.index %}\r\n  \r\n  {% if i <= lkp_conditions|length %}\r\n     left outer join (select  row_number() over(partition by {{ partition_by_field[i-1] }}  order by 1) as rnk,  \r\n     {% set lkp_fields = lkp_field[i-1].split(',') %}\r\n         {% for lkp in lkp_fields %}\r\n            {% set j = loop.index %}\r\n            {% if j < lkp_fields|length %}\r\n               first_value({{lkp_fields[j-1]}}) over(partition by  {{partition_by_field[i-1]}} order by select 1 ) as {{lkp_fields[j-1]}} ,\r\n            {% else %}\r\n               first_value({{lkp_fields[j-1]}}) over(partition by  {{partition_by_field[i-1]}} order by select 1 ) as {{lkp_fields[j-1]}}\r\n            {%- endif -%}\r\n         {% endfor %}\r\n     from {{ lkp_models[i] }})  {{ lkp_models[i] }} on \r\n     {{ lkp_conditions[i-1] }}\r\n  {%- endif -%}\r\n\r\n{% endfor %}\r\n\r\n                  \r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxLookup_macro_bkp": {"unique_id": "macro.dbttraining.PxLookup_macro_bkp", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxLookup_macro.sql", "original_file_path": "macros\\PxLookup_macro.sql", "name": "PxLookup_macro_bkp", "macro_sql": "\r\n\r\n\r\n{%- macro PxLookup_macro_bkp(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['lkp_models'][0] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n{% set lkp_models = metadata_dict['lkp_models'] %}\r\n{% set lkp_conditions = metadata_dict['lkp_conditions'] %}\r\n\r\n\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom {{ source_model }} as {{ source_model }}  \r\n\r\n{% for lkpcond in lkp_conditions %}\r\n {% set i = loop.index %}\r\n  {% if i < lkp_conditions|length %}\r\n     left outer join {{ lkp_models[i] }} as {{ lkp_models[i] }} on \r\n     {{ lkp_conditions[i-1] }}\r\n  {%- endif -%}\r\n  {% if i == lkp_conditions|length %}\r\n     left outer join {{ lkp_models[i] }} as {{ lkp_models[i] }}\r\n     {{ lkp_conditions[i-1] }}\r\n  {%- endif -%}\r\n{% endfor %}\r\n\r\n                  \r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxModify_macro": {"unique_id": "macro.dbttraining.PxModify_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxModify.sql", "original_file_path": "macros\\PxModify.sql", "name": "PxModify_macro", "macro_sql": "{%- macro PxModify_macro(metadata_dict=none) -%}\r\n\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\n{% set derived_columns = metadata_dict['derived_columns'] %}\r\n\r\n{% set hashed_columns = metadata_dict['hashed_columns'] %}\r\n\r\nWITH staging AS (\r\n{{ dbtvault.stage(include_source_columns=false,\r\n                  source_model=source_model,\r\n                  derived_columns=derived_columns,\r\n                  hashed_columns=none,\r\n                  ranked_columns=none) }}\r\n)\r\n\r\nSELECT *\r\nFROM staging\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxPivot_macro": {"unique_id": "macro.dbttraining.PxPivot_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxPivot_macro.sql", "original_file_path": "macros\\PxPivot_macro.sql", "name": "PxPivot_macro", "macro_sql": "{%- macro PxPivot_macro(metadata_dict=none) -%}\r\n\r\n{%- set source_model = metadata_dict['source_model'] -%}\r\n{%- set derived_columns = metadata_dict['derived_columns'] -%}\r\n{%- set pivot_columns = metadata_dict['pivot_columns'] -%}\r\n{%- set agg_column = metadata_dict['agg_column'] -%}\r\n{%- set pivot_column = metadata_dict['pivot_column'] -%}\r\n{%- set group_column = metadata_dict['group_column'] -%}\r\n{%- set array_index = metadata_dict['array_index'] -%}\r\n\r\n{%- set j = array_index + 1 -%}\r\n\r\nwith pivot_data as (\r\nselect distinct {{group_column}}\r\n{%- for pvtcol in pivot_column -%}\r\n       \r\n    {%- for _ in range(1, j) -%}\r\n        {%- if loop.index == 1 -%}\r\n        ,nth_value({{ pvtcol }}, {{loop.index}}) over (partition by {{ group_column }} order by (select 1)) as {{pvtcol}}\r\n        {%- endif -%} \r\n\r\n        {%- if loop.index != 1 -%}\r\n        {%- set i= loop.index - 1 -%}\r\n        ,nth_value({{ pvtcol }}, {{loop.index}}) over (partition by {{ group_column }} order by (select 1)) as {{pvtcol~'_'~i}}\r\n        {%- endif -%} \r\n\r\n    {%- endfor -%}\r\n{%- endfor %}\r\n from {{ source_model}}\r\n)\r\n\r\nselect {{ create_alias(source_model=source_model,  derived_columns=derived_columns) }} \r\nfrom pivot_data\r\n\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxSequentialFile_macro": {"unique_id": "macro.dbttraining.PxSequentialFile_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxSequentialFile_macro.sql", "original_file_path": "macros\\PxSequentialFile_macro.sql", "name": "PxSequentialFile_macro", "macro_sql": "{%- macro PxSequentialFile_macro(metadata_dict=none) -%}\r\n\r\n\r\n{% set source_columns = metadata_dict['source_columns'] %}\r\n{% set source_table = metadata_dict['source_table'] %}\r\n\r\n   select {{ source_columns }} from {{ source_table }} \r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.PxSort_macro": {"unique_id": "macro.dbttraining.PxSort_macro", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\PxSort_macro.sql", "original_file_path": "macros\\PxSort_macro.sql", "name": "PxSort_macro", "macro_sql": "{%- macro PxSort_macro(metadata_dict=none) -%}\r\n\r\n\r\n{% set sort_columns = metadata_dict['sort_columns'] %}\r\n{% set source_model = metadata_dict['source_model'] %}\r\n\r\nselect * from {{ source_model }} order by {{ sort_columns }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.remove_braces": {"unique_id": "macro.dbttraining.remove_braces", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\remove_braces.sql", "original_file_path": "macros\\remove_braces.sql", "name": "remove_braces", "macro_sql": "{% macro remove_braces(str) %}\r\n{% set str=  str | replace(\"(\",\"\") | replace(\")\",\"\")  %}\r\n{% set str1 =  str | replace(\",,\",\",\") %}\r\n{{str1}}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.remove_brackets": {"unique_id": "macro.dbttraining.remove_brackets", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\remove_brackets.sql", "original_file_path": "macros\\remove_brackets.sql", "name": "remove_brackets", "macro_sql": "{% macro remove_brackets(str) %}\r\n{% set str=  str | replace(\"[\",\"\") | replace(\"]\",\"\")  %}\r\n{{str}}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.remove_comma": {"unique_id": "macro.dbttraining.remove_comma", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\remove_comma.sql", "original_file_path": "macros\\remove_comma.sql", "name": "remove_comma", "macro_sql": "{% macro remove_comma(str) %}\r\n\r\n\r\n{% set str=  str | replace(\",\",\"\") %}\r\n\r\n{{str}}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbttraining.remove_quotes": {"unique_id": "macro.dbttraining.remove_quotes", "package_name": "dbttraining", "root_path": "E:\\Training\\DBT\\DBTTRAINING", "path": "macros\\remove_quotes.sql", "original_file_path": "macros\\remove_quotes.sql", "name": "remove_quotes", "macro_sql": "{% macro remove_quotes(str) %}\r\n\r\n\r\n{% set str=  str | replace(\"'\",\"\") %}\r\n\r\n{{str}}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__create_table_as": {"unique_id": "macro.dbt_snowflake.snowflake__create_table_as", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__create_table_as", "macro_sql": "{% macro snowflake__create_table_as(temporary, relation, sql) -%}\n  {%- set transient = config.get('transient', default=true) -%}\n  {%- set cluster_by_keys = config.get('cluster_by', default=none) -%}\n  {%- set enable_automatic_clustering = config.get('automatic_clustering', default=false) -%}\n  {%- set copy_grants = config.get('copy_grants', default=false) -%}\n\n  {%- if cluster_by_keys is not none and cluster_by_keys is string -%}\n    {%- set cluster_by_keys = [cluster_by_keys] -%}\n  {%- endif -%}\n  {%- if cluster_by_keys is not none -%}\n    {%- set cluster_by_string = cluster_by_keys|join(\", \")-%}\n  {% else %}\n    {%- set cluster_by_string = none -%}\n  {%- endif -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n      create or replace {% if temporary -%}\n        temporary\n      {%- elif transient -%}\n        transient\n      {%- endif %} table {{ relation }} {% if copy_grants and not temporary -%} copy grants {%- endif %} as\n      (\n        {%- if cluster_by_string is not none -%}\n          select * from(\n            {{ sql }}\n            ) order by ({{ cluster_by_string }})\n        {%- else -%}\n          {{ sql }}\n        {%- endif %}\n      );\n    {% if cluster_by_string is not none and not temporary -%}\n      alter table {{relation}} cluster by ({{cluster_by_string}});\n    {%- endif -%}\n    {% if enable_automatic_clustering and cluster_by_string is not none and not temporary  -%}\n      alter table {{relation}} resume recluster;\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__create_view_as": {"unique_id": "macro.dbt_snowflake.snowflake__create_view_as", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__create_view_as", "macro_sql": "{% macro snowflake__create_view_as(relation, sql) -%}\n  {%- set secure = config.get('secure', default=false) -%}\n  {%- set copy_grants = config.get('copy_grants', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create or replace {% if secure -%}\n    secure\n  {%- endif %} view {{ relation }} {% if copy_grants -%} copy grants {%- endif %} as (\n    {{ sql }}\n  );\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_columns_in_relation": {"unique_id": "macro.dbt_snowflake.snowflake__get_columns_in_relation", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__get_columns_in_relation", "macro_sql": "{% macro snowflake__get_columns_in_relation(relation) -%}\n  {%- set sql -%}\n    describe table {{ relation }}\n  {%- endset -%}\n  {%- set result = run_query(sql) -%}\n\n  {% set maximum = 10000 %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many columns in relation {{ relation }}! dbt can only get\n      information about relations with fewer than {{ maximum }} columns.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n\n  {% set columns = [] %}\n  {% for row in result %}\n    {% do columns.append(api.Column.from_description(row['name'], row['type'])) %}\n  {% endfor %}\n  {% do return(columns) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__list_schemas": {"unique_id": "macro.dbt_snowflake.snowflake__list_schemas", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__list_schemas", "macro_sql": "{% macro snowflake__list_schemas(database) -%}\n  {# 10k limit from here: https://docs.snowflake.net/manuals/sql-reference/sql/show-schemas.html#usage-notes #}\n  {% set maximum = 10000 %}\n  {% set sql -%}\n    show terse schemas in database {{ database }}\n    limit {{ maximum }}\n  {%- endset %}\n  {% set result = run_query(sql) %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many schemas in database {{ database }}! dbt can only get\n      information about databases with fewer than {{ maximum }} schemas.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n  {{ return(result) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__list_relations_without_caching": {"unique_id": "macro.dbt_snowflake.snowflake__list_relations_without_caching", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__list_relations_without_caching", "macro_sql": "{% macro snowflake__list_relations_without_caching(schema_relation) %}\n  {%- set sql -%}\n    show terse objects in {{ schema_relation }}\n  {%- endset -%}\n\n  {%- set result = run_query(sql) -%}\n  {% set maximum = 10000 %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many schemas in schema  {{ schema_relation }}! dbt can only get\n      information about schemas with fewer than {{ maximum }} objects.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n  {%- do return(result) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__check_schema_exists": {"unique_id": "macro.dbt_snowflake.snowflake__check_schema_exists", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__check_schema_exists", "macro_sql": "{% macro snowflake__check_schema_exists(information_schema, schema) -%}\n  {% call statement('check_schema_exists', fetch_result=True) -%}\n        select count(*)\n        from {{ information_schema }}.schemata\n        where upper(schema_name) = upper('{{ schema }}')\n            and upper(catalog_name) = upper('{{ information_schema.database }}')\n  {%- endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__current_timestamp": {"unique_id": "macro.dbt_snowflake.snowflake__current_timestamp", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__current_timestamp", "macro_sql": "{% macro snowflake__current_timestamp() -%}\n  convert_timezone('UTC', current_timestamp())\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__snapshot_string_as_time": {"unique_id": "macro.dbt_snowflake.snowflake__snapshot_string_as_time", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__snapshot_string_as_time", "macro_sql": "{% macro snowflake__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp_ntz('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__snapshot_get_time": {"unique_id": "macro.dbt_snowflake.snowflake__snapshot_get_time", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__snapshot_get_time", "macro_sql": "{% macro snowflake__snapshot_get_time() -%}\n  to_timestamp_ntz({{ current_timestamp() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__rename_relation": {"unique_id": "macro.dbt_snowflake.snowflake__rename_relation", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__rename_relation", "macro_sql": "{% macro snowflake__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ to_relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_column_type": {"unique_id": "macro.dbt_snowflake.snowflake__alter_column_type", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_column_type", "macro_sql": "{% macro snowflake__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter {{ adapter.quote(column_name) }} set data type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_relation_comment": {"unique_id": "macro.dbt_snowflake.snowflake__alter_relation_comment", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_relation_comment", "macro_sql": "{% macro snowflake__alter_relation_comment(relation, relation_comment) -%}\n  comment on {{ relation.type }} {{ relation }} IS $${{ relation_comment | replace('$', '[$]') }}$$;\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_column_comment": {"unique_id": "macro.dbt_snowflake.snowflake__alter_column_comment", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_column_comment", "macro_sql": "{% macro snowflake__alter_column_comment(relation, column_dict) -%}\n    alter {{ relation.type }} {{ relation }} alter\n    {% for column_name in column_dict %}\n        {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }} COMMENT $${{ column_dict[column_name]['description'] | replace('$', '[$]') }}$$ {{ ',' if not loop.last else ';' }}\n    {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.get_current_query_tag": {"unique_id": "macro.dbt_snowflake.get_current_query_tag", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "get_current_query_tag", "macro_sql": "{% macro get_current_query_tag() -%}\n  {{ return(run_query(\"show parameters like 'query_tag' in session\").rows[0]['value']) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.set_query_tag": {"unique_id": "macro.dbt_snowflake.set_query_tag", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "set_query_tag", "macro_sql": "{% macro set_query_tag() -%}\n  {% set new_query_tag = config.get('query_tag') %}\n  {% if new_query_tag %}\n    {% set original_query_tag = get_current_query_tag() %}\n    {{ log(\"Setting query_tag to '\" ~ new_query_tag ~ \"'. Will reset to '\" ~ original_query_tag ~ \"' after materialization.\") }}\n    {% do run_query(\"alter session set query_tag = '{}'\".format(new_query_tag)) %}\n    {{ return(original_query_tag)}}\n  {% endif %}\n  {{ return(none)}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.unset_query_tag": {"unique_id": "macro.dbt_snowflake.unset_query_tag", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "unset_query_tag", "macro_sql": "{% macro unset_query_tag(original_query_tag) -%}\n  {% set new_query_tag = config.get('query_tag') %}\n  {% if new_query_tag %}\n    {% if original_query_tag %}\n      {{ log(\"Resetting query_tag to '\" ~ original_query_tag ~ \"'.\") }}\n      {% do run_query(\"alter session set query_tag = '{}'\".format(original_query_tag)) %}\n    {% else %}\n      {{ log(\"No original query_tag, unsetting parameter.\") }}\n      {% do run_query(\"alter session unset query_tag\") %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_catalog": {"unique_id": "macro.dbt_snowflake.snowflake__get_catalog", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\catalog.sql", "original_file_path": "macros\\catalog.sql", "name": "snowflake__get_catalog", "macro_sql": "{% macro snowflake__get_catalog(information_schema, schemas) -%}\n  {% set query %}\n      with tables as (\n\n          select\n              table_catalog as \"table_database\",\n              table_schema as \"table_schema\",\n              table_name as \"table_name\",\n              table_type as \"table_type\",\n              comment as \"table_comment\",\n\n              -- note: this is the _role_ that owns the table\n              table_owner as \"table_owner\",\n\n              'Clustering Key' as \"stats:clustering_key:label\",\n              clustering_key as \"stats:clustering_key:value\",\n              'The key used to cluster this table' as \"stats:clustering_key:description\",\n              (clustering_key is not null) as \"stats:clustering_key:include\",\n\n              'Row Count' as \"stats:row_count:label\",\n              row_count as \"stats:row_count:value\",\n              'An approximate count of rows in this table' as \"stats:row_count:description\",\n              (row_count is not null) as \"stats:row_count:include\",\n\n              'Approximate Size' as \"stats:bytes:label\",\n              bytes as \"stats:bytes:value\",\n              'Approximate size of the table as reported by Snowflake' as \"stats:bytes:description\",\n              (bytes is not null) as \"stats:bytes:include\",\n\n              'Last Modified' as \"stats:last_modified:label\",\n              to_varchar(convert_timezone('UTC', last_altered), 'yyyy-mm-dd HH24:MI'||'UTC') as \"stats:last_modified:value\",\n              'The timestamp for last update/change' as \"stats:last_modified:description\",\n              (last_altered is not null and table_type='BASE TABLE') as \"stats:last_modified:include\"\n\n          from {{ information_schema }}.tables\n\n      ),\n\n      columns as (\n\n          select\n              table_catalog as \"table_database\",\n              table_schema as \"table_schema\",\n              table_name as \"table_name\",\n\n              column_name as \"column_name\",\n              ordinal_position as \"column_index\",\n              data_type as \"column_type\",\n              comment as \"column_comment\"\n\n          from {{ information_schema }}.columns\n      )\n\n      select *\n      from tables\n      join columns using (\"table_database\", \"table_schema\", \"table_name\")\n      where (\n        {%- for schema in schemas -%}\n          upper(\"table_schema\") = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n      order by \"column_index\"\n    {%- endset -%}\n\n  {{ return(run_query(query)) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.dbt_snowflake_validate_get_incremental_strategy": {"unique_id": "macro.dbt_snowflake.dbt_snowflake_validate_get_incremental_strategy", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "dbt_snowflake_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_snowflake_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'delete+insert'\n  {%- endset %}\n  {% if strategy not in ['merge', 'delete+insert'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.dbt_snowflake_get_incremental_sql": {"unique_id": "macro.dbt_snowflake.dbt_snowflake_get_incremental_sql", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "dbt_snowflake_get_incremental_sql", "macro_sql": "{% macro dbt_snowflake_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key, dest_columns) %}\n  {% if strategy == 'merge' %}\n    {% do return(get_merge_sql(target_relation, tmp_relation, unique_key, dest_columns)) %}\n  {% elif strategy == 'delete+insert' %}\n    {% do return(get_delete_insert_merge_sql(target_relation, tmp_relation, unique_key, dest_columns)) %}\n  {% else %}\n    {% do exceptions.raise_compiler_error('invalid strategy: ' ~ strategy) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_incremental_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_incremental_snowflake", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "materialization_incremental_snowflake", "macro_sql": "{% materialization incremental, adapter='snowflake' -%}\n\n  {% set original_query_tag = set_query_tag() %}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_snowflake_validate_get_incremental_strategy(config) -%}\n\n  -- setup\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% if existing_relation is none %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n    {#-- Can't overwrite a view with a table - we must drop --#}\n    {{ log(\"Dropping relation \" ~ target_relation ~ \" because it is a view and this model is a table.\") }}\n    {% do adapter.drop_relation(existing_relation) %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do adapter.expand_target_column_types(\n           from_relation=tmp_relation,\n           to_relation=target_relation) %}\n    {% set dest_columns = adapter.get_columns_in_relation(target_relation) %}\n    {% set build_sql = dbt_snowflake_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key, dest_columns) %}\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {%- endcall -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = target_relation.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {% do unset_query_tag(original_query_tag) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_merge_sql": {"unique_id": "macro.dbt_snowflake.snowflake__get_merge_sql", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\merge.sql", "original_file_path": "macros\\materializations\\merge.sql", "name": "snowflake__get_merge_sql", "macro_sql": "{% macro snowflake__get_merge_sql(target, source_sql, unique_key, dest_columns, predicates) -%}\n\n    {#\n       Workaround for Snowflake not being happy with a merge on a constant-false predicate.\n       When no unique_key is provided, this macro will do a regular insert. If a unique_key\n       is provided, then this macro will do a proper merge instead.\n    #}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute='name')) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {%- if unique_key is none -%}\n\n        {{ sql_header if sql_header is not none }}\n\n        insert into {{ target }} ({{ dest_cols_csv }})\n        (\n            select {{ dest_cols_csv }}\n            from {{ source_sql }}\n        );\n\n    {%- else -%}\n\n        {{ default__get_merge_sql(target, source_sql, unique_key, dest_columns, predicates) }}\n\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_table_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_table_snowflake", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\table.sql", "original_file_path": "macros\\materializations\\table.sql", "name": "materialization_table_snowflake", "macro_sql": "{% materialization table, adapter='snowflake' %}\n\n  {% set original_query_tag = set_query_tag() %}\n\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database, type='table') -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {#-- Drop the relation if it was a view to \"convert\" it in a table. This may lead to\n    -- downtime, but it should be a relatively infrequent occurrence  #}\n  {% if old_relation is not none and not old_relation.is_table %}\n    {{ log(\"Dropping relation \" ~ old_relation ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ drop_relation_if_exists(old_relation) }}\n  {% endif %}\n\n  --build model\n  {% call statement('main') -%}\n    {{ create_table_as(false, target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do unset_query_tag(original_query_tag) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_view_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_view_snowflake", "package_name": "dbt_snowflake", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\view.sql", "original_file_path": "macros\\materializations\\view.sql", "name": "materialization_view_snowflake", "macro_sql": "{% materialization view, adapter='snowflake' -%}\n\n    {% set original_query_tag = set_query_tag() %}\n    {% set to_return = create_or_replace_view() %}\n\n    {% set target_relation = this.incorporate(type='view') %}\n    {% do persist_docs(target_relation, model, for_columns=false) %}\n\n    {% do return(to_return) %}\n\n    {% do unset_query_tag(original_query_tag) %}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.statement": {"unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\core.sql", "original_file_path": "macros\\core.sql", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.noop_statement": {"unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\core.sql", "original_file_path": "macros\\core.sql", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_query": {"unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query')(select_sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_query": {"unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_schema": {"unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_schema": {"unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_schema": {"unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_schema": {"unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_table_as": {"unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter.dispatch('create_table_as')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_table_as": {"unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_view_as": {"unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_view_as": {"unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_catalog": {"unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog')(information_schema, schemas)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_catalog": {"unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_relation": {"unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.sql_convert_columns_in_relation": {"unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_relation": {"unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_type": {"unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_comment": {"unique_id": "macro.dbt.alter_column_comment", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment')(relation, column_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_comment": {"unique_id": "macro.dbt.default__alter_column_comment", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_relation_comment": {"unique_id": "macro.dbt.alter_relation_comment", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment')(relation, relation_comment)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_relation_comment": {"unique_id": "macro.dbt.default__alter_relation_comment", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.persist_docs": {"unique_id": "macro.dbt.persist_docs", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__persist_docs": {"unique_id": "macro.dbt.default__persist_docs", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_type": {"unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation": {"unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter.dispatch('drop_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_relation": {"unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.truncate_relation": {"unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__truncate_relation": {"unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.rename_relation": {"unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation')(from_relation, to_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__rename_relation": {"unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.information_schema_name": {"unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__information_schema_name": {"unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.list_schemas": {"unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_schemas": {"unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.check_schema_exists": {"unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists')(information_schema, schema)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__check_schema_exists": {"unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.list_relations_without_caching": {"unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching')(schema_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_relations_without_caching": {"unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.current_timestamp": {"unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter.dispatch('current_timestamp')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__current_timestamp": {"unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.collect_freshness": {"unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness')(source, loaded_at_field, filter))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__collect_freshness": {"unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.make_temp_relation": {"unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_temp_relation')(base_relation, suffix))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__make_temp_relation": {"unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.set_sql_header": {"unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.convert_datetime": {"unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.dates_in_range": {"unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.partition_range": {"unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.py_current_timestring": {"unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_alias_name": {"unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_alias.sql", "original_file_path": "macros\\etc\\get_custom_alias.sql", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_database_name": {"unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_database.sql", "original_file_path": "macros\\etc\\get_custom_database.sql", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name')(custom_database_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__generate_database_name": {"unique_id": "macro.dbt.default__generate_database_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_database.sql", "original_file_path": "macros\\etc\\get_custom_database.sql", "name": "default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name": {"unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_schema.sql", "original_file_path": "macros\\etc\\get_custom_schema.sql", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name_for_env": {"unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_schema.sql", "original_file_path": "macros\\etc\\get_custom_schema.sql", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.is_incremental": {"unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\is_incremental.sql", "original_file_path": "macros\\etc\\is_incremental.sql", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.run_query": {"unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\query.sql", "original_file_path": "macros\\etc\\query.sql", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.run_hooks": {"unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.column_list": {"unique_id": "macro.dbt.column_list", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "column_list", "macro_sql": "{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.column_list_for_create_table": {"unique_id": "macro.dbt.column_list_for_create_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "column_list_for_create_table", "macro_sql": "{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.make_hook_config": {"unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.before_begin": {"unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.in_transaction": {"unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.after_commit": {"unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation_if_exists": {"unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.load_relation": {"unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.should_full_refresh": {"unique_id": "macro.dbt.should_full_refresh", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_merge_sql": {"unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter.dispatch('get_merge_sql')(target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_delete_insert_merge_sql": {"unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql')(target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_merge_sql": {"unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_quoted_csv": {"unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.common_get_delete_insert_merge_sql": {"unique_id": "macro.dbt.common_get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "common_get_delete_insert_merge_sql", "macro_sql": "{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_delete_insert_merge_sql": {"unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.incremental_upsert": {"unique_id": "macro.dbt.incremental_upsert", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\incremental\\helpers.sql", "original_file_path": "macros\\materializations\\incremental\\helpers.sql", "name": "incremental_upsert", "macro_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_incremental_default": {"unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\incremental\\incremental.sql", "original_file_path": "macros\\materializations\\incremental\\incremental.sql", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or should_full_refresh() %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_csv_table": {"unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.reset_csv_table": {"unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.load_csv_rows": {"unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_csv_table": {"unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__reset_csv_table": {"unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_seed_column_quoted_csv": {"unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.basic_load_csv_rows": {"unique_id": "macro.dbt.basic_load_csv_rows", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "basic_load_csv_rows", "macro_sql": "{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__load_csv_rows": {"unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_seed_default": {"unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_columns": {"unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns')(relation, columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_columns": {"unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.post_snapshot": {"unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot')(staging_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__post_snapshot": {"unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table": {"unique_id": "macro.dbt.snapshot_staging_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    insertions_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to,\n            {{ strategy.scd_id }} as dbt_scd_id\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            {{ strategy.updated_at }} as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.dbt_scd_id\n\n        from updates_source_data as source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n    )\n\n    select * from insertions\n    union all\n    select * from updates\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_table": {"unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_or_create_relation": {"unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_staging_table": {"unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_snapshot_default": {"unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_merge_sql": {"unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql')(target, source, insert_cols) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_merge_sql": {"unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.strategy_dispatch": {"unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_hash_arguments": {"unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments')(args) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_hash_arguments": {"unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_get_time": {"unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter.dispatch('snapshot_get_time')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_get_time": {"unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_timestamp_strategy": {"unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/fishtown-analytics/dbt/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.dbt_valid_from < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_string_as_time": {"unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time')(timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_string_as_time": {"unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_all_get_existing_columns": {"unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_strategy": {"unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {#-- don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_table_default": {"unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\table\\table.sql", "original_file_path": "macros\\materializations\\table\\table.sql", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.handle_existing_table": {"unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch(\"handle_existing_table\", packages=['dbt'])(full_refresh, old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__handle_existing_table": {"unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_or_replace_view": {"unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_view_default": {"unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\view.sql", "original_file_path": "macros\\materializations\\view\\view.sql", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_accepted_values": {"unique_id": "macro.dbt.default__test_accepted_values", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\accepted_values.sql", "original_file_path": "macros\\schema_tests\\accepted_values.sql", "name": "default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*) as validation_errors\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_accepted_values": {"unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\accepted_values.sql", "original_file_path": "macros\\schema_tests\\accepted_values.sql", "name": "test_accepted_values", "macro_sql": "{% macro test_accepted_values(model, values) %}\n    {% set macro = adapter.dispatch('test_accepted_values') %}\n    {{ macro(model, values, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_not_null": {"unique_id": "macro.dbt.default__test_not_null", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\not_null.sql", "original_file_path": "macros\\schema_tests\\not_null.sql", "name": "default__test_not_null", "macro_sql": "{% macro default__test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*) as validation_errors\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_not_null": {"unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\not_null.sql", "original_file_path": "macros\\schema_tests\\not_null.sql", "name": "test_not_null", "macro_sql": "{% macro test_not_null(model) %}\n    {% set macro = adapter.dispatch('test_not_null') %}\n    {{ macro(model, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_relationships": {"unique_id": "macro.dbt.default__test_relationships", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\relationships.sql", "original_file_path": "macros\\schema_tests\\relationships.sql", "name": "default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*) as validation_errors\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_relationships": {"unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\relationships.sql", "original_file_path": "macros\\schema_tests\\relationships.sql", "name": "test_relationships", "macro_sql": "{% macro test_relationships(model, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships') %}\n    {{ macro(model, to, field, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_unique": {"unique_id": "macro.dbt.default__test_unique", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\unique.sql", "original_file_path": "macros\\schema_tests\\unique.sql", "name": "default__test_unique", "macro_sql": "{% macro default__test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*) as validation_errors\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_unique": {"unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\unique.sql", "original_file_path": "macros\\schema_tests\\unique.sql", "name": "test_unique", "macro_sql": "{% macro test_unique(model) %}\n    {% set macro = adapter.dispatch('test_unique') %}\n    {{ macro(model, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.alias": {"unique_id": "macro.dbtvault.alias", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\alias.sql", "original_file_path": "macros\\internal\\alias.sql", "name": "alias", "macro_sql": "{%- macro alias(alias_config=none, prefix=none) -%}\n\n    {{- adapter.dispatch('alias', packages = dbtvault.get_dbtvault_namespaces())(alias_config=alias_config, prefix=prefix) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Perform aliasing on a mapping and optionally prefix the string as well.\n\nSee also:\n[alias_all](#!/macro/macro.dbtvault.alias_all)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": [{"name": "alias_config", "type": "Mapping", "description": "A mapping, containing a configuration for the aliasing. \n                                                \n| Key           | Description          | Type   |\n| ------------- | -------------------- | ------ |\n| source_column | Column being aliased | string |\n| alias         | Column alias         | string |"}, {"name": "prefix", "type": "String", "description": "A string to prefix the column with."}]}, "macro.dbtvault.default__alias": {"unique_id": "macro.dbtvault.default__alias", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\alias.sql", "original_file_path": "macros\\internal\\alias.sql", "name": "default__alias", "macro_sql": "\n\n{%- macro default__alias(alias_config=none, prefix=none) -%}\n\n{%- if alias_config is defined and alias_config is not none and alias_config -%}\n\n    {%- if alias_config is mapping -%}\n\n        {%- if alias_config['source_column'] and alias_config['alias'] -%}\n\n            {%- if prefix -%}\n                {{prefix}}.{{ alias_config['source_column'] }} AS {{ alias_config['alias'] }}\n            {%- else -%}\n                {{ alias_config['source_column'] }} AS {{ alias_config['alias'] }}\n            {%- endif -%}\n\n        {%- endif -%}\n\n    {%- else -%}\n\n        {%- if prefix -%}\n\n        {{- dbtvault.prefix([alias_config], prefix) -}}\n\n        {%- else -%}\n\n        {{ alias_config }}\n\n        {%- endif -%}\n\n    {%- endif -%}\n\n{%- else -%}\n\n    {%- if execute -%}\n\n        {{ exceptions.raise_compiler_error(\"Invalid alias configuration:\\nexpected format: {source_column: 'column', alias: 'column_alias'}\\ngot: \" ~ alias_config) }}\n\n    {%- endif -%}\n\n{%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.alias_all": {"unique_id": "macro.dbtvault.alias_all", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\alias_all.sql", "original_file_path": "macros\\internal\\alias_all.sql", "name": "alias_all", "macro_sql": "{%- macro alias_all(columns=none, prefix=none) -%}\n\n    {{- adapter.dispatch('alias_all', packages = dbtvault.get_dbtvault_namespaces())(columns=columns, prefix=prefix) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Perform aliasing on a mapping and optionally prefix the string as well.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": [{"name": "columns", "type": "string", "description": "A list of columns, as strings or mappings.\n\ne.g.\n\n```\nsrc_hashdiff: \n  source_column: \"CUSTOMER_HASHDIFF\"\n  alias: \"HASHDIFF\"\n```"}, {"name": "prefix", "type": "string", "description": "A string to prefix all columns with."}]}, "macro.dbtvault.default__alias_all": {"unique_id": "macro.dbtvault.default__alias_all", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\alias_all.sql", "original_file_path": "macros\\internal\\alias_all.sql", "name": "default__alias_all", "macro_sql": "\n\n{%- macro default__alias_all(columns, prefix) -%}\n\n{%- if dbtvault.is_list(columns) -%}\n\n    {%- for column in columns -%}\n        {{ dbtvault.alias(alias_config=column, prefix=prefix) }}\n        {%- if not loop.last -%} , {% endif -%}\n    {%- endfor -%}\n\n{%- elif columns is string -%}\n\n{{ dbtvault.alias(alias_config=columns, prefix=prefix) }}\n\n{%- else -%}\n\n    {%- if execute -%}\n        {{ exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list or a string.\") }}\n    {%- endif %}\n\n{%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.as_constant": {"unique_id": "macro.dbtvault.as_constant", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\as_constant.sql", "original_file_path": "macros\\internal\\as_constant.sql", "name": "as_constant", "macro_sql": "{%- macro as_constant(column_str=none) -%}\n\n    {{- adapter.dispatch('as_constant', packages = dbtvault.get_dbtvault_namespaces())(column_str=column_str) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Render a string as a constant value if it is prefixed with an exclamation mark (`!`) otherwise, return as provided.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": [{"name": "column_str", "type": "string", "description": "The string to parse as a constant."}]}, "macro.dbtvault.default__as_constant": {"unique_id": "macro.dbtvault.default__as_constant", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\as_constant.sql", "original_file_path": "macros\\internal\\as_constant.sql", "name": "default__as_constant", "macro_sql": "\n\n{%- macro default__as_constant(column_str) -%}\n\n    {% if column_str is not none and column_str is string and column_str %}\n\n        {%- if column_str | first == \"!\" -%}\n        \n            {{- return(\"'\" ~ column_str[1:] ~ \"'\") -}}\n        \n        {%- else -%}\n        \n            {{- return(column_str) -}}\n        \n        {%- endif -%}\n    {%- else -%}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid columns_str object provided. Must be a string and not null.\") }}\n        {%- endif %}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.expand_column_list": {"unique_id": "macro.dbtvault.expand_column_list", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\expand_column_list.sql", "original_file_path": "macros\\internal\\expand_column_list.sql", "name": "expand_column_list", "macro_sql": "{%- macro expand_column_list(columns=none) -%}\n\n{%- if not columns -%}\n    {%- if execute -%}\n         {{ exceptions.raise_compiler_error(\"Expected a list of columns, got: \" ~ columns) }}\n    {%- endif -%}\n{%- endif -%}\n\n{%- set col_list = [] -%}\n\n{%- if dbtvault.is_list(columns) -%}\n\n    {%- for col in columns -%}\n\n        {%- if col is string -%}\n\n            {%- do col_list.append(col) -%}\n\n        {#- If list of lists -#}\n        {%- elif dbtvault.is_list(col) -%}\n\n            {%- for cols in col -%}\n\n                {%- do col_list.append(cols) -%}\n\n            {%- endfor -%}\n        {%- elif col is mapping -%}\n\n            {%- do col_list.append(col) -%}\n\n        {%- else -%}\n\n            {%- if execute -%}\n                {{ exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list of lists, dictionaries or strings.\") }}\n            {%- endif %}\n\n        {%- endif -%}\n\n    {%- endfor -%}\n{%- else -%}\n\n    {%- if execute -%}\n        {{ exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list.\") }}\n    {%- endif %}\n\n{%- endif -%}\n\n{% do return(col_list) %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Flatten a nested list structure into a single list so that it may be rendered in CSV format or provided to other macros.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of lists to flatten. May contain strings as well, these will be added as single items in the returned list."}]}, "macro.dbtvault.get_dbtvault_namespaces": {"unique_id": "macro.dbtvault.get_dbtvault_namespaces", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\get_package_namespaces.sql", "original_file_path": "macros\\internal\\get_package_namespaces.sql", "name": "get_dbtvault_namespaces", "macro_sql": "{%- macro get_dbtvault_namespaces() -%}\n    {%- set override_namespaces = var('adapter_packages', []) -%}\n    {%- do return(override_namespaces + ['dbtvault']) -%}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.is_list": {"unique_id": "macro.dbtvault.is_list", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\is_checks.sql", "original_file_path": "macros\\internal\\is_checks.sql", "name": "is_list", "macro_sql": "{%- macro is_list(obj, empty_is_false=false) -%}\n\n    {%- if obj is iterable and obj is not string and obj is not mapping -%}\n        {%- if obj is none and obj is undefined and not obj and empty_is_false -%}\n            {%- do return(false) -%}\n        {%- endif -%}\n\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.is_nothing": {"unique_id": "macro.dbtvault.is_nothing", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\is_checks.sql", "original_file_path": "macros\\internal\\is_checks.sql", "name": "is_nothing", "macro_sql": "{%- macro is_nothing(obj) -%}\n\n    {%- if obj is none or obj is undefined or not obj -%}\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.is_something": {"unique_id": "macro.dbtvault.is_something", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\is_checks.sql", "original_file_path": "macros\\internal\\is_checks.sql", "name": "is_something", "macro_sql": "{%- macro is_something(obj) -%}\n\n    {%- if obj is not none and obj is defined and obj -%}\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.multikey": {"unique_id": "macro.dbtvault.multikey", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\multikey.sql", "original_file_path": "macros\\internal\\multikey.sql", "name": "multikey", "macro_sql": "{%- macro multikey(columns, prefix=none, condition=none, operator='AND') -%}\n\n    {{- adapter.dispatch('multikey', packages = dbtvault.get_dbtvault_namespaces())(columns=columns, prefix=prefix, condition=condition, operator=operator) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Apply the same conditions and comparisons to a list of columns/keys. \n\ne.g. Given the following argument values:\n\ncolumns = ['CUSTOMER_ID', 'NATION_ID']\nprefix = ['a', 'b']\ncondition = '='\noperator = 'AND'\n\nThe macro would render this as:\n\n```\na.CUSTOMER_ID = b.CUSTOMER_ID\nAND a.NATION_ID = b.NATION_ID \n```", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of columns to generate comparisons for."}, {"name": "prefix", "type": "string/list", "description": "A pair of prefixes, one for each side of the comparison."}, {"name": "condition", "type": "string", "description": "The comparison to make between the keys, should be one of: \n\n'<>', '!=', '='"}, {"name": "operator", "type": "string", "description": "The operator to join the conditions with, defaults to 'AND', but could also be 'OR'."}]}, "macro.dbtvault.default__multikey": {"unique_id": "macro.dbtvault.default__multikey", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\multikey.sql", "original_file_path": "macros\\internal\\multikey.sql", "name": "default__multikey", "macro_sql": "\n\n{%- macro default__multikey(columns, prefix=none, condition=none, operator='AND') -%}\n\n    {%- if prefix is string -%}\n        {%- set prefix = [prefix] -%}\n    {%- endif -%}\n\n    {%- if columns is string -%}\n        {%- set columns = [columns] -%}\n    {%- endif -%}\n\n    {%- if condition in ['<>', '!=', '='] -%}\n        {%- for col in columns -%}\n            {{ prefix[0] ~ '.' if prefix }}{{ col }} {{ condition }} {{ prefix[1] ~ '.' if prefix }}{{ col }}\n            {%- if not loop.last %} {{ operator }} {% endif %}\n        {% endfor -%}\n    {%- else -%}\n        {%- if dbtvault.is_list(columns) -%}\n            {%- for col in columns -%}\n                {{ prefix[0] ~ '.' if prefix }}{{ col }} {{ condition if condition else '' }}\n                {%- if not loop.last -%} {{ \"\\n    \" ~ operator }} {% endif -%}\n            {%- endfor -%}\n        {%- else -%}\n            {{ prefix[0] ~ '.' if prefix }}{{ columns }} {{ condition if condition else '' }}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.prepend_generated_by": {"unique_id": "macro.dbtvault.prepend_generated_by", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\prepend_generated_by.sql", "original_file_path": "macros\\internal\\prepend_generated_by.sql", "name": "prepend_generated_by", "macro_sql": "{%- macro prepend_generated_by() -%}\n-- Generated by dbtvault.\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A convenience macro to print a `-- Generated by dbtvault.` string.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\internal\\internal_schema.yml", "arguments": []}, "macro.dbtvault.process_columns_to_select": {"unique_id": "macro.dbtvault.process_columns_to_select", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\stage_processing_macros.sql", "original_file_path": "macros\\internal\\stage_processing_macros.sql", "name": "process_columns_to_select", "macro_sql": "{%- macro process_columns_to_select(columns_list=none, exclude_columns_list=none) -%}\n\n    {% set columns_to_select = [] %}\n\n    {% if not dbtvault.is_list(columns_list) or not dbtvault.is_list(exclude_columns_list)  %}\n\n        {{- exceptions.raise_compiler_error(\"One or both arguments are not of list type.\") -}}\n\n    {%- endif -%}\n\n    {%- if dbtvault.is_something(columns_list) and dbtvault.is_something(exclude_columns_list) -%}\n\n        {%- for col in columns_list -%}\n\n            {%- if col not in exclude_columns_list -%}\n                {%- do columns_to_select.append(col) -%}\n            {%- endif -%}\n\n        {%- endfor -%}\n\n    {%- endif -%}\n\n    {%- do return(columns_to_select) -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.extract_column_names": {"unique_id": "macro.dbtvault.extract_column_names", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\stage_processing_macros.sql", "original_file_path": "macros\\internal\\stage_processing_macros.sql", "name": "extract_column_names", "macro_sql": "{%- macro extract_column_names(columns_dict=none) -%}\n\n    {%- set extracted_column_names = [] -%}\n\n    {%- if columns_dict is mapping -%}\n        {%- for key, value in columns_dict.items() -%}\n            {%- do extracted_column_names.append(key) -%}\n        {%- endfor -%}\n\n        {%- do return(extracted_column_names) -%}\n    {%- else -%}\n        {%- do return([]) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.process_hash_column_excludes": {"unique_id": "macro.dbtvault.process_hash_column_excludes", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\stage_processing_macros.sql", "original_file_path": "macros\\internal\\stage_processing_macros.sql", "name": "process_hash_column_excludes", "macro_sql": "{%- macro process_hash_column_excludes(hash_columns=none, source_columns=none) -%}\n\n    {%- set processed_hash_columns = {} -%}\n\n    {%- for col, col_mapping in hash_columns.items() -%}\n        \n        {%- if col_mapping is mapping -%}\n            {%- if col_mapping.exclude_columns -%}\n\n                {%- if col_mapping.columns -%}\n\n                    {%- set columns_to_hash = dbtvault.process_columns_to_select(source_columns, col_mapping.columns) -%}\n\n                    {%- do hash_columns[col].pop('exclude_columns') -%}\n                    {%- do hash_columns[col].update({'columns': columns_to_hash}) -%}\n\n                    {%- do processed_hash_columns.update({col: hash_columns[col]}) -%}\n                {%- else -%}\n\n                    {%- do hash_columns[col].pop('exclude_columns') -%}\n                    {%- do hash_columns[col].update({'columns': source_columns}) -%}\n\n                    {%- do processed_hash_columns.update({col: hash_columns[col]}) -%}\n                {%- endif -%}\n            {%- else -%}\n                {%- do processed_hash_columns.update({col: col_mapping}) -%}\n            {%- endif -%}\n        {%- else -%}\n            {%- do processed_hash_columns.update({col: col_mapping}) -%}\n        {%- endif -%}\n\n    {%- endfor -%}\n\n    {%- do return(processed_hash_columns) -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.print_list": {"unique_id": "macro.dbtvault.print_list", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\internal\\stage_processing_macros.sql", "original_file_path": "macros\\internal\\stage_processing_macros.sql", "name": "print_list", "macro_sql": "{%- macro print_list(list_to_print=none, indent=4) -%}\n\n    {%- for col_name in list_to_print -%}\n        {{- col_name | indent(indent) -}}{{ \",\\n    \" if not loop.last }}\n    {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "replace_placeholder_with_period_filter", "macro_sql": "\n\n{%- macro replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) -%}\n\n    {% set macro = adapter.dispatch('replace_placeholder_with_period_filter',\n                                    packages = dbtvault.get_dbtvault_namespaces())(core_sql=core_sql,\n                                                                                   timestamp_field=timestamp_field,\n                                                                                   start_timestamp=start_timestamp,\n                                                                                   stop_timestamp=stop_timestamp,\n                                                                                   offset=offset,\n                                                                                   period=period) %}\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Replace the `__PERIOD_FILTER__` string present in the given SQL, with a `WHERE` clause which filters data by a\nspecific `period` of time, `offset` from the `start_date`.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "core_sql", "type": "string", "description": "SQL string containing the `__PERIOD_FILTER__` string."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "start_timestamp", "type": "string", "description": "The starting timestamp for the range of records to be loaded. \nRecords must have a timestamp greater or equal to this value to be included."}, {"name": "stop_timestamp", "type": "string", "description": "The stopping timestamp for the range of records to be loaded. \nRecords must have a timestamp less than this value to be included."}, {"name": "offset", "type": "integer", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}]}, "macro.dbtvault.default__replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.default__replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "default__replace_placeholder_with_period_filter", "macro_sql": "{% macro default__replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) %}\n\n    {%- set period_filter -%}\n            (TO_DATE({{ timestamp_field }}) >= DATE_TRUNC('{{ period }}', TO_DATE('{{ start_timestamp }}') + INTERVAL '{{ offset }} {{ period }}') AND\n             TO_DATE({{ timestamp_field }}) < DATE_TRUNC('{{ period }}', TO_DATE('{{ start_timestamp }}') + INTERVAL '{{ offset }} {{ period }}' + INTERVAL '1 {{ period }}'))\n      AND (TO_DATE({{ timestamp_field }}) >= TO_DATE('{{ start_timestamp }}'))\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Replace the `__PERIOD_FILTER__` string present in the given SQL, with a `WHERE` clause which filters data by a\nspecific `period` of time, `offset` from the `start_date`.\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_snowflake_schema.yml", "arguments": [{"name": "core_sql", "type": "string", "description": "SQL string containing the `__PERIOD_FILTER__` string."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "start_timestamp", "type": "string", "description": "The starting timestamp for the range of records to be loaded. \nRecords must have a timestamp greater or equal to this value to be included."}, {"name": "stop_timestamp", "type": "string", "description": "The stopping timestamp for the range of records to be loaded. \nRecords must have a timestamp less than this value to be included."}, {"name": "offset", "type": "integer", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}]}, "macro.dbtvault.get_period_filter_sql": {"unique_id": "macro.dbtvault.get_period_filter_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "get_period_filter_sql", "macro_sql": "\n\n{%- macro get_period_filter_sql(target_cols_csv, base_sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n    {% set macro = adapter.dispatch('get_period_filter_sql',\n                                    packages = dbtvault.get_dbtvault_namespaces())(target_cols_csv=target_cols_csv,\n                                                                                   base_sql=base_sql,\n                                                                                   timestamp_field=timestamp_field,\n                                                                                   period=period,\n                                                                                   start_timestamp=start_timestamp,\n                                                                                   stop_timestamp=stop_timestamp,\n                                                                                   offset=offset) %}\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A wrapper around the `replace_placeholder_with_period_filter` macro which creates a query designed to\nbuild a temporary table, to select the necessary records for the given load cycle.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "target_cols_csv", "type": "string", "description": "A CSV string of the columns to be created in the target table \n(the table the model is creating with this materialisation)"}, {"name": "base_sql", "type": "string", "description": "The SQL provided by the model, prior to any manipulation."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}, {"name": "start_timestamp", "type": "string", "description": "The starting timestamp for the range of records to be loaded. \nRecords must have a timestamp greater or equal to this value to be included."}, {"name": "stop_timestamp", "type": "string", "description": "The stopping timestamp for the range of records to be loaded. \nRecords must have a timestamp less than this value to be included."}, {"name": "offset", "type": "string", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}]}, "macro.dbtvault.default__get_period_filter_sql": {"unique_id": "macro.dbtvault.default__get_period_filter_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "default__get_period_filter_sql", "macro_sql": "{% macro default__get_period_filter_sql(target_cols_csv, base_sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n    {%- set filtered_sql = {'sql': base_sql} -%}\n\n    {%- do filtered_sql.update({'sql': dbtvault.replace_placeholder_with_period_filter(filtered_sql.sql,\n                                                                                       timestamp_field,\n                                                                                       start_timestamp,\n                                                                                       stop_timestamp,\n                                                                                       offset, period)}) -%}\n    select {{ target_cols_csv }} from ({{ filtered_sql.sql }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A wrapper around the `replace_placeholder_with_period_filter` macro which creates a query designed to\nbuild a temporary table, to select the necessary records for the given load cycle.\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_snowflake_schema.yml", "arguments": [{"name": "target_cols_csv", "type": "string", "description": "A CSV string of the columns to be created in the target table \n(the table the model is creating with this materialisation)"}, {"name": "base_sql", "type": "string", "description": "The SQL provided by the model, prior to any manipulation."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}, {"name": "start_timestamp", "type": "string", "description": "The starting timestamp for the range of records to be loaded. \nRecords must have a timestamp greater or equal to this value to be included."}, {"name": "stop_timestamp", "type": "string", "description": "The stopping timestamp for the range of records to be loaded. \nRecords must have a timestamp less than this value to be included."}, {"name": "offset", "type": "string", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}]}, "macro.dbtvault.get_period_boundaries": {"unique_id": "macro.dbtvault.get_period_boundaries", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "get_period_boundaries", "macro_sql": "\n\n{%- macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {% set macro = adapter.dispatch('get_period_boundaries',\n                                    packages = dbtvault.get_dbtvault_namespaces())(target_schema=target_schema,\n                                                                                   target_table=target_table,\n                                                                                   timestamp_field=timestamp_field,\n                                                                                   start_date=start_date,\n                                                                                   stop_date=stop_date,\n                                                                                   period=period) %}\n\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Get the start and stop timestamp, as well as the number of periods/iterations which need to be made to do the full load.\nIt is important to note that this materialisation handles the idempotent nature of the materialisation by running a `COALESCE`\non the maximal date found in the target table if it already exists, and the provided `start_date`. \n\nThis also allows the materialisation to handle aborted loads.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "target_schema", "type": "string", "description": "The schema that the target table is materialised in."}, {"name": "target_table", "type": "string", "description": "The name of the materialised target table."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "start_date", "type": "string", "description": "The date stamp to start loading from. Must be in the format 'YYYY-MM-DD'"}, {"name": "stop_date", "type": "string", "description": "THe date stamp to stop loading on. Must be in the format 'YYYY-MM-DD'"}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}]}, "macro.dbtvault.default__get_period_boundaries": {"unique_id": "macro.dbtvault.default__get_period_boundaries", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "default__get_period_boundaries", "macro_sql": "{% macro default__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {% set period_boundary_sql -%}\n        with data as (\n            select\n                coalesce(max({{ timestamp_field }}), '{{ start_date }}')::timestamp as start_timestamp,\n                coalesce({{ dbt_utils.dateadd('millisecond', 86399999, \"nullif('\" ~ stop_date | lower ~ \"','none')::timestamp\") }},\n                         {{ dbt_utils.current_timestamp() }} ) as stop_timestamp\n            from {{ target_schema }}.{{ target_table }}\n        )\n        select\n            start_timestamp,\n            stop_timestamp,\n            {{ dbt_utils.datediff('start_timestamp',\n                                  'stop_timestamp',\n                                  period) }} + 1 as num_periods\n        from data\n    {%- endset %}\n\n    {% set period_boundaries_dict = dbt_utils.get_query_results_as_dict(period_boundary_sql) %}\n\n    {% set period_boundaries = {'start_timestamp': period_boundaries_dict['START_TIMESTAMP'][0] | string,\n                                'stop_timestamp': period_boundaries_dict['STOP_TIMESTAMP'][0] | string,\n                                'num_periods': period_boundaries_dict['NUM_PERIODS'][0] | int} %}\n\n    {% do return(period_boundaries) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Get the start and stop timestamp, as well as the number of periods/iterations which need to be made to do the full load.\nIt is important to note that this materialisation handles the idempotent nature of the materialisation by running a `COALESCE`\non the maximal date found in the target table if it already exists, and the provided `start_date`. \n\nThis also allows the materialisation to handle aborted loads.\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_snowflake_schema.yml", "arguments": [{"name": "target_schema", "type": "string", "description": "The schema that the target table is materialised in."}, {"name": "target_table", "type": "string", "description": "The name of the materialised target table."}, {"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "start_date", "type": "string", "description": "The date stamp to start loading from. Must be in the format 'YYYY-MM-DD'"}, {"name": "stop_date", "type": "string", "description": "THe date stamp to stop loading on. Must be in the format 'YYYY-MM-DD'"}, {"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}]}, "macro.dbtvault.get_period_of_load": {"unique_id": "macro.dbtvault.get_period_of_load", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "get_period_of_load", "macro_sql": "\n\n{%- macro get_period_of_load(period, offset, start_timestamp) -%}\n\n    {% set macro = adapter.dispatch('get_period_of_load',\n                                    packages = dbtvault.get_dbtvault_namespaces())(period=period,\n                                                                                   offset=offset,\n                                                                                   start_timestamp=start_timestamp) %}\n\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A helper macro to fetch the date of the current load cycle.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}, {"name": "offset", "type": "string", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}, {"name": "start_timestamp", "type": "string", "description": "The `start_timestamp` of the load, derived from the `start_date`."}]}, "macro.dbtvault.default__get_period_of_load": {"unique_id": "macro.dbtvault.default__get_period_of_load", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "default__get_period_of_load", "macro_sql": "\n\n{%- macro default__get_period_of_load(period, offset, start_timestamp) -%}\n\n    {% set period_of_load_sql -%}\n        SELECT DATE_TRUNC('{{ period }}', DATEADD({{ period }}, {{ offset }}, TO_DATE('{{start_timestamp}}'))) AS period_of_load\n    {%- endset %}\n\n    {% set period_of_load_dict = dbt_utils.get_query_results_as_dict(period_of_load_sql) %}\n\n    {% set period_of_load = period_of_load_dict['PERIOD_OF_LOAD'][0] | string %}\n\n    {% do return(period_of_load) %}\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A helper macro to fetch the date of the current load cycle.\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_snowflake_schema.yml", "arguments": [{"name": "period", "type": "string", "description": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}, {"name": "offset", "type": "string", "description": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}, {"name": "start_timestamp", "type": "string", "description": "The `start_timestamp` of the load, derived from the `start_date`."}]}, "macro.dbtvault.is_vault_insert_by_period": {"unique_id": "macro.dbtvault.is_vault_insert_by_period", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "is_vault_insert_by_period", "macro_sql": "{% macro is_vault_insert_by_period() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'vault_insert_by_period'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Check that a model is using the `vault_insert_by_period` materialisation.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": []}, "macro.dbtvault.get_start_stop_dates": {"unique_id": "macro.dbtvault.get_start_stop_dates", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\period_mat_helpers.sql", "original_file_path": "macros\\materialisations\\period_mat_helpers.sql", "name": "get_start_stop_dates", "macro_sql": "{% macro get_start_stop_dates(timestamp_field, date_source_models) %}\n\n    {% if config.get('start_date', default=none) is not none %}\n\n        {%- set start_date = config.get('start_date') -%}\n        {%- set stop_date = config.get('stop_date', default=none) -%}\n\n        {% do return({'start_date': start_date,'stop_date': stop_date}) %}\n\n    {% elif date_source_models is not none %}\n\n        {% if date_source_models is string %}\n            {% set date_source_models = [date_source_models] %}\n        {% endif %}\n        {% set query_sql %}\n            WITH stage AS (\n            {% for source_model in date_source_models %}\n                SELECT {{ timestamp_field }} FROM {{ ref(source_model) }}\n                {% if not loop.last %} UNION ALL {% endif %}\n            {% endfor %})\n\n            SELECT MIN({{ timestamp_field }}) AS MIN, MAX({{ timestamp_field }}) AS MAX\n            FROM stage\n        {% endset %}\n\n        {% set min_max_dict = dbt_utils.get_query_results_as_dict(query_sql) %}\n\n        {% set start_date = min_max_dict['MIN'][0] | string %}\n        {% set stop_date = min_max_dict['MAX'][0] | string %}\n        {% set min_max_dates = {\"start_date\": start_date, \"stop_date\": stop_date} %}\n\n        {% do return(min_max_dates) %}\n\n    {% else %}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid 'vault_insert_by_period' configuration. Must provide 'start_date' and 'stop_date', just 'stop_date', and/or 'date_source_models' options.\") }}\n        {%- endif -%}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A helper macro to fetch the start and stop dates to load with. It will either infer the date range from the min and max \ndates present in the tables in `date_source_models` list, or alternatively use the `start_date` and `stop_date` \nconfig options. The config options take precedence if both are provided. A suitable error is raised if neither is provided.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "timestamp_field", "type": "string", "description": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, {"name": "date_source_models", "type": "string/list", "description": "A list of models to union together and extract min and max dates from, which will be used as the range to load records with."}]}, "macro.dbtvault.replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\rank_mat_helpers.sql", "original_file_path": "macros\\materialisations\\rank_mat_helpers.sql", "name": "replace_placeholder_with_rank_filter", "macro_sql": "\n\n{%- macro replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) -%}\n\n    {% set macro = adapter.dispatch('replace_placeholder_with_rank_filter',\n                                    packages = dbtvault.get_dbtvault_namespaces())(core_sql=core_sql,\n                                                                                   rank_column=rank_column,\n                                                                                   rank_iteration=rank_iteration) %}\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.default__replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.default__replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\rank_mat_helpers.sql", "original_file_path": "macros\\materialisations\\rank_mat_helpers.sql", "name": "default__replace_placeholder_with_rank_filter", "macro_sql": "{% macro default__replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) %}\n\n    {%- set rank_filter -%}\n        {{ rank_column }}::INTEGER = {{ rank_iteration }}::INTEGER\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__RANK_FILTER__\", rank_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.get_min_max_ranks": {"unique_id": "macro.dbtvault.get_min_max_ranks", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\rank_mat_helpers.sql", "original_file_path": "macros\\materialisations\\rank_mat_helpers.sql", "name": "get_min_max_ranks", "macro_sql": "{% macro get_min_max_ranks(rank_column, rank_source_models) %}\n\n    {% if rank_source_models is not none %}\n\n        {% if rank_source_models is string %}\n            {% set rank_source_models = [rank_source_models] %}\n        {% endif %}\n\n        {% set query_sql %}\n            WITH stage AS (\n            {% for source_model in rank_source_models %}\n                SELECT {{ rank_column }} FROM {{ ref(source_model) }}\n                {% if not loop.last %} UNION ALL {% endif %}\n            {% endfor %})\n\n            SELECT MIN({{ rank_column }}) AS MIN, MAX({{ rank_column }}) AS MAX\n            FROM stage\n        {% endset %}\n\n        {% set min_max_dict = dbt_utils.get_query_results_as_dict(query_sql) %}\n\n        {% set min_rank = min_max_dict['MIN'][0] | string %}\n        {% set max_rank = min_max_dict['MAX'][0] | string %}\n        {% set min_max_ranks = {\"min_rank\": min_rank, \"max_rank\": max_rank} %}\n\n        {% do return(min_max_ranks) %}\n\n    {% else %}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid 'vault_insert_by_rank' configuration. Must provide 'rank_column', and 'rank_source_models' options.\") }}\n        {%- endif -%}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.is_vault_insert_by_rank": {"unique_id": "macro.dbtvault.is_vault_insert_by_rank", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\rank_mat_helpers.sql", "original_file_path": "macros\\materialisations\\rank_mat_helpers.sql", "name": "is_vault_insert_by_rank", "macro_sql": "{% macro is_vault_insert_by_rank() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'vault_insert_by_rank'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.check_placeholder": {"unique_id": "macro.dbtvault.check_placeholder", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\shared_helpers.sql", "original_file_path": "macros\\materialisations\\shared_helpers.sql", "name": "check_placeholder", "macro_sql": "{% macro check_placeholder(model_sql, placeholder='__PERIOD_FILTER__') %}\n\n    {%- if model_sql.find(placeholder) == -1 -%}\n        {%- set error_message -%}\n            Model '{{ model.unique_id }}' does not include the required string '{{ placeholder }}' in its sql\n        {%- endset -%}\n        {{ exceptions.raise_compiler_error(error_message) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Searches the given SQL string for an expected placeholder, throwing an error if it is not found.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\helpers_schema.yml", "arguments": [{"name": "model_sql", "type": "string", "description": "The SQL string to search."}, {"name": "placeholder", "type": "string", "description": "Optional. Default: `__PERIOD_FILTER__`\n\nThe placeholder to search for."}]}, "macro.dbtvault.materialization_vault_insert_by_period_default": {"unique_id": "macro.dbtvault.materialization_vault_insert_by_period_default", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\vault_insert_by_period_materialization.sql", "original_file_path": "macros\\materialisations\\vault_insert_by_period_materialization.sql", "name": "materialization_vault_insert_by_period_default", "macro_sql": "{% materialization vault_insert_by_period, default -%}\n\n    {%- set full_refresh_mode = flags.FULL_REFRESH -%}\n\n    {%- set target_relation = this -%}\n    {%- set existing_relation = load_relation(this) -%}\n    {%- set tmp_relation = make_temp_relation(this) -%}\n\n    {%- set timestamp_field = config.require('timestamp_field') -%}\n    {%- set date_source_models = config.get('date_source_models', default=none) -%}\n\n    {%- set start_stop_dates = dbtvault.get_start_stop_dates(timestamp_field, date_source_models) | as_native -%}\n\n    {%- set period = config.get('period', default='day') -%}\n    {%- set to_drop = [] -%}\n\n    {%- do dbtvault.check_placeholder(sql) -%}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% if existing_relation is none %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_period_filter(sql, timestamp_field,\n                                                                       start_stop_dates.start_date,\n                                                                       start_stop_dates.stop_date,\n                                                                       0, period) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% do to_drop.append(tmp_relation) %}\n\n    {% elif existing_relation.is_view or full_refresh_mode %}\n        {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n        {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n        {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n\n        {% do adapter.drop_relation(backup_relation) %}\n        {% do adapter.rename_relation(target_relation, backup_relation) %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_period_filter(sql, timestamp_field,\n                                                                       start_stop_dates.start_date,\n                                                                       start_stop_dates.stop_date,\n                                                                       0, period) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% do to_drop.append(tmp_relation) %}\n        {% do to_drop.append(backup_relation) %}\n    {% else %}\n\n        {% set period_boundaries = dbtvault.get_period_boundaries(schema,\n                                                                  target_relation.name,\n                                                                  timestamp_field,\n                                                                  start_stop_dates.start_date,\n                                                                  start_stop_dates.stop_date,\n                                                                  period) %}\n\n        {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n        {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n        {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n        {% for i in range(period_boundaries.num_periods) -%}\n\n            {%- set iteration_number = i + 1 -%}\n            {%- set period_of_load = dbtvault.get_period_of_load(period, i, period_boundaries.start_timestamp) -%}\n\n            {{ dbt_utils.log_info(\"Running for {} {} of {} ({}) [{}]\".format(period, iteration_number, period_boundaries.num_periods, period_of_load, model.unique_id)) }}\n\n            {% set tmp_relation = make_temp_relation(this) %}\n            {% set tmp_table_sql = dbtvault.get_period_filter_sql(target_cols_csv, sql, timestamp_field, period,\n                                                                  period_boundaries.start_timestamp,\n                                                                  period_boundaries.stop_timestamp, i) %}\n\n            {% call statement() -%}\n                {{ dbt.create_table_as(True, tmp_relation, tmp_table_sql) }}\n            {%- endcall %}\n\n            {{ adapter.expand_target_column_types(from_relation=tmp_relation,\n                                                  to_relation=target_relation) }}\n\n            {%- set insert_query_name = 'main-' ~ i -%}\n            {% call statement(insert_query_name, fetch_result=True) -%}\n                insert into {{ target_relation }} ({{ target_cols_csv }})\n                (\n                    select {{ target_cols_csv }}\n                    from {{ tmp_relation.include(schema=True) }}\n                );\n            {%- endcall %}\n\n            {% set result = load_result(insert_query_name) %}\n\n            {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n                {% set rows_inserted = result['response']['rows_affected'] %}\n            {% else %} {# older versions #}\n                {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n            {% endif %}\n\n            {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n            {%- do loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %}\n\n            {{ dbt_utils.log_info(\"Ran for {} {} of {} ({}); {} records inserted [{}]\".format(period, iteration_number,\n                                                                                              period_boundaries.num_periods,\n                                                                                              period_of_load, rows_inserted,\n                                                                                              model.unique_id)) }}\n\n            {% do to_drop.append(tmp_relation) %}\n            {% do adapter.commit() %}\n\n        {% endfor %}\n\n        {% call noop_statement('main', \"INSERT {}\".format(loop_vars['sum_rows_inserted']) ) -%}\n            {{ tmp_table_sql }}\n        {%- endcall %}\n\n    {% endif %}\n\n    {% if build_sql is defined %}\n        {% call statement(\"main\", fetch_result=True) %}\n            {{ build_sql }}\n        {% endcall %}\n\n        {% set result = load_result('main') %}\n\n        {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n            {% set rows_inserted = result['response']['rows_affected'] %}\n        {% else %} {# older versions #}\n            {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n        {% endif %}\n\n        {% call noop_statement('main', \"BASE LOAD {}\".format(rows_inserted)) -%}\n            {{ build_sql }}\n        {%- endcall %}\n\n        -- `COMMIT` happens here\n        {% do adapter.commit() %}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {% for rel in to_drop %}\n        {% if rel.type is not none %}\n            {% do adapter.drop_relation(rel) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A materialisation designed to iterate through source data and load it in discrete periods of time, configurable by the user.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\materialisations\\materialisations_schema.yml", "arguments": []}, "macro.dbtvault.materialization_vault_insert_by_rank_default": {"unique_id": "macro.dbtvault.materialization_vault_insert_by_rank_default", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\materialisations\\vault_insert_by_rank_materialization.sql", "original_file_path": "macros\\materialisations\\vault_insert_by_rank_materialization.sql", "name": "materialization_vault_insert_by_rank_default", "macro_sql": "{% materialization vault_insert_by_rank, default -%}\n\n    {%- set full_refresh_mode = flags.FULL_REFRESH -%}\n\n    {%- set target_relation = this -%}\n    {%- set existing_relation = load_relation(this) -%}\n    {%- set tmp_relation = make_temp_relation(this) -%}\n\n    {%- set rank_column = config.require('rank_column') -%}\n    {%- set rank_source_models = config.require('rank_source_models') -%}\n\n    {%- set min_max_ranks = dbtvault.get_min_max_ranks(rank_column, rank_source_models) | as_native -%}\n\n    {%- set to_drop = [] -%}\n\n    {%- do dbtvault.check_placeholder(sql, \"__RANK_FILTER__\") -%}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% if existing_relation is none %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, 1) %}\n\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% do to_drop.append(tmp_relation) %}\n\n    {% elif existing_relation.is_view or full_refresh_mode %}\n        {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n        {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n        {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n\n        {% do adapter.drop_relation(backup_relation) %}\n        {% do adapter.rename_relation(target_relation, backup_relation) %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, 1) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% do to_drop.append(tmp_relation) %}\n        {% do to_drop.append(backup_relation) %}\n    {% else %}\n\n        {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n        {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n        {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n        {% for i in range(min_max_ranks.max_rank | int ) -%}\n\n            {%- set iteration_number = i + 1 -%}\n\n            {%- set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, iteration_number) -%}\n\n            {{ dbt_utils.log_info(\"Running for {} {} of {} on column '{}' [{}]\".format('rank', iteration_number, min_max_ranks.max_rank, rank_column, model.unique_id)) }}\n\n            {% set tmp_relation = make_temp_relation(this) %}\n\n            {% call statement() -%}\n                {{ dbt.create_table_as(True, tmp_relation, filtered_sql) }}\n            {%- endcall %}\n\n            {{ adapter.expand_target_column_types(from_relation=tmp_relation,\n                                                  to_relation=target_relation) }}\n\n            {%- set insert_query_name = 'main-' ~ i -%}\n            {% call statement(insert_query_name, fetch_result=True) -%}\n                insert into {{ target_relation }} ({{ target_cols_csv }})\n                (\n                    select {{ target_cols_csv }}\n                    from {{ tmp_relation.include(schema=True) }}\n                );\n            {%- endcall %}\n\n            {% set result = load_result(insert_query_name) %}\n\n            {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n                {% set rows_inserted = result['response']['rows_affected'] %}\n            {% else %} {# older versions #}\n                {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n            {% endif %}\n\n            {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n            {%- do loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %}\n\n            {{ dbt_utils.log_info(\"Ran for {} {} of {}; {} records inserted [{}]\".format('rank', iteration_number,\n                                                                                          min_max_ranks.max_rank,\n                                                                                          rows_inserted,\n                                                                                          model.unique_id)) }}\n\n\n            {% do to_drop.append(tmp_relation) %}\n            {% do adapter.commit() %}\n\n        {% endfor %}\n\n        {% call noop_statement('main', \"INSERT {}\".format(loop_vars['sum_rows_inserted']) ) -%}\n            {{ filtered_sql }}\n        {%- endcall %}\n\n    {% endif %}\n\n    {% if build_sql is defined %}\n        {% call statement(\"main\", fetch_result=True) %}\n            {{ build_sql }}\n        {% endcall %}\n\n        {% set result = load_result('main') %}\n\n        {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n            {% set rows_inserted = result['response']['rows_affected'] %}\n        {% else %} {# older versions #}\n            {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n        {% endif %}\n\n        {% call noop_statement('main', \"BASE LOAD {}\".format(rows_inserted)) -%}\n            {{ build_sql }}\n        {%- endcall %}\n\n        -- `COMMIT` happens here\n        {% do adapter.commit() %}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {% for rel in to_drop %}\n        {% if rel.type is not none %}\n            {% do adapter.drop_relation(rel) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.derive_columns": {"unique_id": "macro.dbtvault.derive_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\derive_columns.sql", "original_file_path": "macros\\staging\\derive_columns.sql", "name": "derive_columns", "macro_sql": "{%- macro derive_columns(source_relation=none, columns=none) -%}\n\n    {{- adapter.dispatch('derive_columns', packages = dbtvault.get_dbtvault_namespaces())(source_relation=source_relation, columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro used by the `stage` macro internally, which processes a mapping of new columns to source columns, in order to generate new columns. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#derive_columns)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_schema.yml", "arguments": [{"name": "source_relation", "type": "Relation", "description": "The source relation to extract columns from, for deriving from."}, {"name": "columns", "type": "list", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}]}, "macro.dbtvault.default__derive_columns": {"unique_id": "macro.dbtvault.default__derive_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\derive_columns.sql", "original_file_path": "macros\\staging\\derive_columns.sql", "name": "default__derive_columns", "macro_sql": "\n\n{%- macro default__derive_columns(source_relation=none, columns=none) -%}\n\n{%- set exclude_columns = [] -%}\n{%- set include_columns = [] -%}\n{%- set src_columns = [] -%}\n{%- set der_columns = [] -%}\n\n{%- set source_cols = dbtvault.source_columns(source_relation=source_relation) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {#- Add aliases of derived columns to excludes and full SQL to includes -#}\n    {%- for col in columns -%}\n        {%- if dbtvault.is_list(columns[col]) -%}\n            {%- set column_list = [] -%}\n\n            {%- for concat_component in columns[col] -%}\n                {%- set column_str = dbtvault.as_constant(concat_component) -%}\n                {%- do column_list.append(column_str) -%}\n            {%- endfor -%}\n\n            {%- set concat_string = \"CONCAT_WS(\" ~ \"'||', \" ~ column_list | join(\", \") ~ \") AS \" ~ col -%}\n\n            {%- do der_columns.append(concat_string) -%}\n            {%- set exclude_columns = exclude_columns + columns[col] -%}\n        {% else %}\n            {%- set column_str = dbtvault.as_constant(columns[col]) -%}\n            {%- do der_columns.append(column_str ~ \" AS \" ~ col) -%}\n            {%- do exclude_columns.append(col) -%}\n        {% endif %}\n\n    {%- endfor -%}\n\n    {#- Add all columns from source_model relation -#}\n    {%- if source_relation is defined and source_relation is not none -%}\n\n        {%- for col in source_cols -%}\n            {%- if col not in exclude_columns -%}\n                {%- do src_columns.append(col) -%}\n            {%- endif -%}\n        {%- endfor -%}\n\n    {%- endif -%}\n\n    {#- Makes sure the columns are appended in a logical order. Derived columns then source columns -#}\n    {%- set include_columns = src_columns + der_columns -%}\n\n    {#- Print out all columns in includes -#}\n    {%- for col in include_columns -%}\n        {{- col | indent(4) -}}{{ \",\\n\" if not loop.last }}\n    {%- endfor -%}\n\n{%- else -%}\n\n{%- if execute -%}\n{{ exceptions.raise_compiler_error(\"Invalid column configuration:\nexpected format: {'source_relation': Relation, 'columns': {column_name: column_value}}\ngot: {'source_relation': \" ~ source_relation ~ \", 'columns': \" ~ columns ~ \"}\") }}\n{%- endif %}\n\n{%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro used by the `stage` macro internally, which processes a mapping of new columns to source columns, in order to generate new columns. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#derive_columns)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_snowflake_schema.yml", "arguments": [{"name": "source_relation", "type": "Relation", "description": "The source relation to extract columns from, for deriving from."}, {"name": "columns", "type": "list", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}]}, "macro.dbtvault.derive_columns_only": {"unique_id": "macro.dbtvault.derive_columns_only", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\derive_columns_only.sql", "original_file_path": "macros\\staging\\derive_columns_only.sql", "name": "derive_columns_only", "macro_sql": "{%- macro derive_columns_only(source_relation=none, columns=none) -%}\n\n    {{- adapter.dispatch('derive_columns_only', packages = dbtvault.get_dbtvault_namespaces())(source_relation=source_relation, columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.default__derive_columns_only": {"unique_id": "macro.dbtvault.default__derive_columns_only", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\derive_columns_only.sql", "original_file_path": "macros\\staging\\derive_columns_only.sql", "name": "default__derive_columns_only", "macro_sql": "\n\n{%- macro default__derive_columns_only(source_relation=none, columns=none) -%}\n\n{%- set exclude_columns = [] -%}\n{%- set include_columns = [] -%}\n{%- set src_columns = [] -%}\n{%- set der_columns = [] -%}\n\n{%- set source_cols = dbtvault.source_columns(source_relation=source_relation) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {#- Add aliases of derived columns to excludes and full SQL to includes -#}\n    {%- for col in columns -%}\n        {%- if dbtvault.is_list(columns[col]) -%}\n            {%- set column_list = [] -%}\n\n            {%- for concat_component in columns[col] -%}\n                {%- set column_str = dbtvault.as_constant(concat_component) -%}\n                {%- do column_list.append(column_str) -%}\n            {%- endfor -%}\n\n            {%- set concat_string = \"CONCAT_WS(\" ~ \"'||', \" ~ column_list | join(\", \") ~ \") AS \" ~ col -%}\n\n            {%- do der_columns.append(concat_string) -%}\n            {%- set exclude_columns = exclude_columns + columns[col] -%}\n        {% else %}\n            {%- set column_str = dbtvault.as_constant(columns[col]) -%}\n            {%- do der_columns.append(column_str ~ \" AS \" ~ col) -%}\n            {%- do exclude_columns.append(col) -%}\n        {% endif %}\n\n    {%- endfor -%}\n\n    {#- Add all columns from source_model relation -#}\n    {%- if source_relation is defined and source_relation is not none -%}\n\n        {%- for col in source_cols -%}\n            {%- if col not in exclude_columns -%}\n                {%- do src_columns.append(col) -%}\n            {%- endif -%}\n        {%- endfor -%}\n\n    {%- endif -%}\n\n    {#- Makes sure the columns are appended in a logical order. Derived columns then source columns -#}\n    {%- set include_columns =  der_columns -%}\n\n    {#- Print out all columns in includes -#}\n    {%- for col in include_columns -%}\n        {{- col | indent(4) -}}{{ \",\\n\" if not loop.last }}\n    {%- endfor -%}\n\n{%- else -%}\n\n{%- if execute -%}\n{{ exceptions.raise_compiler_error(\"Invalid column configuration:\nexpected format: {'source_relation': Relation, 'columns': {column_name: column_value}}\ngot: {'source_relation': \" ~ source_relation ~ \", 'columns': \" ~ columns ~ \"}\") }}\n{%- endif %}\n\n{%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.hash_columns": {"unique_id": "macro.dbtvault.hash_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\hash_columns.sql", "original_file_path": "macros\\staging\\hash_columns.sql", "name": "hash_columns", "macro_sql": "{%- macro hash_columns(columns=none) -%}\n\n    {{- adapter.dispatch('hash_columns', packages = dbtvault.get_dbtvault_namespaces())(columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro used by the `stage` macro internally, which processes a mapping of hash key names to source columns, in order to generate hash keys. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#hash_columns)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}]}, "macro.dbtvault.default__hash_columns": {"unique_id": "macro.dbtvault.default__hash_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\hash_columns.sql", "original_file_path": "macros\\staging\\hash_columns.sql", "name": "default__hash_columns", "macro_sql": "\n\n{%- macro default__hash_columns(columns=none) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {%- for col in columns -%}\n\n        {% if columns[col] is mapping and columns[col].is_hashdiff -%}\n\n            {{- dbtvault.hash(columns=columns[col]['columns'], \n                              alias=col, \n                              is_hashdiff=columns[col]['is_hashdiff']) -}}\n\n        {%- elif columns[col] is not mapping -%}\n\n            {{- dbtvault.hash(columns=columns[col],\n                              alias=col,\n                              is_hashdiff=false) -}}\n        \n        {%- elif columns[col] is mapping and not columns[col].is_hashdiff -%}\n\n            {%- if execute -%}\n                {%- do exceptions.warn(\"[\" ~ this ~ \"] Warning: You provided a list of columns under a 'columns' key, but did not provide the 'is_hashdiff' flag. Use list syntax for PKs.\") -%}\n            {% endif %}\n\n            {{- dbtvault.hash(columns=columns[col]['columns'], alias=col) -}}\n\n        {%- endif -%}\n\n        {{- \",\\n\" if not loop.last -}}\n    {%- endfor -%}\n\n{%- endif %}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro used by the `stage` macro internally, which processes a mapping of hash key names to source columns, in order to generate hash keys. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#hash_columns)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_snowflake_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}]}, "macro.dbtvault.rank_columns": {"unique_id": "macro.dbtvault.rank_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\rank_columns.sql", "original_file_path": "macros\\staging\\rank_columns.sql", "name": "rank_columns", "macro_sql": "{%- macro rank_columns(columns=none) -%}\n\n    {{- adapter.dispatch('rank_columns', packages = dbtvault.get_dbtvault_namespaces())(columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.default__rank_columns": {"unique_id": "macro.dbtvault.default__rank_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\rank_columns.sql", "original_file_path": "macros\\staging\\rank_columns.sql", "name": "default__rank_columns", "macro_sql": "\n\n{%- macro default__rank_columns(columns=none) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {%- for col in columns -%}\n\n        {%- if columns[col] is mapping and columns[col].partition_by and columns[col].order_by -%}\n\n            {{- \"RANK() OVER (PARTITION BY {} ORDER BY {}) AS {}\".format(columns[col].partition_by, columns[col].order_by, col) | indent(4) -}}\n\n        {%- endif -%}\n\n        {{- \",\\n\" if not loop.last -}}\n    {%- endfor -%}\n\n{%- endif %}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.source_columns": {"unique_id": "macro.dbtvault.source_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\source_columns.sql", "original_file_path": "macros\\staging\\source_columns.sql", "name": "source_columns", "macro_sql": "{%- macro source_columns(source_relation=none) -%}\n\n    {%- if source_relation -%}\n        {%- set source_model_cols = adapter.get_columns_in_relation(source_relation) -%}\n\n        {%- set column_list = [] -%}\n\n        {%- for source_col in source_model_cols -%}\n            {%- do column_list.append(source_col.column) -%}\n        {%- endfor -%}\n\n        {%- do return(column_list) -%}\n    {%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbtvault.stage": {"unique_id": "macro.dbtvault.stage", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\stage.sql", "original_file_path": "macros\\staging\\stage.sql", "name": "stage", "macro_sql": "{%- macro stage(include_source_columns=none, source_model=none, hashed_columns=none, derived_columns=none, ranked_columns=none) -%}\n\n    {%- if include_source_columns is none -%}\n        {%- set include_source_columns = true -%}\n    {%- endif -%}\n\n    {{- adapter.dispatch('stage', packages = dbtvault.get_dbtvault_namespaces())(include_source_columns=include_source_columns,\n                                                                                 source_model=source_model,\n                                                                                 hashed_columns=hashed_columns,\n                                                                                 derived_columns=derived_columns,\n                                                                                 ranked_columns=ranked_columns) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro to aid in generating a staging layer for the raw vault. Allows users to:\n\n- Create new columns from already existing columns (Derived columns)\n- Create new hashed columns from already existing columns and provided derived columns (Hashed columns)\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#stage)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_schema.yml", "arguments": [{"name": "include_source_columns", "type": "boolean", "description": "True by default. If true, all columns included in the source model for the stage layer, will be propagated to the stage layer.\n\nIf false, only derived and hash columns (if configured) will be present in the resulting stage layer."}, {"name": "source_model", "type": "string", "description": "The dbt model name or source to build a staging layer from. Can be provided in the following formats:\n\n```\n[REF STYLE]\nsource_model: model_name\nOR\n[SOURCES STYLE]\nsource_model:\n    source_name: source_table_name\"\n```"}, {"name": "hashed_columns", "type": "Mapping", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}, {"name": "derived_columns", "type": "Mapping", "description": "A mapping of new column names to existing columns which should be hashed to create that key.\n\ne.g.\n\n```\nderived_columns:\n    NATION_KEY: 'SUPPLIER_NATION_KEY'\n    REGION_KEY: 'SUPPLIER_REGION_KEY'\n    SOURCE: '!TPCH-INVENTORY'\n```"}]}, "macro.dbtvault.default__stage": {"unique_id": "macro.dbtvault.default__stage", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\staging\\stage.sql", "original_file_path": "macros\\staging\\stage.sql", "name": "default__stage", "macro_sql": "{%- macro default__stage(include_source_columns, source_model, hashed_columns, derived_columns, ranked_columns) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{% if (source_model is none) and execute %}\n\n    {%- set error_message -%}\n    \"Staging error: Missing source_model configuration. A source model name must be provided.\n    e.g. \n    [REF STYLE]\n    source_model: model_name\n    OR\n    [SOURCES STYLE]\n    source_model:\n        source_name: source_table_name\"\n    {%- endset -%}\n\n    {{- exceptions.raise_compiler_error(error_message) -}}\n{%- endif -%}\n\n{#- Check for source format or ref format and create relation object from source_model -#}\n{% if source_model is mapping and source_model is not none -%}\n\n    {%- set source_name = source_model | first -%}\n    {%- set source_table_name = source_model[source_name] -%}\n\n    {%- set source_relation = source(source_name, source_table_name) -%}\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\n{%- elif source_model is not mapping and source_model is not none -%}\n\n    {%- set source_relation = ref(source_model) -%}\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\n{%- else -%}\n\n    {%- set all_source_columns = [] -%}\n{%- endif -%}\n\n{%- set derived_column_names = dbtvault.extract_column_names(derived_columns) -%}\n{%- set hashed_column_names = dbtvault.extract_column_names(hashed_columns) -%}\n{%- set ranked_column_names = dbtvault.extract_column_names(ranked_columns) -%}\n{%- set exclude_column_names = derived_column_names + hashed_column_names %}\n{%- set source_and_derived_column_names = all_source_columns + derived_column_names %}\n\n{%- set source_columns_to_select = dbtvault.process_columns_to_select(all_source_columns, exclude_column_names) -%}\n{%- set derived_columns_to_select = dbtvault.process_columns_to_select(source_and_derived_column_names, hashed_column_names) | unique | list -%}\n{%- set final_columns_to_select = [] -%}\n\n{#- Include source columns in final column selection if true -#}\n{%- if include_source_columns -%}\n    {%- if dbtvault.is_nothing(derived_columns)\n           and dbtvault.is_nothing(hashed_columns)\n           and dbtvault.is_nothing(ranked_columns) -%}\n        {%- set final_columns_to_select = final_columns_to_select + all_source_columns -%}\n    {%- else -%}\n        {#- Only include non-overriden columns if not just source columns -#}\n        {%- set final_columns_to_select = final_columns_to_select + source_columns_to_select -%}\n    {%- endif -%}\n{%- endif %}\n\nWITH source_data AS (\n\n    SELECT\n\n    {{- \"\\n\\n    \" ~ dbtvault.print_list(all_source_columns) if all_source_columns else \" *\" }}\n\n    FROM {{ source_relation }}\n    {%- set last_cte = \"source_data\" %}\n)\n\n{%- if dbtvault.is_something(derived_columns) -%},\n\nderived_columns AS (\n\n    SELECT\n\n    {{ dbtvault.derive_columns(source_relation=source_relation, columns=derived_columns) | indent(4) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"derived_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + derived_column_names %}\n)\n{%- endif -%}\n\n{% if dbtvault.is_something(hashed_columns) -%},\n\nhashed_columns AS (\n\n    SELECT\n\n    {{ dbtvault.print_list(derived_columns_to_select) }},\n\n    {% set processed_hash_columns = dbtvault.process_hash_column_excludes(hashed_columns, all_source_columns) -%}\n    {{- dbtvault.hash_columns(columns=processed_hash_columns) | indent(4) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"hashed_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + hashed_column_names %}\n)\n{%- endif -%}\n\n{% if dbtvault.is_something(ranked_columns) -%},\n\nranked_columns AS (\n\n    SELECT *,\n\n    {{ dbtvault.rank_columns(columns=ranked_columns) | indent(4) if dbtvault.is_something(ranked_columns) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"ranked_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + ranked_column_names %}\n)\n{%- endif -%}\n\n,\n\ncolumns_to_select AS (\n\n    SELECT\n\n    {{ dbtvault.print_list(final_columns_to_select) }}\n\n    FROM {{ last_cte }}\n)\n\nSELECT * FROM columns_to_select\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A macro to aid in generating a staging layer for the raw vault. Allows users to:\n\n- Create new columns from already existing columns (Derived columns)\n- Create new hashed columns from already existing columns and provided derived columns (Hashed columns)\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#stage)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\staging\\staging_snowflake_schema.yml", "arguments": [{"name": "include_source_columns", "type": "boolean", "description": "True by default. If true, all columns included in the source model for the stage layer, will be propagated to the stage layer.\n\nIf false, only derived and hash columns (if configured) will be present in the resulting stage layer."}, {"name": "source_model", "type": "string", "description": "The dbt model name or source to build a staging layer from. Can be provided in the following formats:\n\n```\n[REF STYLE]\nsource_model: model_name\nOR\n[SOURCES STYLE]\nsource_model:\n    source_name: source_table_name\"\n```"}, {"name": "hashed_columns", "type": "Mapping", "description": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}, {"name": "derived_columns", "type": "Mapping", "description": "A mapping of new column names to existing columns which should be hashed to create that key.\n\ne.g.\n\n```\nderived_columns:\n    NATION_KEY: 'SUPPLIER_NATION_KEY'\n    REGION_KEY: 'SUPPLIER_REGION_KEY'\n    SOURCE: '!TPCH-INVENTORY'\n```"}]}, "macro.dbtvault.hash": {"unique_id": "macro.dbtvault.hash", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\supporting\\hash.sql", "original_file_path": "macros\\supporting\\hash.sql", "name": "hash", "macro_sql": "{%- macro hash(columns=none, alias=none, is_hashdiff=false) -%}\n\n    {% if is_hashdiff is none %}\n        {%- set is_hashdiff = false -%}\n    {% endif %}\n\n    {{- adapter.dispatch('hash', packages = dbtvault.get_dbtvault_namespaces())(columns=columns, alias=alias, is_hashdiff=is_hashdiff) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Generate SQL to hash one or more columns using MD5 or SHA256. \n\nSee [How do we hash?](https://dbtvault.readthedocs.io/en/latest/best_practices/#how-do-we-hash) for an in-depth look at how dbtvault does hashing. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hash)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\supporting\\supporting_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of one or more columns to hash."}, {"name": "alias", "type": "string", "description": "The alias (name) for the new column output using the hash macro."}, {"name": "is_hashdiff", "type": "boolean", "description": "Boolean flag. If true, sort the column names in alphabetical order prior to hashing.\nThis is required for hashdiffs to ensure consistent hashing."}]}, "macro.dbtvault.default__hash": {"unique_id": "macro.dbtvault.default__hash", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\supporting\\hash.sql", "original_file_path": "macros\\supporting\\hash.sql", "name": "default__hash", "macro_sql": "\n\n{%- macro default__hash(columns, alias, is_hashdiff) -%}\n\n{%- set concat_string = \"||\" -%}\n{%- set null_placeholder_string = \"^^\" -%}\n\n{%- set hash = var('hash', 'MD5') -%}\n\n{#- Select hashing algorithm -#}\n{%- if hash == 'MD5' -%}\n    {%- set hash_alg = 'MD5_BINARY' -%}\n    {%- set hash_size = 16 -%}\n{%- elif hash == 'SHA' -%}\n    {%- set hash_alg = 'SHA2_BINARY' -%}\n    {%- set hash_size = 32 -%}\n{%- else -%}\n    {%- set hash_alg = 'MD5_BINARY' -%}\n    {%- set hash_size = 16 -%}\n{%- endif -%}\n\n{%- set standardise = \"NULLIF(UPPER(TRIM(CAST([EXPRESSION] AS VARCHAR))), '')\" %}\n\n{#- Alpha sort columns before hashing if a hashdiff -#}\n{%- if is_hashdiff and dbtvault.is_list(columns) -%}\n    {%- set columns = columns|sort -%}\n{%- endif -%}\n\n{#- If single column to hash -#}\n{%- if columns is string -%}\n    {%- set column_str = dbtvault.as_constant(columns) -%}\n    {{- \"CAST(({}({})) AS BINARY({})) AS {}\".format(hash_alg, standardise | replace('[EXPRESSION]', column_str), hash_size, alias) | indent(4) -}}\n\n{#- Else a list of columns to hash -#}\n{%- else -%}\n    {%- set all_null = [] -%}\n\n    {%- if is_hashdiff -%}\n        {{- \"CAST({}(CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- else -%}\n        {{- \"CAST({}(NULLIF(CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- endif -%}\n\n    {%- for column in columns -%}\n\n        {%- do all_null.append(null_placeholder_string) -%}\n\n        {%- set column_str = dbtvault.as_constant(column) -%}\n        {{- \"\\nIFNULL({}, '{}')\".format(standardise | replace('[EXPRESSION]', column_str), null_placeholder_string) | indent(4) -}}\n        {{- \",\" if not loop.last -}}\n\n        {%- if loop.last -%}\n\n            {% if is_hashdiff %}\n                {{- \"\\n)) AS BINARY({})) AS {}\".format(hash_size, alias) -}}\n            {%- else -%}\n                {{- \"\\n), '{}')) AS BINARY({})) AS {}\".format(all_null | join(\"\"), hash_size, alias) -}}\n            {%- endif -%}\n        {%- else -%}\n\n            {%- do all_null.append(concat_string) -%}\n\n        {%- endif -%}\n\n    {%- endfor -%}\n\n{%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Generate SQL to hash one or more columns using MD5 or SHA256. \n\nSee [How do we hash?](https://dbtvault.readthedocs.io/en/latest/best_practices/#how-do-we-hash) for an in-depth look at how dbtvault does hashing. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hash)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\supporting\\supporting_snowflake_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of one or more columns to hash."}, {"name": "alias", "type": "string", "description": "The alias (name) for the new column output using the hash macro."}, {"name": "is_hashdiff", "type": "boolean", "description": "Boolean flag. If true, sort the column names in alphabetical order prior to hashing.\nThis is required for hashdiffs to ensure consistent hashing."}]}, "macro.dbtvault.prefix": {"unique_id": "macro.dbtvault.prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\supporting\\prefix.sql", "original_file_path": "macros\\supporting\\prefix.sql", "name": "prefix", "macro_sql": "{%- macro prefix(columns, prefix_str, alias_target) -%}\n\n    {{- adapter.dispatch('prefix', packages = dbtvault.get_dbtvault_namespaces())(columns=columns,\n                                                                         prefix_str=prefix_str,\n                                                                         alias_target=alias_target) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Prefix one or more strings with a given string and print each one.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#prefix)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\supporting\\supporting_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of columns (string or mapping) to prefix.\n\nIf a column is specified using an alias mapping as follows:\n\n{'source_column': <'column name'>, 'alias': <'alias string'>}\n\nThen it will also be aliased using `AS <column name>`."}, {"name": "prefix_str", "type": "string", "description": "The string to prepend to each column/string."}, {"name": "alias_target", "type": "source | target", "description": "Switch the aliasing target. `source` by default.\n\nIf a column is specified using an alias mapping as follows:\n\n`{'source_column': <'column name'>, 'alias': <'alias string'>}`\n\nThen it will also be aliased using `AS <column name>`.\n\nHowever, if the `alias_target` is `target` instead of `source`, the column will be rendered as follows:\n\n`AS <alias string>`"}]}, "macro.dbtvault.default__prefix": {"unique_id": "macro.dbtvault.default__prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\supporting\\prefix.sql", "original_file_path": "macros\\supporting\\prefix.sql", "name": "default__prefix", "macro_sql": "{%- macro default__prefix(columns=none, prefix_str=none, alias_target='source') -%}\n\n    {%- if columns and prefix_str -%}\n\n        {%- for col in columns -%}\n\n            {%- if col is mapping -%}\n\n                {%- if alias_target == 'source' -%}\n\n                    {{- dbtvault.prefix([col['source_column']], prefix_str) -}}\n\n                {%- elif alias_target == 'target' -%}\n\n                    {{- dbtvault.prefix([col['alias']], prefix_str) -}}\n\n                {%- else -%}\n\n                    {{- dbtvault.prefix([col['source_column']], prefix_str) -}}\n\n                {%- endif -%}\n\n                {%- if not loop.last -%} , {% endif %}\n\n            {%- else -%}\n\n                {%- if col is iterable and col is not string -%}\n\n                    {{- dbtvault.prefix(col, prefix_str) -}}\n\n                {%- elif col is not none -%}\n\n                    {{- prefix_str}}.{{col.strip() -}}\n                {% else %}\n\n                    {%- if execute -%}\n                        {{- exceptions.raise_compiler_error(\"Unexpected or missing configuration for '\" ~ this ~ \"' Unable to prefix columns.\") -}}\n                    {%- endif -%}\n                {%- endif -%}\n\n                {{- ', ' if not loop.last -}}\n\n            {%- endif -%}\n\n        {%- endfor -%}\n\n    {%- else -%}\n\n        {%- if execute -%}\n            {{- exceptions.raise_compiler_error(\"Invalid parameters provided to prefix macro. Expected: (columns [list/string], prefix_str [string]) got: (\" ~ columns ~ \", \" ~ prefix_str ~ \")\") -}}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Prefix one or more strings with a given string and print each one.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#prefix)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\supporting\\supporting_snowflake_schema.yml", "arguments": [{"name": "columns", "type": "list", "description": "A list of columns (string or mapping) to prefix.\n\nIf a column is specified using an alias mapping as follows:\n\n{'source_column': <'column name'>, 'alias': <'alias string'>}\n\nThen it will also be aliased using `AS <column name>`."}, {"name": "prefix_str", "type": "string", "description": "The string to prepend to each column/string."}, {"name": "alias_target", "type": "source | target", "description": "Switch the aliasing target. `source` by default.\n\nIf a column is specified using an alias mapping as follows:\n\n`{'source_column': <'column name'>, 'alias': <'alias string'>}`\n\nThen it will also be aliased using `AS <column name>`.\n\nHowever, if the `alias_target` is `target` instead of `source`, the column will be rendered as follows:\n\n`AS <alias string>`"}]}, "macro.dbtvault.eff_sat": {"unique_id": "macro.dbtvault.eff_sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\eff_sat.sql", "original_file_path": "macros\\tables\\eff_sat.sql", "name": "eff_sat", "macro_sql": "{%- macro eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('eff_sat', packages = dbtvault.get_dbtvault_namespaces())(src_pk=src_pk, src_dfk=src_dfk, src_sfk=src_sfk,\n                                                                                   src_start_date=src_start_date, src_end_date=src_end_date,\n                                                                                   src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                                                                   source_model=source_model) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "An Effectivity Satellite keeps track of the effective dates of relationships contained in links. \nIf a relationship changes (for example, a Customer moves country, changing a customer and nation relation) \nthen an effectivity satellite will record this change as a new entry, and when it happened. \n\nWhen a new relationship is loaded from the source, a new record will be created with the new relation and an open end date (the max date, `9999-12-31`).\nIf auto end-dating is enabled and a relationship changes which is already recorded in the effectivity satellite, then effectivity satellites in dbtvault will \nautomatically create a record as a copy of the old record. This record will be created with the effective date of the new relation. \n\nIf auto end-dating is not enabled, a new record with open end date will still be created, but additional business rules will need to be applied to work out the \nend dates manually. This may be useful when there is external business logic which describes under what situations a relationship is considered effective or not. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#eff_sat)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_dfk", "type": "list/string", "description": ""}, {"name": "src_sfk", "type": "list/string", "description": ""}, {"name": "src_start_date", "type": "string", "description": ""}, {"name": "src_end_date", "type": "string", "description": ""}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.default__eff_sat": {"unique_id": "macro.dbtvault.default__eff_sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\eff_sat.sql", "original_file_path": "macros\\tables\\eff_sat.sql", "name": "default__eff_sat", "macro_sql": "{%- macro default__eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list(columns=[src_dfk, src_sfk]) -%}\n{%- set is_auto_end_dating = config.get('is_auto_end_dating', default=false) %}\n\n{{- dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    SELECT *\n    FROM {{ ref(source_model) }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    WHERE __PERIOD_FILTER__\n    {% endif %}\n    {%- set source_cte = \"source_data\" %}\n),\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\nrank_col AS (\n    SELECT * FROM source_data\n    WHERE __RANK_FILTER__\n    {%- set source_cte = \"rank_col\" %}\n),\n{% endif -%}\n\n{%- if load_relation(this) is none %}\n\nrecords_to_insert AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'e') }}\n    FROM {{ source_cte }} AS e\n)\n{%- else %}\n\nlatest_open_eff AS\n(\n    SELECT {{ dbtvault.alias_all(source_cols, 'b') }},\n           ROW_NUMBER() OVER (\n                PARTITION BY b.{{ src_pk }}\n                ORDER BY b.{{ src_ldts }} DESC\n           ) AS row_number\n    FROM {{ this }} AS b\n    WHERE TO_DATE(b.{{ src_end_date }}) = TO_DATE('9999-12-31')\n    QUALIFY row_number = 1\n),\n\nstage_slice AS\n(\n    SELECT {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM {{ \"rank_col\" if model.config.materialized == 'vault_insert_by_rank' else \"source_data\" }} AS stage\n),\n\nnew_open_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM stage_slice AS stage\n    LEFT JOIN latest_open_eff AS e\n    ON stage.{{ src_pk }} = e.{{ src_pk }}\n    WHERE e.{{ src_pk }} IS NULL\n    AND {{ dbtvault.multikey(src_dfk, prefix='stage', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_sfk, prefix='stage', condition='IS NOT NULL') }}\n),\n{%- if is_auto_end_dating %}\n\nlinks_to_end_date AS (\n    SELECT a.*\n    FROM latest_open_eff AS a\n    LEFT JOIN stage_slice AS b\n    ON {{ dbtvault.multikey(src_dfk, prefix=['a', 'b'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_sfk, prefix='b', condition='IS NULL', operator='OR') }}\n    OR {{ dbtvault.multikey(src_sfk, prefix=['a', 'b'], condition='<>', operator='OR') }}\n),\n\nnew_end_dated_records AS (\n    SELECT DISTINCT\n        h.{{ src_pk }},\n        {{ dbtvault.alias_all(fk_cols, 'g') }},\n        h.EFFECTIVE_FROM AS {{ src_start_date }}, h.{{ src_source }}\n    FROM latest_open_eff AS h\n    INNER JOIN links_to_end_date AS g\n    ON g.{{ src_pk }} = h.{{ src_pk }}\n),\n\namended_end_dated_records AS (\n    SELECT DISTINCT\n        a.{{ src_pk }},\n        {{ dbtvault.alias_all(fk_cols, 'a') }},\n        a.{{ src_start_date }},\n        stage.{{ src_eff }} AS END_DATE, stage.{{ src_eff }}, stage.{{ src_ldts }},\n        a.{{ src_source }}\n    FROM new_end_dated_records AS a\n    INNER JOIN stage_slice AS stage\n    ON {{ dbtvault.multikey(src_dfk, prefix=['stage', 'a'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_sfk, prefix='stage', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_dfk, prefix='stage', condition='IS NOT NULL') }}\n),\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT * FROM new_open_records\n    {%- if is_auto_end_dating %}\n    UNION\n    SELECT * FROM amended_end_dated_records\n    {%- endif %}\n)\n{%- endif %}\n\nSELECT * FROM records_to_insert\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "An Effectivity Satellite keeps track of the effective dates of relationships contained in links. \nIf a relationship changes (for example, a Customer moves country, changing a customer and nation relation) \nthen an effectivity satellite will record this change as a new entry, and when it happened. \n\nWhen a new relationship is loaded from the source, a new record will be created with the new relation and an open end date (the max date, `9999-12-31`).\nIf auto end-dating is enabled and a relationship changes which is already recorded in the effectivity satellite, then effectivity satellites in dbtvault will \nautomatically create a record as a copy of the old record. This record will be created with the effective date of the new relation. \n\nIf auto end-dating is not enabled, a new record with open end date will still be created, but additional business rules will need to be applied to work out the \nend dates manually. This may be useful when there is external business logic which describes under what situations a relationship is considered effective or not. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#eff_sat)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_snowflake_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_dfk", "type": "list/string", "description": ""}, {"name": "src_sfk", "type": "list/string", "description": ""}, {"name": "src_start_date", "type": "string", "description": ""}, {"name": "src_end_date", "type": "string", "description": ""}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.hub": {"unique_id": "macro.dbtvault.hub", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\hub.sql", "original_file_path": "macros\\tables\\hub.sql", "name": "hub", "macro_sql": "{%- macro hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('hub', packages = dbtvault.get_dbtvault_namespaces())(src_pk=src_pk, src_nk=src_nk,\n                                                                               src_ldts=src_ldts, src_source=src_source,\n                                                                               source_model=source_model) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Hub contains a distinct set of keys for a given top-level business concept, for example a `HUB_CUSTOMER` hub may contain a distinct list\nof Customer IDs. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hub)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_nk", "type": "mapping/string", "description": "The column used as the natural or business key of the table. This must be the non-hashed version of the column used for the `src_pk`."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.default__hub": {"unique_id": "macro.dbtvault.default__hub", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\hub.sql", "original_file_path": "macros\\tables\\hub.sql", "name": "default__hub", "macro_sql": "{%- macro default__hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_nk, src_ldts, src_source]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ source_cols_with_rank | join(', ') }},\n    {%- else %}\n    SELECT {{ source_cols | join(', ') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ src_pk }}\n               ORDER BY {{ src_ldts }} ASC\n           ) AS row_number\n    FROM {{ ref(src) }}\n    QUALIFY row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- endif -%}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ src_pk }}\n               ORDER BY {{ src_ldts }}, {{ src_source }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }}\n    WHERE {{ src_pk }} IS NOT NULL\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_vault_insert_by_period() or is_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON a.{{ src_pk }} = d.{{ src_pk }}\n    WHERE {{ dbtvault.prefix([src_pk], 'd') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Hub contains a distinct set of keys for a given top-level business concept, for example a `HUB_CUSTOMER` hub may contain a distinct list\nof Customer IDs. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hub)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_snowflake_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_nk", "type": "mapping/string", "description": "The column used as the natural or business key of the table. This must be the non-hashed version of the column used for the `src_pk`."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.link": {"unique_id": "macro.dbtvault.link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\link.sql", "original_file_path": "macros\\tables\\link.sql", "name": "link", "macro_sql": "{%- macro link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('link', packages = dbtvault.get_dbtvault_namespaces())(src_pk=src_pk, src_fk=src_fk,\n                                                                                src_ldts=src_ldts, src_source=src_source,\n                                                                                source_model=source_model) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Link contains a distinct set of relationships between top-level business concepts. \nThese structures 'link' hubs together based on a business relationship between the two.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#link)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_fk", "type": "mapping/string", "description": "A single column or list of columns which are the primary key columns of other, related tables. Used in links to shows hubs associated with the link."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.default__link": {"unique_id": "macro.dbtvault.default__link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\link.sql", "original_file_path": "macros\\tables\\link.sql", "name": "default__link", "macro_sql": "{%- macro default__link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ source_cols_with_rank | join(', ') }},\n    {%- else %}\n    SELECT {{ source_cols | join(', ') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ src_pk }}\n               ORDER BY {{ src_ldts }} ASC\n           ) AS row_number\n    FROM {{ ref(src) }}\n    QUALIFY row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{% endif %}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ src_pk }}\n               ORDER BY {{ src_ldts }}, {{ src_source }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }}\n    WHERE {{ dbtvault.multikey(fk_cols, condition='IS NOT NULL') }}\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_vault_insert_by_period() or is_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON a.{{ src_pk }} = d.{{ src_pk }}\n    WHERE {{ dbtvault.prefix([src_pk], 'd') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Link contains a distinct set of relationships between top-level business concepts. \nThese structures 'link' hubs together based on a business relationship between the two.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#link)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_snowflake_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_fk", "type": "mapping/string", "description": "A single column or list of columns which are the primary key columns of other, related tables. Used in links to shows hubs associated with the link."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.sat": {"unique_id": "macro.dbtvault.sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\sat.sql", "original_file_path": "macros\\tables\\sat.sql", "name": "sat", "macro_sql": "{%- macro sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('sat', packages = dbtvault.get_dbtvault_namespaces())(src_pk=src_pk, src_hashdiff=src_hashdiff,\n                                                                               src_payload=src_payload, src_eff=src_eff, src_ldts=src_ldts,\n                                                                               src_source=src_source, source_model=source_model) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Satellite contains records corresponding to Hub or Link records which provide concrete attributes for those records. For example a `SAT_CUSTOMER_DETAILS` Satellite\nwould contain details about the customer, by using the same primary key as the corresponding hub record. \nThe payload for this example may contain `CUSTOMER_DOB`, `CUSTOMER_GIVEN_NAME`, `CUSTOMER_SURNAME` columns.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#sat)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_hashdiff", "type": "string", "description": "A column which contains a single hash, composed of a list of columns and alpha-sorted. A hashdiff is used as a kind of checksum, to detect changes in records. \nIf any of the columns which form the hashdiff change their value, then the hashdiff itself will change. This is used in satellites to detect changes in the payload."}, {"name": "src_payload", "type": "string", "description": "A list or single list of columns which contains the payload of the satellite. \nA satellite payload should contain the concrete attributes for entity descried in the corresponding hub record."}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.default__sat": {"unique_id": "macro.dbtvault.default__sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\sat.sql", "original_file_path": "macros\\tables\\sat.sql", "name": "default__sat", "macro_sql": "\n\n{%- macro default__sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'a', alias_target='source') }}\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS a\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    WHERE __PERIOD_FILTER__\n    {% endif %}\n    {%- set source_cte = \"source_data\" %}\n),\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\nrank_col AS (\n    SELECT * FROM source_data\n    WHERE __RANK_FILTER__\n    {%- set source_cte = \"rank_col\" %}\n),\n{% endif -%}\n\n{% if dbtvault.is_vault_insert_by_period() or dbtvault.is_vault_insert_by_rank() or is_incremental() %}\n\nupdate_records AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ this }} as a\n    JOIN source_data as b\n    ON a.{{ src_pk }} = b.{{ src_pk }}\n),\n\nlatest_records AS (\n    SELECT {{ dbtvault.prefix(rank_cols, 'c', alias_target='target') }},\n           CASE WHEN RANK()\n           OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'c') }}\n           ORDER BY {{ dbtvault.prefix([src_ldts], 'c') }} DESC) = 1\n    THEN 'Y' ELSE 'N' END AS latest\n    FROM update_records as c\n    QUALIFY latest = 'Y'\n),\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.alias_all(source_cols, 'e') }}\n    FROM {{ source_cte }} AS e\n    {%- if dbtvault.is_vault_insert_by_period() or dbtvault.is_vault_insert_by_rank() or is_incremental() %}\n    LEFT JOIN latest_records\n    ON {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} = {{ dbtvault.prefix([src_hashdiff], 'e') }}\n    WHERE {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A Satellite contains records corresponding to Hub or Link records which provide concrete attributes for those records. For example a `SAT_CUSTOMER_DETAILS` Satellite\nwould contain details about the customer, by using the same primary key as the corresponding hub record. \nThe payload for this example may contain `CUSTOMER_DOB`, `CUSTOMER_GIVEN_NAME`, `CUSTOMER_SURNAME` columns.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#sat)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_snowflake_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_hashdiff", "type": "string", "description": "A column which contains a single hash, composed of a list of columns and alpha-sorted. A hashdiff is used as a kind of checksum, to detect changes in records. \nIf any of the columns which form the hashdiff change their value, then the hashdiff itself will change. This is used in satellites to detect changes in the payload."}, {"name": "src_payload", "type": "string", "description": "A list or single list of columns which contains the payload of the satellite. \nA satellite payload should contain the concrete attributes for entity descried in the corresponding hub record."}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.t_link": {"unique_id": "macro.dbtvault.t_link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\t_link.sql", "original_file_path": "macros\\tables\\t_link.sql", "name": "t_link", "macro_sql": "{%- macro t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('t_link', packages = dbtvault.get_dbtvault_namespaces())(src_pk=src_pk, src_fk=src_fk, src_payload=src_payload,\n                                                                                  src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                                                                  source_model=source_model) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A transactional link is an immutable list of transaction records. By definition transactions are never modified:\nif a transaction needs to be updated, then a new transaction occurs. Transactional links contain a payload of columns which contain\ndetails about the transaction, usually consisting of payments, location, type and more. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#t_link)", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_fk", "type": "mapping/string", "description": "A single column or list of columns which are the primary key columns of other, related tables. Used in links to shows hubs associated with the link."}, {"name": "src_payload", "type": "string", "description": "A list or single list of columns which contains the payload of the t-link. \nA t-link payload should contain the transactional/event attributes for entity descried in the corresponding hub record."}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbtvault.default__t_link": {"unique_id": "macro.dbtvault.default__t_link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "macros\\tables\\t_link.sql", "original_file_path": "macros\\tables\\t_link.sql", "name": "default__t_link", "macro_sql": "\n\n{%- macro default__t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_payload, src_eff, src_ldts, src_source]) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH stage AS (\n    SELECT {{ source_cols | join(', ') }}\n    FROM {{ ref(source_model) }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    WHERE __PERIOD_FILTER__\n    {%- endif %}\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    WHERE __RANK_FILTER__\n    {%- endif %}\n),\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols, 'stg') }}\n    FROM stage AS stg\n    {% if is_incremental() -%}\n    LEFT JOIN {{ this }} AS tgt\n    ON {{ dbtvault.prefix([src_pk], 'stg') }} = {{ dbtvault.prefix([src_pk], 'tgt') }}\n    WHERE {{ dbtvault.prefix([src_pk], 'tgt') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "A transactional link is an immutable list of transaction records. By definition transactions are never modified:\nif a transaction needs to be updated, then a new transaction occurs. Transactional links contain a payload of columns which contain\ndetails about the transaction, usually consisting of payments, location, type and more. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#t_link)\n\nSnowflake implementation", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\tables\\tables_snowflake_schema.yml", "arguments": [{"name": "src_pk", "type": "mapping/string", "description": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, {"name": "src_fk", "type": "mapping/string", "description": "A single column or list of columns which are the primary key columns of other, related tables. Used in links to shows hubs associated with the link."}, {"name": "src_payload", "type": "string", "description": "A list or single list of columns which contains the payload of the t-link. \nA t-link payload should contain the transactional/event attributes for entity descried in the corresponding hub record."}, {"name": "src_eff", "type": "string", "description": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, {"name": "src_ldts", "type": "string", "description": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, {"name": "src_source", "type": "string", "description": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, {"name": "source_model", "type": "string", "description": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}]}, "macro.dbt_utils.concat": {"unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', packages = dbt_utils._get_utils_namespaces())(fields)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__concat": {"unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.alternative_concat": {"unique_id": "macro.dbt_utils.alternative_concat", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "alternative_concat", "macro_sql": "{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__concat": {"unique_id": "macro.dbt_utils.redshift__concat", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "redshift__concat", "macro_sql": "{% macro redshift__concat(fields) %}\n    {{ dbt_utils.alternative_concat(fields) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__concat": {"unique_id": "macro.dbt_utils.snowflake__concat", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "snowflake__concat", "macro_sql": "{% macro snowflake__concat(fields) %}\n    {{ dbt_utils.alternative_concat(fields) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp": {"unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ return(adapter.dispatch('current_timestamp', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp": {"unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__current_timestamp": {"unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__current_timestamp": {"unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\n  {{ return(adapter.dispatch('current_timestamp_in_utc', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_string": {"unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_string": {"unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\n    string\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__type_string": {"unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "redshift__type_string", "macro_sql": "\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__type_string": {"unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_string": {"unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_timestamp": {"unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_timestamp": {"unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_timestamp": {"unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_float": {"unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_float": {"unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\n    float\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_float": {"unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_numeric": {"unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_numeric": {"unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_numeric": {"unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_bigint": {"unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_bigint": {"unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_bigint": {"unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_int": {"unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', packages = dbt_utils._get_utils_namespaces())()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_int": {"unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\n    int\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_int": {"unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.dateadd": {"unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', packages = dbt_utils._get_utils_namespaces())(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__dateadd": {"unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__dateadd": {"unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__dateadd": {"unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.datediff": {"unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', packages = dbt_utils._get_utils_namespaces())(first_date, second_date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__datediff": {"unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__datediff": {"unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__datediff": {"unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_trunc": {"unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', packages = dbt_utils._get_utils_namespaces()) (datepart, date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__date_trunc": {"unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__date_trunc": {"unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.except": {"unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', packages = dbt_utils._get_utils_namespaces())()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__except": {"unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__except": {"unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.hash": {"unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', packages = dbt_utils._get_utils_namespaces()) (field)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__hash": {"unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__hash": {"unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.identifier": {"unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\t\n  {%- set error_message = '\n    Warning: the `identifier` macro is no longer supported and will be deprecated in a future release of dbt-utils. \\\n    Use `adapter.quote` instead. The {}.{} model triggered this warning. \\\n    '.format(model.package_name, model.name) -%}\n  {%- do exceptions.warn(error_message) -%}\n  {{ return(adapter.dispatch('identifier', packages = dbt_utils._get_utils_namespaces()) (value)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__identifier": {"unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\t\n    \"{{ value }}\"\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__identifier": {"unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\t\n    `{{ value }}`\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.intersect": {"unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', packages = dbt_utils._get_utils_namespaces())()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__intersect": {"unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__intersect": {"unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.last_day": {"unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', packages = dbt_utils._get_utils_namespaces()) (date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default_last_day": {"unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "default_last_day", "macro_sql": "\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__last_day": {"unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__last_day": {"unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.length": {"unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', packages = dbt_utils._get_utils_namespaces()) (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__length": {"unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__length": {"unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.string_literal": {"unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\literal.sql", "original_file_path": "macros\\cross_db_utils\\literal.sql", "name": "string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', packages = dbt_utils._get_utils_namespaces()) (value)) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__string_literal": {"unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\literal.sql", "original_file_path": "macros\\cross_db_utils\\literal.sql", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.position": {"unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', packages = dbt_utils._get_utils_namespaces()) (substring_text, string_text)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__position": {"unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__position": {"unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.replace": {"unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\replace.sql", "original_file_path": "macros\\cross_db_utils\\replace.sql", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', packages = dbt_utils._get_utils_namespaces()) (field, old_chars, new_chars)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__replace": {"unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\replace.sql", "original_file_path": "macros\\cross_db_utils\\replace.sql", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.right": {"unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', packages = dbt_utils._get_utils_namespaces()) (string_text, length_expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__right": {"unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__right": {"unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__right": {"unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_cast": {"unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', packages = dbt_utils._get_utils_namespaces()) (field, type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__safe_cast": {"unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__safe_cast": {"unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__safe_cast": {"unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.split_part": {"unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', packages = dbt_utils._get_utils_namespaces()) (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__split_part": {"unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__split_part": {"unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.width_bucket": {"unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ return(adapter.dispatch('width_bucket', packages = dbt_utils._get_utils_namespaces()) (expr, min_value, max_value, num_buckets)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__width_bucket": {"unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__width_bucket": {"unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__width_bucket": {"unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._get_utils_namespaces": {"unique_id": "macro.dbt_utils._get_utils_namespaces", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_get_utils_namespaces.sql", "original_file_path": "macros\\cross_db_utils\\_get_utils_namespaces.sql", "name": "_get_utils_namespaces", "macro_sql": "{% macro _get_utils_namespaces() %}\n  {% set override_namespaces = var('dbt_utils_dispatch_list', []) %}\n  {% do return(override_namespaces + ['dbt_utils']) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_ephemeral": {"unique_id": "macro.dbt_utils._is_ephemeral", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_is_ephemeral.sql", "original_file_path": "macros\\cross_db_utils\\_is_ephemeral.sql", "name": "_is_ephemeral", "macro_sql": "{% macro _is_ephemeral(obj, macro) %}\n    {%- if obj.is_cte -%}\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\n        {% if obj.name.startswith(ephemeral_prefix) %}\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\n        {% else %}\n            {% set model_name = obj.name %}\n        {%- endif -%}\n        {% set error_message %}\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\n\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\n        {% endset %}\n        {%- do exceptions.raise_compiler_error(error_message) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_relation": {"unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_is_relation.sql", "original_file_path": "macros\\cross_db_utils\\_is_relation.sql", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_intervals_between": {"unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', packages = dbt_utils._get_utils_namespaces())(start_date, end_date, datepart)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_intervals_between": {"unique_id": "macro.dbt_utils.default__get_intervals_between", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "default__get_intervals_between", "macro_sql": "{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_spine": {"unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', packages = dbt_utils._get_utils_namespaces())(datepart, start_date, end_date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__date_spine": {"unique_id": "macro.dbt_utils.default__date_spine", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "default__date_spine", "macro_sql": "{% macro default__date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.haversine_distance": {"unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\geo\\haversine_distance.sql", "original_file_path": "macros\\geo\\haversine_distance.sql", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\n    {{ return(adapter.dispatch('haversine_distance', packages = dbt_utils._get_utils_namespaces())(lat1,lon1,lat2,lon2)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__haversine_distance": {"unique_id": "macro.dbt_utils.default__haversine_distance", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\geo\\haversine_distance.sql", "original_file_path": "macros\\geo\\haversine_distance.sql", "name": "default__haversine_distance", "macro_sql": "{% macro default__haversine_distance(lat1,lon1,lat2,lon2) -%}\n\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.log_info": {"unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\log_info.sql", "original_file_path": "macros\\logger\\log_info.sql", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\n    {{ return(adapter.dispatch('log_info', packages = dbt_utils._get_utils_namespaces())(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__log_info": {"unique_id": "macro.dbt_utils.default__log_info", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\log_info.sql", "original_file_path": "macros\\logger\\log_info.sql", "name": "default__log_info", "macro_sql": "{% macro default__log_info(message) %}\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_log_format": {"unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_log_format.sql", "original_file_path": "macros\\logger\\pretty_log_format.sql", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\n    {{ return(adapter.dispatch('pretty_log_format', packages = dbt_utils._get_utils_namespaces())(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__pretty_log_format": {"unique_id": "macro.dbt_utils.default__pretty_log_format", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_log_format.sql", "original_file_path": "macros\\logger\\pretty_log_format.sql", "name": "default__pretty_log_format", "macro_sql": "{% macro default__pretty_log_format(message) %}\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_time": {"unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_time.sql", "original_file_path": "macros\\logger\\pretty_time.sql", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n    {{ return(adapter.dispatch('pretty_time', packages = dbt_utils._get_utils_namespaces())(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__pretty_time": {"unique_id": "macro.dbt_utils.default__pretty_time", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_time.sql", "original_file_path": "macros\\logger\\pretty_time.sql", "name": "default__pretty_time", "macro_sql": "{% macro default__pretty_time(format='%H:%M:%S') %}\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_boundaries": {"unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n    {{ return(adapter.dispatch('get_period_boundaries', packages = dbt_utils._get_utils_namespaces())(target_schema, target_table, timestamp_field, start_date, stop_date, period)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_period_boundaries": {"unique_id": "macro.dbt_utils.default__get_period_boundaries", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "default__get_period_boundaries", "macro_sql": "{% macro default__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_sql": {"unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n    {{ return(adapter.dispatch('get_period_sql', packages = dbt_utils._get_utils_namespaces())(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_period_sql": {"unique_id": "macro.dbt_utils.default__get_period_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "default__get_period_sql", "macro_sql": "{% macro default__get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.materialization_insert_by_period_default": {"unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {% set result = load_result('main-' ~ i) %}\n    {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n        {% set rows_inserted = result['response']['rows_affected'] %}\n    {% else %} {# older versions #}\n        {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n    {% endif %}\n    \n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement('main', status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n  -- Return the relations created in this materialization\n  {{ return({'relations': [target_relation]}) }}  \n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_at_least_one": {"unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\at_least_one.sql", "original_file_path": "macros\\schema_tests\\at_least_one.sql", "name": "test_at_least_one", "macro_sql": "{% macro test_at_least_one(model) %}\n  {{ return(adapter.dispatch('test_at_least_one', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_at_least_one": {"unique_id": "macro.dbt_utils.default__test_at_least_one", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\at_least_one.sql", "original_file_path": "macros\\schema_tests\\at_least_one.sql", "name": "default__test_at_least_one", "macro_sql": "{% macro default__test_at_least_one(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n    select\n        {# In TSQL, subquery aggregate columns need aliases #}\n        {# thus: a filler col name, 'filler_column' #}\n      count({{ column_name }}) as filler_column\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_cardinality_equality": {"unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\cardinality_equality.sql", "original_file_path": "macros\\schema_tests\\cardinality_equality.sql", "name": "test_cardinality_equality", "macro_sql": "{% macro test_cardinality_equality(model, to, field) %}\n\n    {{ return(adapter.dispatch('test_cardinality_equality', packages = dbt_utils._get_utils_namespaces())(model, to, field, **kwargs)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_cardinality_equality": {"unique_id": "macro.dbt_utils.default__test_cardinality_equality", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\cardinality_equality.sql", "original_file_path": "macros\\schema_tests\\cardinality_equality.sql", "name": "default__test_cardinality_equality", "macro_sql": "{% macro default__test_cardinality_equality(model, to, field) %}\n\n{# T-SQL doesn't let you use numbers as aliases for columns #}\n{# Thus, no \"GROUP BY 1\" #}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by {{ column_name }}\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by {{ column_name }}\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect count(*)\nfrom unioned\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equality": {"unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equality.sql", "original_file_path": "macros\\schema_tests\\equality.sql", "name": "test_equality", "macro_sql": "{% macro test_equality(model) %}\n  {{ return(adapter.dispatch('test_equality', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_equality": {"unique_id": "macro.dbt_utils.default__test_equality", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equality.sql", "original_file_path": "macros\\schema_tests\\equality.sql", "name": "default__test_equality", "macro_sql": "{% macro default__test_equality(model) %}\n\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n\n{#-\nIf the compare_cols arg is provided, we can run this test without querying the\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\n-#}\n{%- set compare_columns = kwargs.get('compare_columns', None) -%}\n\n{%- if not compare_columns -%}\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality') -%}\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\n{%- endif -%}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equal_rowcount": {"unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equal_rowcount.sql", "original_file_path": "macros\\schema_tests\\equal_rowcount.sql", "name": "test_equal_rowcount", "macro_sql": "{% macro test_equal_rowcount(model) %}\n  {{ return(adapter.dispatch('test_equal_rowcount', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_equal_rowcount": {"unique_id": "macro.dbt_utils.default__test_equal_rowcount", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equal_rowcount.sql", "original_file_path": "macros\\schema_tests\\equal_rowcount.sql", "name": "default__test_equal_rowcount", "macro_sql": "{% macro default__test_equal_rowcount(model) %}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select abs(\n            (select count_a from a) -\n            (select count_b from b)\n            )\n        as diff_count\n\n)\n\nselect diff_count from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_expression_is_true": {"unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\expression_is_true.sql", "original_file_path": "macros\\schema_tests\\expression_is_true.sql", "name": "test_expression_is_true", "macro_sql": "{% macro test_expression_is_true(model, condition='1=1') %}\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n  {{ return(adapter.dispatch('test_expression_is_true', packages = dbt_utils._get_utils_namespaces())(model, condition, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_expression_is_true": {"unique_id": "macro.dbt_utils.default__test_expression_is_true", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\expression_is_true.sql", "original_file_path": "macros\\schema_tests\\expression_is_true.sql", "name": "default__test_expression_is_true", "macro_sql": "{% macro default__test_expression_is_true(model, condition) %}\n\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\n\nwith meet_condition as (\n\n    select * from {{ model }} where {{ condition }}\n\n),\nvalidation_errors as (\n\n    select\n        *\n    from meet_condition\n    where not({{expression}})\n\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "original_file_path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n  {{ return(adapter.dispatch('test_mutually_exclusive_ranges', packages = dbt_utils._get_utils_namespaces())(model, lower_bound_column, upper_bound_column, partition_by, gaps)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.default__test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "original_file_path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "name": "default__test_mutually_exclusive_ranges", "macro_sql": "{% macro default__test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }},\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound < upper_bound,\n            false\n        ) as lower_bound_less_than_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_less_than_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect count(*) from validation_errors\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_constant": {"unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\not_constant.sql", "original_file_path": "macros\\schema_tests\\not_constant.sql", "name": "test_not_constant", "macro_sql": "{% macro test_not_constant(model) %}\n  {{ return(adapter.dispatch('test_not_constant', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_not_constant": {"unique_id": "macro.dbt_utils.default__test_not_constant", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\not_constant.sql", "original_file_path": "macros\\schema_tests\\not_constant.sql", "name": "default__test_not_constant", "macro_sql": "{% macro default__test_not_constant(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\n\nfrom (\n\n    select\n          {# In TSQL, subquery aggregate columns need aliases #}\n          {# thus: a filler col name, 'filler_column' #}\n          count(distinct {{ column_name }}) as filler_column\n\n    from {{ model }}\n\n    having count(distinct {{ column_name }}) = 1\n\n    ) validation_errors\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_recency": {"unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\recency.sql", "original_file_path": "macros\\schema_tests\\recency.sql", "name": "test_recency", "macro_sql": "{% macro test_recency(model, datepart, interval) %}\n  {{ return(adapter.dispatch('test_recency', packages = dbt_utils._get_utils_namespaces())(model, datepart, interval, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_recency": {"unique_id": "macro.dbt_utils.default__test_recency", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\recency.sql", "original_file_path": "macros\\schema_tests\\recency.sql", "name": "default__test_recency", "macro_sql": "{% macro default__test_recency(model, datepart, interval) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n\nselect\n    case when count(*) > 0 then 0\n    else 1\n    end as error_result\nfrom {{model}}\nwhere {{column_name}} >=\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_relationships_where": {"unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\relationships_where.sql", "original_file_path": "macros\\schema_tests\\relationships_where.sql", "name": "test_relationships_where", "macro_sql": "{% macro test_relationships_where(model, to, field) %}\n  {{ return(adapter.dispatch('test_relationships_where', packages = dbt_utils._get_utils_namespaces())(model, to, field, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_relationships_where": {"unique_id": "macro.dbt_utils.default__test_relationships_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\relationships_where.sql", "original_file_path": "macros\\schema_tests\\relationships_where.sql", "name": "default__test_relationships_where", "macro_sql": "{% macro default__test_relationships_where(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n{% set from_condition = kwargs.get('from_condition', \"1=1\") %}\n{% set to_condition = kwargs.get('to_condition', \"1=1\") %}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect count(*) from exceptions\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_null_where": {"unique_id": "macro.dbt_utils.test_not_null_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_not_null_where.sql", "original_file_path": "macros\\schema_tests\\test_not_null_where.sql", "name": "test_not_null_where", "macro_sql": "{% macro test_not_null_where(model) %}\r\n  {{ return(adapter.dispatch('test_not_null_where', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_not_null_where": {"unique_id": "macro.dbt_utils.default__test_not_null_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_not_null_where.sql", "original_file_path": "macros\\schema_tests\\test_not_null_where.sql", "name": "default__test_not_null_where", "macro_sql": "{% macro default__test_not_null_where(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n{% set where = kwargs.get('where', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\nfrom {{ model }}\r\nwhere {{ column_name }} is null\r\n{% if where %} and {{ where }} {% endif %}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_where": {"unique_id": "macro.dbt_utils.test_unique_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_unique_where.sql", "original_file_path": "macros\\schema_tests\\test_unique_where.sql", "name": "test_unique_where", "macro_sql": "{% macro test_unique_where(model) %}\r\n  {{ return(adapter.dispatch('test_unique_where', packages = dbt_utils._get_utils_namespaces())(model, **kwargs)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_unique_where": {"unique_id": "macro.dbt_utils.default__test_unique_where", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_unique_where.sql", "original_file_path": "macros\\schema_tests\\test_unique_where.sql", "name": "default__test_unique_where", "macro_sql": "{% macro default__test_unique_where(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n{% set where = kwargs.get('where', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\nfrom (\r\n\r\n    select\r\n        {{ column_name }}\r\n\r\n    from {{ model }}\r\n    where {{ column_name }} is not null\r\n      {% if where %} and {{ where }} {% endif %}\r\n    group by {{ column_name }}\r\n    having count(*) > 1\r\n\r\n) validation_errors\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\unique_combination_of_columns.sql", "original_file_path": "macros\\schema_tests\\unique_combination_of_columns.sql", "name": "test_unique_combination_of_columns", "macro_sql": "{% macro test_unique_combination_of_columns(model, quote_columns = false) %}\n  {{ return(adapter.dispatch('test_unique_combination_of_columns', packages = dbt_utils._get_utils_namespaces())(model, quote_columns, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.default__test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\unique_combination_of_columns.sql", "original_file_path": "macros\\schema_tests\\unique_combination_of_columns.sql", "name": "default__test_unique_combination_of_columns", "macro_sql": "{% macro default__test_unique_combination_of_columns(model, quote_columns = false) %}\n\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\n\n{% if not quote_columns %}\n    {%- set column_list=columns %}\n{% elif quote_columns %}\n    {%- set column_list=[] %}\n        {% for column in columns -%}\n            {% set column_list = column_list.append( adapter.quote(column) ) %}\n        {%- endfor %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`quote_columns` argument for unique_combination_of_columns test must be one of [True, False] Got: '\" ~ quote ~\"'.'\"\n    ) }}\n{% endif %}\n\n{%- set columns_csv=column_list | join(', ') %}\n\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect count(*)\nfrom validation_errors\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_powers_of_two": {"unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', packages = dbt_utils._get_utils_namespaces())(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_powers_of_two": {"unique_id": "macro.dbt_utils.default__get_powers_of_two", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "default__get_powers_of_two", "macro_sql": "{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.generate_series": {"unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', packages = dbt_utils._get_utils_namespaces())(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__generate_series": {"unique_id": "macro.dbt_utils.default__generate_series", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "default__generate_series", "macro_sql": "{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_column_values": {"unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_column_values.sql", "original_file_path": "macros\\sql\\get_column_values.sql", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, max_records=none, default=none) -%}\n    {{ return(adapter.dispatch('get_column_values', packages = dbt_utils._get_utils_namespaces())(table, column, max_records, default)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_column_values": {"unique_id": "macro.dbt_utils.default__get_column_values", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_column_values.sql", "original_file_path": "macros\\sql\\get_column_values.sql", "name": "default__get_column_values", "macro_sql": "{% macro default__get_column_values(table, column, max_records=none, default=none) -%}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n{#--  #}\n\n    {%- set target_relation = adapter.get_relation(database=table.database,\n                                          schema=table.schema,\n                                         identifier=table.identifier) -%}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not target_relation and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not target_relation and default is not none -%}\n\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by 1\n            order by count(*) desc\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_query_results_as_dict": {"unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_query_results_as_dict.sql", "original_file_path": "macros\\sql\\get_query_results_as_dict.sql", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n    {{ return(adapter.dispatch('get_query_results_as_dict', packages = dbt_utils._get_utils_namespaces())(query)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_query_results_as_dict": {"unique_id": "macro.dbt_utils.default__get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_query_results_as_dict.sql", "original_file_path": "macros\\sql\\get_query_results_as_dict.sql", "name": "default__get_query_results_as_dict", "macro_sql": "{% macro default__get_query_results_as_dict(query) %}\n\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_pattern": {"unique_id": "macro.dbt_utils.get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_pattern.sql", "original_file_path": "macros\\sql\\get_relations_by_pattern.sql", "name": "get_relations_by_pattern", "macro_sql": "{% macro get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_pattern', packages = dbt_utils._get_utils_namespaces())(schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_relations_by_pattern": {"unique_id": "macro.dbt_utils.default__get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_pattern.sql", "original_file_path": "macros\\sql\\get_relations_by_pattern.sql", "name": "default__get_relations_by_pattern", "macro_sql": "{% macro default__get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_prefix": {"unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_prefix.sql", "original_file_path": "macros\\sql\\get_relations_by_prefix.sql", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_prefix', packages = dbt_utils._get_utils_namespaces())(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_relations_by_prefix": {"unique_id": "macro.dbt_utils.default__get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_prefix.sql", "original_file_path": "macros\\sql\\get_relations_by_prefix.sql", "name": "default__get_relations_by_prefix", "macro_sql": "{% macro default__get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "get_tables_by_pattern_sql", "macro_sql": "{% macro get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_pattern_sql', packages = dbt_utils._get_utils_namespaces())\n        (schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "default__get_tables_by_pattern_sql", "macro_sql": "{% macro default__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n        select distinct\n            table_schema as \"table_schema\",\n            table_name as \"table_name\",\n            case table_type\n                when 'BASE TABLE' then 'table'\n                else lower(table_type)\n            end as \"table_type\"\n        from {{ database }}.information_schema.tables\n        where table_schema ilike '{{ schema_pattern }}'\n        and table_name ilike '{{ table_pattern }}'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.bigquery__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "bigquery__get_tables_by_pattern_sql", "macro_sql": "{% macro bigquery__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {% if '%' in schema_pattern %}\n        {% set schemata=dbt_utils._bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% else %}\n        {% set schemata=[schema_pattern] %}\n    {% endif %}\n\n    {% set sql %}\n        {% for schema in schemata %}\n            select distinct\n                table_schema,\n                table_name,\n                case table_type\n                    when 'BASE TABLE' then 'table'\n                    else lower(table_type)\n                end as table_type\n\n            from {{ adapter.quote(database) }}.{{ schema }}.INFORMATION_SCHEMA.TABLES\n            where lower(table_name) like lower ('{{ table_pattern }}')\n                and lower(table_name) not like lower ('{{ exclude }}')\n\n            {% if not loop.last %} union all {% endif %}\n\n        {% endfor %}\n    {% endset %}\n\n    {{ return(sql) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._bigquery__get_matching_schemata": {"unique_id": "macro.dbt_utils._bigquery__get_matching_schemata", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "_bigquery__get_matching_schemata", "macro_sql": "{% macro _bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% if execute %}\n\n        {% set sql %}\n        select schema_name from {{ adapter.quote(database) }}.INFORMATION_SCHEMA.SCHEMATA\n        where lower(schema_name) like lower('{{ schema_pattern }}')\n        {% endset %}\n\n        {% set results=run_query(sql) %}\n\n        {% set schemata=results.columns['schema_name'].values() %}\n\n        {{ return(schemata) }}\n\n    {% else %}\n\n        {{ return([]) }}\n\n    {% endif %}\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_prefix_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_prefix_sql.sql", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_prefix_sql', packages = dbt_utils._get_utils_namespaces())(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_prefix_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_prefix_sql.sql", "name": "default__get_tables_by_prefix_sql", "macro_sql": "{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n    {{ dbt_utils.get_tables_by_pattern_sql(\n        schema_pattern = schema,\n        table_pattern = prefix ~ '%',\n        exclude = exclude,\n        database = database\n    ) }}\n    \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.group_by": {"unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\groupby.sql", "original_file_path": "macros\\sql\\groupby.sql", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\n    {{ return(adapter.dispatch('group_by', packages = dbt_utils._get_utils_namespaces())(n)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__group_by": {"unique_id": "macro.dbt_utils.default__group_by", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\groupby.sql", "original_file_path": "macros\\sql\\groupby.sql", "name": "default__group_by", "macro_sql": "\n\n{%- macro default__group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck": {"unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck.sql", "original_file_path": "macros\\sql\\nullcheck.sql", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\n    {{ return(adapter.dispatch('nullcheck', packages = dbt_utils._get_utils_namespaces())(cols)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__nullcheck": {"unique_id": "macro.dbt_utils.default__nullcheck", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck.sql", "original_file_path": "macros\\sql\\nullcheck.sql", "name": "default__nullcheck", "macro_sql": "{% macro default__nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck_table": {"unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck_table.sql", "original_file_path": "macros\\sql\\nullcheck_table.sql", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\n    {{ return(adapter.dispatch('nullcheck_table', packages = dbt_utils._get_utils_namespaces())(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__nullcheck_table": {"unique_id": "macro.dbt_utils.default__nullcheck_table", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck_table.sql", "original_file_path": "macros\\sql\\nullcheck_table.sql", "name": "default__nullcheck_table", "macro_sql": "{% macro default__nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pivot": {"unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\pivot.sql", "original_file_path": "macros\\sql\\pivot.sql", "name": "pivot", "macro_sql": "{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n    {{ return(adapter.dispatch('pivot', packages = dbt_utils._get_utils_namespaces())(column, values, alias, agg, cmp, prefix, suffix, then_value, else_value, quote_identifiers, distinct)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__pivot": {"unique_id": "macro.dbt_utils.default__pivot", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\pivot.sql", "original_file_path": "macros\\sql\\pivot.sql", "name": "default__pivot", "macro_sql": "{% macro default__pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n  {% for v in values %}\n    {{ agg }}(\n      {% if distinct %} distinct {% endif %}\n      case\n      when {{ column }} {{ cmp }} '{{ v }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\n      {% else %}\n        as {{prefix ~ v ~ suffix }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_add": {"unique_id": "macro.dbt_utils.safe_add", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\safe_add.sql", "original_file_path": "macros\\sql\\safe_add.sql", "name": "safe_add", "macro_sql": "{%- macro safe_add() -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('safe_add', packages = dbt_utils._get_utils_namespaces())(*varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__safe_add": {"unique_id": "macro.dbt_utils.default__safe_add", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\safe_add.sql", "original_file_path": "macros\\sql\\safe_add.sql", "name": "default__safe_add", "macro_sql": "\n\n{%- macro default__safe_add() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.star": {"unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\star.sql", "original_file_path": "macros\\sql\\star.sql", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\n    {{ return(adapter.dispatch('star', packages = dbt_utils._get_utils_namespaces())(from, relation_alias, except)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__star": {"unique_id": "macro.dbt_utils.default__star", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\star.sql", "original_file_path": "macros\\sql\\star.sql", "name": "default__star", "macro_sql": "{% macro default__star(from, relation_alias=False, except=[]) -%}\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n    {%- do dbt_utils._is_ephemeral(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n\n    {%- for col in cols -%}\n\n        {%- if col.column not in except -%}\n            {% do include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ adapter.quote(col)|trim }}\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.surrogate_key": {"unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\surrogate_key.sql", "original_file_path": "macros\\sql\\surrogate_key.sql", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key(field_list) -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('surrogate_key', packages = dbt_utils._get_utils_namespaces())(field_list, *varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__surrogate_key": {"unique_id": "macro.dbt_utils.default__surrogate_key", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\surrogate_key.sql", "original_file_path": "macros\\sql\\surrogate_key.sql", "name": "default__surrogate_key", "macro_sql": "\n\n{%- macro default__surrogate_key(field_list) -%}\n\n{%- if varargs|length >= 1 or field_list is string %}\n\n{%- set error_message = '\nWarning: the `surrogate_key` macro now takes a single list argument instead of \\\nmultiple string arguments. Support for multiple string arguments will be \\\ndeprecated in a future release of dbt-utils. The {}.{} model triggered this warning. \\\n'.format(model.package_name, model.name) -%}\n\n{%- do exceptions.warn(error_message) -%}\n\n{# first argument is not included in varargs, so add first element to field_list_xf #}\n{%- set field_list_xf = [field_list] -%}\n\n{%- for field in varargs %}\n{%- set _ = field_list_xf.append(field) -%}\n{%- endfor -%}\n\n{%- else -%}\n\n{# if using list, just set field_list_xf as field_list #}\n{%- set field_list_xf = field_list -%}\n\n{%- endif -%}\n\n\n{%- set fields = [] -%}\n\n{%- for field in field_list_xf -%}\n\n    {%- set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- set _ = fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_relations": {"unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\union.sql", "original_file_path": "macros\\sql\\union.sql", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n    {{ return(adapter.dispatch('union_relations', packages = dbt_utils._get_utils_namespaces())(relations, column_override, include, exclude, source_column_name)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__union_relations": {"unique_id": "macro.dbt_utils.default__union_relations", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\union.sql", "original_file_path": "macros\\sql\\union.sql", "name": "default__union_relations", "macro_sql": "\n\n{%- macro default__union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- do dbt_utils._is_ephemeral(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.unpivot": {"unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\unpivot.sql", "original_file_path": "macros\\sql\\unpivot.sql", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n    {{ return(adapter.dispatch('unpivot', packages = dbt_utils._get_utils_namespaces())(relation, cast_to, exclude, remove, field_name, value_name, table)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__unpivot": {"unique_id": "macro.dbt_utils.default__unpivot", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\sql\\unpivot.sql", "original_file_path": "macros\\sql\\unpivot.sql", "name": "default__unpivot", "macro_sql": "{% macro default__unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if table %}\n        {%- set error_message = '\n            Warning: the `unpivot` macro no longer accepts a `table` parameter. \\\n            This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead. \\\n            The {}.{} model triggered this warning. \\\n            '.format(model.package_name, model.name) -%}\n        {%- do exceptions.warn(error_message) -%}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_host": {"unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_host.sql", "original_file_path": "macros\\web\\get_url_host.sql", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\n    {{ return(adapter.dispatch('get_url_host', packages = dbt_utils._get_utils_namespaces())(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_url_host": {"unique_id": "macro.dbt_utils.default__get_url_host", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_host.sql", "original_file_path": "macros\\web\\get_url_host.sql", "name": "default__get_url_host", "macro_sql": "{% macro default__get_url_host(field) -%}\n\n{%- set parsed = \n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(field, \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n    \n-%}\n\n     \n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n        \n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_parameter": {"unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_parameter.sql", "original_file_path": "macros\\web\\get_url_parameter.sql", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n    {{ return(adapter.dispatch('get_url_parameter', packages = dbt_utils._get_utils_namespaces())(field, url_parameter)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_url_parameter": {"unique_id": "macro.dbt_utils.default__get_url_parameter", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_parameter.sql", "original_file_path": "macros\\web\\get_url_parameter.sql", "name": "default__get_url_parameter", "macro_sql": "{% macro default__get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_path": {"unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_path.sql", "original_file_path": "macros\\web\\get_url_path.sql", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\n    {{ return(adapter.dispatch('get_url_path', packages = dbt_utils._get_utils_namespaces())(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_url_path": {"unique_id": "macro.dbt_utils.default__get_url_path", "package_name": "dbt_utils", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_path.sql", "original_file_path": "macros\\web\\get_url_path.sql", "name": "default__get_url_path", "macro_sql": "{% macro default__get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "c:\\users\\sidda\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dbt\\include\\global_project", "path": "overview.md", "original_file_path": "docs\\overview.md", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://community.getdbt.com/) on Slack for live questions and support."}, "dbtvault.macro__alias": {"unique_id": "dbtvault.macro__alias", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__alias", "block_contents": "Perform aliasing on a mapping and optionally prefix the string as well.\n\nSee also:\n[alias_all](#!/macro/macro.dbtvault.alias_all)"}, "dbtvault.arg__alias__alias_config": {"unique_id": "dbtvault.arg__alias__alias_config", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__alias__alias_config", "block_contents": "A mapping, containing a configuration for the aliasing. \n                                                \n| Key           | Description          | Type   |\n| ------------- | -------------------- | ------ |\n| source_column | Column being aliased | string |\n| alias         | Column alias         | string |"}, "dbtvault.arg__alias__prefix": {"unique_id": "dbtvault.arg__alias__prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__alias__prefix", "block_contents": "A string to prefix the column with."}, "dbtvault.macro__alias_all": {"unique_id": "dbtvault.macro__alias_all", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__alias_all", "block_contents": "Perform aliasing on a mapping and optionally prefix the string as well."}, "dbtvault.arg__alias_all__columns": {"unique_id": "dbtvault.arg__alias_all__columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__alias_all__columns", "block_contents": "A list of columns, as strings or mappings.\n\ne.g.\n\n```\nsrc_hashdiff: \n  source_column: \"CUSTOMER_HASHDIFF\"\n  alias: \"HASHDIFF\"\n```"}, "dbtvault.arg__alias_all__prefix": {"unique_id": "dbtvault.arg__alias_all__prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__alias_all__prefix", "block_contents": "A string to prefix all columns with."}, "dbtvault.macro__as_constant": {"unique_id": "dbtvault.macro__as_constant", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__as_constant", "block_contents": "Render a string as a constant value if it is prefixed with an exclamation mark (`!`) otherwise, return as provided."}, "dbtvault.arg__as_constant__column_str": {"unique_id": "dbtvault.arg__as_constant__column_str", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__as_constant__column_str", "block_contents": "The string to parse as a constant."}, "dbtvault.macro__expand_column_list": {"unique_id": "dbtvault.macro__expand_column_list", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__expand_column_list", "block_contents": "Flatten a nested list structure into a single list so that it may be rendered in CSV format or provided to other macros."}, "dbtvault.arg__expand_column_list__columns": {"unique_id": "dbtvault.arg__expand_column_list__columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__expand_column_list__columns", "block_contents": "A list of lists to flatten. May contain strings as well, these will be added as single items in the returned list."}, "dbtvault.macro__multikey": {"unique_id": "dbtvault.macro__multikey", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__multikey", "block_contents": "Apply the same conditions and comparisons to a list of columns/keys. \n\ne.g. Given the following argument values:\n\ncolumns = ['CUSTOMER_ID', 'NATION_ID']\nprefix = ['a', 'b']\ncondition = '='\noperator = 'AND'\n\nThe macro would render this as:\n\n```\na.CUSTOMER_ID = b.CUSTOMER_ID\nAND a.NATION_ID = b.NATION_ID \n```"}, "dbtvault.arg__multikey__columns": {"unique_id": "dbtvault.arg__multikey__columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__multikey__columns", "block_contents": "A list of columns to generate comparisons for."}, "dbtvault.arg__multikey__prefix": {"unique_id": "dbtvault.arg__multikey__prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__multikey__prefix", "block_contents": "A pair of prefixes, one for each side of the comparison."}, "dbtvault.arg__multikey__condition": {"unique_id": "dbtvault.arg__multikey__condition", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__multikey__condition", "block_contents": "The comparison to make between the keys, should be one of: \n\n'<>', '!=', '='"}, "dbtvault.arg__multikey__operator": {"unique_id": "dbtvault.arg__multikey__operator", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "arg__multikey__operator", "block_contents": "The operator to join the conditions with, defaults to 'AND', but could also be 'OR'."}, "dbtvault.macro__prepend_generated_by": {"unique_id": "dbtvault.macro__prepend_generated_by", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "internal.md", "original_file_path": "docs\\internal.md", "name": "macro__prepend_generated_by", "block_contents": "A convenience macro to print a `-- Generated by dbtvault.` string."}, "dbtvault.__dbtvault__": {"unique_id": "dbtvault.__dbtvault__", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "overview.md", "original_file_path": "docs\\overview.md", "name": "__dbtvault__", "block_contents": "<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/25080503/65772647-89525700-e132-11e9-80ff-12ad30a25466.png\">\n</p>\n\n[![Documentation Status](https://readthedocs.org/projects/dbtvault/badge/?version=stable)](https://dbtvault.readthedocs.io/en/latest/?badge=stable)\n\n[![Join our Slack](https://img.shields.io/badge/Slack-Join-yellow?style=flat&logo=slack)](https://join.slack.com/t/dbtvault/shared_invite/enQtODY5MTY3OTIyMzg2LWJlZDMyNzM4YzAzYjgzYTY0MTMzNTNjN2EyZDRjOTljYjY0NDYyYzEwMTlhODMzNGY3MmU2ODNhYWUxYmM2NjA)\n\n# dbtvault by [Datavault](https://www.data-vault.co.uk)\n\nBuild your own Data Vault data warehouse! dbtvault is a free to use dbt package that generates & executes the ETL you need to run a Data Vault 2.0 Data Warehouse on a Snowflake database.\n\nWhat does dbtvault offer?\n- productivity gains, fewer errors\n- multi-threaded execution of the generated SQL\n- your data modeller can generate most of the ETL code directly from their mapping metadata\n- your ETL developers can focus on the 5% of the SQL code that is different\n- dbt generates documentation and data flow diagrams\n\npowered by [dbt](https://www.getdbt.com/), a registered trademark of [Fishtown Analytics](https://www.fishtownanalytics.com/)\n\n[See the github repo for more details!](https://github.com/Datavault-UK/dbtvault/)"}, "dbtvault.platform__snowflake": {"unique_id": "dbtvault.platform__snowflake", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "platforms.md", "original_file_path": "docs\\platforms.md", "name": "platform__snowflake", "block_contents": "Snowflake implementation"}, "dbtvault.macro__stage": {"unique_id": "dbtvault.macro__stage", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "macro__stage", "block_contents": "A macro to aid in generating a staging layer for the raw vault. Allows users to:\n\n- Create new columns from already existing columns (Derived columns)\n- Create new hashed columns from already existing columns and provided derived columns (Hashed columns)\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#stage)"}, "dbtvault.arg__stage__include_source_columns": {"unique_id": "dbtvault.arg__stage__include_source_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "arg__stage__include_source_columns", "block_contents": "True by default. If true, all columns included in the source model for the stage layer, will be propagated to the stage layer.\n\nIf false, only derived and hash columns (if configured) will be present in the resulting stage layer."}, "dbtvault.arg__stage__source_model": {"unique_id": "dbtvault.arg__stage__source_model", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "arg__stage__source_model", "block_contents": "The dbt model name or source to build a staging layer from. Can be provided in the following formats:\n\n```\n[REF STYLE]\nsource_model: model_name\nOR\n[SOURCES STYLE]\nsource_model:\n    source_name: source_table_name\"\n```"}, "dbtvault.arg__stage__hashed_columns": {"unique_id": "dbtvault.arg__stage__hashed_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "arg__stage__hashed_columns", "block_contents": "A mapping of hash key names to column names which should be hashed to create that key.\n\ne.g.\n\n```\nhashed_columns:\n    SUPPLIER_PK: 'SUPPLIERKEY'\n    SUPPLIER_NATION_PK: 'SUPPLIER_NATION_KEY'\n    SUPPLIER_REGION_PK: 'SUPPLIER_REGION_KEY'\n    REGION_PK: 'SUPPLIER_REGION_KEY'\n    NATION_PK: 'SUPPLIER_NATION_KEY'\n    NATION_REGION_PK:\n      - 'SUPPLIER_NATION_KEY'\n      - 'SUPPLIER_REGION_KEY'\n    LINK_SUPPLIER_NATION_PK:\n      - 'SUPPLIERKEY'\n      - 'SUPPLIER_NATION_KEY'\n    PART_PK: 'PARTKEY'\n    INVENTORY_PK:\n      - 'PARTKEY'\n      - 'SUPPLIERKEY'\n    INVENTORY_HASHDIFF:\n      is_hashdiff: true\n      columns:\n        - 'PARTKEY'\n        - 'SUPPLIERKEY'\n        - 'AVAILQTY'\n        - 'SUPPLYCOST'\n        - 'PART_SUPPLY_COMMENT'\n```"}, "dbtvault.arg__stage__derived_columns": {"unique_id": "dbtvault.arg__stage__derived_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "arg__stage__derived_columns", "block_contents": "A mapping of new column names to existing columns which should be hashed to create that key.\n\ne.g.\n\n```\nderived_columns:\n    NATION_KEY: 'SUPPLIER_NATION_KEY'\n    REGION_KEY: 'SUPPLIER_REGION_KEY'\n    SOURCE: '!TPCH-INVENTORY'\n```"}, "dbtvault.macro__derive_columns": {"unique_id": "dbtvault.macro__derive_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "macro__derive_columns", "block_contents": "A macro used by the `stage` macro internally, which processes a mapping of new columns to source columns, in order to generate new columns. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#derive_columns)"}, "dbtvault.arg__derive_columns__source_relation": {"unique_id": "dbtvault.arg__derive_columns__source_relation", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "arg__derive_columns__source_relation", "block_contents": "The source relation to extract columns from, for deriving from."}, "dbtvault.macro__hash_columns": {"unique_id": "dbtvault.macro__hash_columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "staging.md", "original_file_path": "docs\\staging.md", "name": "macro__hash_columns", "block_contents": "A macro used by the `stage` macro internally, which processes a mapping of hash key names to source columns, in order to generate hash keys. \n\nSee also:\n[stage](#!/macro/macro.dbtvault.stage)\n[Online docs](https://dbtvault.readthedocs.io/en/latest/macros/#hash_columns)"}, "dbtvault.macro__hash": {"unique_id": "dbtvault.macro__hash", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "macro__hash", "block_contents": "Generate SQL to hash one or more columns using MD5 or SHA256. \n\nSee [How do we hash?](https://dbtvault.readthedocs.io/en/latest/best_practices/#how-do-we-hash) for an in-depth look at how dbtvault does hashing. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hash)"}, "dbtvault.arg__hash__columns": {"unique_id": "dbtvault.arg__hash__columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__hash__columns", "block_contents": "A list of one or more columns to hash."}, "dbtvault.arg__hash__alias": {"unique_id": "dbtvault.arg__hash__alias", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__hash__alias", "block_contents": "The alias (name) for the new column output using the hash macro."}, "dbtvault.arg__hash__is_hashdiff": {"unique_id": "dbtvault.arg__hash__is_hashdiff", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__hash__is_hashdiff", "block_contents": "Boolean flag. If true, sort the column names in alphabetical order prior to hashing.\nThis is required for hashdiffs to ensure consistent hashing."}, "dbtvault.macro__prefix": {"unique_id": "dbtvault.macro__prefix", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "macro__prefix", "block_contents": "Prefix one or more strings with a given string and print each one.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#prefix)"}, "dbtvault.arg__prefix__columns": {"unique_id": "dbtvault.arg__prefix__columns", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__prefix__columns", "block_contents": "A list of columns (string or mapping) to prefix.\n\nIf a column is specified using an alias mapping as follows:\n\n{'source_column': <'column name'>, 'alias': <'alias string'>}\n\nThen it will also be aliased using `AS <column name>`."}, "dbtvault.arg__prefix__prefix_str": {"unique_id": "dbtvault.arg__prefix__prefix_str", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__prefix__prefix_str", "block_contents": "The string to prepend to each column/string."}, "dbtvault.arg__prefix__alias_target": {"unique_id": "dbtvault.arg__prefix__alias_target", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "supporting.md", "original_file_path": "docs\\supporting.md", "name": "arg__prefix__alias_target", "block_contents": "Switch the aliasing target. `source` by default.\n\nIf a column is specified using an alias mapping as follows:\n\n`{'source_column': <'column name'>, 'alias': <'alias string'>}`\n\nThen it will also be aliased using `AS <column name>`.\n\nHowever, if the `alias_target` is `target` instead of `source`, the column will be rendered as follows:\n\n`AS <alias string>`"}, "dbtvault.materialization__vault_insert_by_period__default": {"unique_id": "dbtvault.materialization__vault_insert_by_period__default", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\materialisations.md", "original_file_path": "docs\\materialisations\\materialisations.md", "name": "materialization__vault_insert_by_period__default", "block_contents": "A materialisation designed to iterate through source data and load it in discrete periods of time, configurable by the user."}, "dbtvault.macro__is_vault_insert_by_period": {"unique_id": "dbtvault.macro__is_vault_insert_by_period", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\materialisations.md", "original_file_path": "docs\\materialisations\\materialisations.md", "name": "macro__is_vault_insert_by_period", "block_contents": "Check that a model is using the `vault_insert_by_period` materialisation."}, "dbtvault.macro__check_placeholder": {"unique_id": "dbtvault.macro__check_placeholder", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\check_placeholder.md", "original_file_path": "docs\\materialisations\\helpers\\check_placeholder.md", "name": "macro__check_placeholder", "block_contents": "Searches the given SQL string for an expected placeholder, throwing an error if it is not found."}, "dbtvault.arg__check_placeholder__model_sql": {"unique_id": "dbtvault.arg__check_placeholder__model_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\check_placeholder.md", "original_file_path": "docs\\materialisations\\helpers\\check_placeholder.md", "name": "arg__check_placeholder__model_sql", "block_contents": "The SQL string to search."}, "dbtvault.arg__check_placeholder__placeholder": {"unique_id": "dbtvault.arg__check_placeholder__placeholder", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\check_placeholder.md", "original_file_path": "docs\\materialisations\\helpers\\check_placeholder.md", "name": "arg__check_placeholder__placeholder", "block_contents": "Optional. Default: `__PERIOD_FILTER__`\n\nThe placeholder to search for."}, "dbtvault.macro__get_period_boundaries": {"unique_id": "dbtvault.macro__get_period_boundaries", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_boundaries.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_boundaries.md", "name": "macro__get_period_boundaries", "block_contents": "Get the start and stop timestamp, as well as the number of periods/iterations which need to be made to do the full load.\nIt is important to note that this materialisation handles the idempotent nature of the materialisation by running a `COALESCE`\non the maximal date found in the target table if it already exists, and the provided `start_date`. \n\nThis also allows the materialisation to handle aborted loads."}, "dbtvault.arg__get_period_boundaries__target_schema": {"unique_id": "dbtvault.arg__get_period_boundaries__target_schema", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_boundaries.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_boundaries.md", "name": "arg__get_period_boundaries__target_schema", "block_contents": "The schema that the target table is materialised in."}, "dbtvault.arg__get_period_boundaries__target_table": {"unique_id": "dbtvault.arg__get_period_boundaries__target_table", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_boundaries.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_boundaries.md", "name": "arg__get_period_boundaries__target_table", "block_contents": "The name of the materialised target table."}, "dbtvault.arg__get_period_boundaries__start_date": {"unique_id": "dbtvault.arg__get_period_boundaries__start_date", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_boundaries.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_boundaries.md", "name": "arg__get_period_boundaries__start_date", "block_contents": "The date stamp to start loading from. Must be in the format 'YYYY-MM-DD'"}, "dbtvault.arg__get_period_boundaries__stop_date": {"unique_id": "dbtvault.arg__get_period_boundaries__stop_date", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_boundaries.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_boundaries.md", "name": "arg__get_period_boundaries__stop_date", "block_contents": "THe date stamp to stop loading on. Must be in the format 'YYYY-MM-DD'"}, "dbtvault.macro__get_period_filter_sql": {"unique_id": "dbtvault.macro__get_period_filter_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_filter_sql.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_filter_sql.md", "name": "macro__get_period_filter_sql", "block_contents": "A wrapper around the `replace_placeholder_with_period_filter` macro which creates a query designed to\nbuild a temporary table, to select the necessary records for the given load cycle."}, "dbtvault.arg__get_period_filter_sql__target_cols_csv": {"unique_id": "dbtvault.arg__get_period_filter_sql__target_cols_csv", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_filter_sql.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_filter_sql.md", "name": "arg__get_period_filter_sql__target_cols_csv", "block_contents": "A CSV string of the columns to be created in the target table \n(the table the model is creating with this materialisation)"}, "dbtvault.arg__get_period_filter_sql__base_sql": {"unique_id": "dbtvault.arg__get_period_filter_sql__base_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_filter_sql.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_filter_sql.md", "name": "arg__get_period_filter_sql__base_sql", "block_contents": "The SQL provided by the model, prior to any manipulation."}, "dbtvault.macro__get_period_of_load": {"unique_id": "dbtvault.macro__get_period_of_load", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_of_load.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_of_load.md", "name": "macro__get_period_of_load", "block_contents": "A helper macro to fetch the date of the current load cycle."}, "dbtvault.arg__get_period_of_load__start_timestamp": {"unique_id": "dbtvault.arg__get_period_of_load__start_timestamp", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_period_of_load.md", "original_file_path": "docs\\materialisations\\helpers\\get_period_of_load.md", "name": "arg__get_period_of_load__start_timestamp", "block_contents": "The `start_timestamp` of the load, derived from the `start_date`."}, "dbtvault.macro__get_start_stop_dates": {"unique_id": "dbtvault.macro__get_start_stop_dates", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_start_stop_dates.md", "original_file_path": "docs\\materialisations\\helpers\\get_start_stop_dates.md", "name": "macro__get_start_stop_dates", "block_contents": "A helper macro to fetch the start and stop dates to load with. It will either infer the date range from the min and max \ndates present in the tables in `date_source_models` list, or alternatively use the `start_date` and `stop_date` \nconfig options. The config options take precedence if both are provided. A suitable error is raised if neither is provided."}, "dbtvault.arg__get_start_stop_dates__date_source_models": {"unique_id": "dbtvault.arg__get_start_stop_dates__date_source_models", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\get_start_stop_dates.md", "original_file_path": "docs\\materialisations\\helpers\\get_start_stop_dates.md", "name": "arg__get_start_stop_dates__date_source_models", "block_contents": "A list of models to union together and extract min and max dates from, which will be used as the range to load records with."}, "dbtvault.macro__replace_placeholder_with_period_filter": {"unique_id": "dbtvault.macro__replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\replace_placeholder_with_filter.md", "original_file_path": "docs\\materialisations\\helpers\\replace_placeholder_with_filter.md", "name": "macro__replace_placeholder_with_period_filter", "block_contents": "Replace the `__PERIOD_FILTER__` string present in the given SQL, with a `WHERE` clause which filters data by a\nspecific `period` of time, `offset` from the `start_date`."}, "dbtvault.arg__replace_placeholder_with_period_filter__core_sql": {"unique_id": "dbtvault.arg__replace_placeholder_with_period_filter__core_sql", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\replace_placeholder_with_filter.md", "original_file_path": "docs\\materialisations\\helpers\\replace_placeholder_with_filter.md", "name": "arg__replace_placeholder_with_period_filter__core_sql", "block_contents": "SQL string containing the `__PERIOD_FILTER__` string."}, "dbtvault.arg__period_materialisation__timestamp_field": {"unique_id": "dbtvault.arg__period_materialisation__timestamp_field", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\shared_definitions.md", "original_file_path": "docs\\materialisations\\helpers\\shared_definitions.md", "name": "arg__period_materialisation__timestamp_field", "block_contents": "The field to reference and extract timestamps and dates from. \n\nThis should be the same as the `src_ldts` attribute if using a table macro."}, "dbtvault.arg__period_materialisation__offset": {"unique_id": "dbtvault.arg__period_materialisation__offset", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\shared_definitions.md", "original_file_path": "docs\\materialisations\\helpers\\shared_definitions.md", "name": "arg__period_materialisation__offset", "block_contents": "The period of time to offset the start of the load from. For example, if period is set to `day` and the offset is `1`, then\nthis will evaluate to `start + 1 day`"}, "dbtvault.arg__period_materialisation__period": {"unique_id": "dbtvault.arg__period_materialisation__period", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\shared_definitions.md", "original_file_path": "docs\\materialisations\\helpers\\shared_definitions.md", "name": "arg__period_materialisation__period", "block_contents": "The period of time to iterate through. The naming varies per platform, though some common examples are:\n\n- hour\n- day\n- month\n- year\n\nSee below for platform specific documentation.\n\n[Snowflake](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#supported-date-and-time-parts)"}, "dbtvault.arg__period_materialisation__start_timestamp": {"unique_id": "dbtvault.arg__period_materialisation__start_timestamp", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\shared_definitions.md", "original_file_path": "docs\\materialisations\\helpers\\shared_definitions.md", "name": "arg__period_materialisation__start_timestamp", "block_contents": "The starting timestamp for the range of records to be loaded. \nRecords must have a timestamp greater or equal to this value to be included."}, "dbtvault.arg__period_materialisation__stop_timestamp": {"unique_id": "dbtvault.arg__period_materialisation__stop_timestamp", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "materialisations\\helpers\\shared_definitions.md", "original_file_path": "docs\\materialisations\\helpers\\shared_definitions.md", "name": "arg__period_materialisation__stop_timestamp", "block_contents": "The stopping timestamp for the range of records to be loaded. \nRecords must have a timestamp less than this value to be included."}, "dbtvault.arg__tables__src_pk": {"unique_id": "dbtvault.arg__tables__src_pk", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_pk", "block_contents": "The column used as the primary key of the table. This must be a hash key generated from a natural key in the staging layer. \nIn future versions of dbtvault, hashing will not be a requirement."}, "dbtvault.arg__tables__src_nk": {"unique_id": "dbtvault.arg__tables__src_nk", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_nk", "block_contents": "The column used as the natural or business key of the table. This must be the non-hashed version of the column used for the `src_pk`."}, "dbtvault.arg__tables__src_fk": {"unique_id": "dbtvault.arg__tables__src_fk", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_fk", "block_contents": "A single column or list of columns which are the primary key columns of other, related tables. Used in links to shows hubs associated with the link."}, "dbtvault.arg__tables__src_hashdiff": {"unique_id": "dbtvault.arg__tables__src_hashdiff", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_hashdiff", "block_contents": "A column which contains a single hash, composed of a list of columns and alpha-sorted. A hashdiff is used as a kind of checksum, to detect changes in records. \nIf any of the columns which form the hashdiff change their value, then the hashdiff itself will change. This is used in satellites to detect changes in the payload."}, "dbtvault.arg__tables__src_payload_sat": {"unique_id": "dbtvault.arg__tables__src_payload_sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_payload_sat", "block_contents": "A list or single list of columns which contains the payload of the satellite. \nA satellite payload should contain the concrete attributes for entity descried in the corresponding hub record."}, "dbtvault.arg__tables__src_payload__t_link": {"unique_id": "dbtvault.arg__tables__src_payload__t_link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_payload__t_link", "block_contents": "A list or single list of columns which contains the payload of the t-link. \nA t-link payload should contain the transactional/event attributes for entity descried in the corresponding hub record."}, "dbtvault.arg__tables__src_eff": {"unique_id": "dbtvault.arg__tables__src_eff", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_eff", "block_contents": "The effective from column for a record. This is the business-effective date of a record. \n\n- For a transactional link, this would be the time at which the transaction occurred. \n- For a satellite, this would be the time at which we first saw this data in the system (i.e when the payload changed) in a given form.\n- For an effectivity satellite, this is the time at which we first saw the link relationship in a given form."}, "dbtvault.arg__tables__src_ldts": {"unique_id": "dbtvault.arg__tables__src_ldts", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_ldts", "block_contents": "The load datetime stamp of the record. When this record appeared/was loaded into the database."}, "dbtvault.arg__tables__src_source": {"unique_id": "dbtvault.arg__tables__src_source", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__src_source", "block_contents": "The source for a given record. This can be a code which corresponds to a lookup table or simply a string with a named system."}, "dbtvault.arg__tables__source_model": {"unique_id": "dbtvault.arg__tables__source_model", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\shared_definitions.md", "original_file_path": "docs\\tables\\shared_definitions.md", "name": "arg__tables__source_model", "block_contents": "The name of the model which contains the data which needs to be loaded. This can be a list for Hubs and Links, which could have multiple sources."}, "dbtvault.macro__hub": {"unique_id": "dbtvault.macro__hub", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\tables.md", "original_file_path": "docs\\tables\\tables.md", "name": "macro__hub", "block_contents": "A Hub contains a distinct set of keys for a given top-level business concept, for example a `HUB_CUSTOMER` hub may contain a distinct list\nof Customer IDs. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#hub)"}, "dbtvault.macro__link": {"unique_id": "dbtvault.macro__link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\tables.md", "original_file_path": "docs\\tables\\tables.md", "name": "macro__link", "block_contents": "A Link contains a distinct set of relationships between top-level business concepts. \nThese structures 'link' hubs together based on a business relationship between the two.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#link)"}, "dbtvault.macro__sat": {"unique_id": "dbtvault.macro__sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\tables.md", "original_file_path": "docs\\tables\\tables.md", "name": "macro__sat", "block_contents": "A Satellite contains records corresponding to Hub or Link records which provide concrete attributes for those records. For example a `SAT_CUSTOMER_DETAILS` Satellite\nwould contain details about the customer, by using the same primary key as the corresponding hub record. \nThe payload for this example may contain `CUSTOMER_DOB`, `CUSTOMER_GIVEN_NAME`, `CUSTOMER_SURNAME` columns.\n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#sat)"}, "dbtvault.macro__eff_sat": {"unique_id": "dbtvault.macro__eff_sat", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\tables.md", "original_file_path": "docs\\tables\\tables.md", "name": "macro__eff_sat", "block_contents": "An Effectivity Satellite keeps track of the effective dates of relationships contained in links. \nIf a relationship changes (for example, a Customer moves country, changing a customer and nation relation) \nthen an effectivity satellite will record this change as a new entry, and when it happened. \n\nWhen a new relationship is loaded from the source, a new record will be created with the new relation and an open end date (the max date, `9999-12-31`).\nIf auto end-dating is enabled and a relationship changes which is already recorded in the effectivity satellite, then effectivity satellites in dbtvault will \nautomatically create a record as a copy of the old record. This record will be created with the effective date of the new relation. \n\nIf auto end-dating is not enabled, a new record with open end date will still be created, but additional business rules will need to be applied to work out the \nend dates manually. This may be useful when there is external business logic which describes under what situations a relationship is considered effective or not. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#eff_sat)"}, "dbtvault.macro__t_link": {"unique_id": "dbtvault.macro__t_link", "package_name": "dbtvault", "root_path": "E:\\Training\\DBT\\DBTTRAINING\\dbt_modules\\dbtvault", "path": "tables\\tables.md", "original_file_path": "docs\\tables\\tables.md", "name": "macro__t_link", "block_contents": "A transactional link is an immutable list of transaction records. By definition transactions are never modified:\nif a transaction needs to be updated, then a new transaction occurs. Transactional links contain a payload of columns which contain\ndetails about the transaction, usually consisting of payments, location, type and more. \n\n[Read more online](https://dbtvault.readthedocs.io/en/latest/macros/#t_link)"}}, "exposures": {}, "disabled": [], "generated_at": "2021-04-26T11:44:46.726175Z", "parent_map": {"model.dbttraining.product": ["model.dbttraining.stg_product"], "model.dbttraining.stg_product": ["source.dbttraining.product_schema.product_src"], "model.dbttraining.CTransformerStage": ["model.dbttraining.lkp_day_part"], "model.dbttraining.CTransformerStage_multiinput": ["model.dbttraining.lkp_busi_dt"], "model.dbttraining.DB_input": [], "model.dbttraining.PxCopy": ["model.dbttraining.lkp_day_part"], "model.dbttraining.PxDataset": [], "model.dbttraining.PxFilter": ["model.dbttraining.lkp_day_part"], "model.dbttraining.PxFunnel": ["model.dbttraining.lkp_day_part", "model.dbttraining.lkp_day_part"], "model.dbttraining.Pxjoin": ["model.dbttraining.lkp_busi_dt"], "model.dbttraining.PxLookup": ["model.dbttraining.lkp_trans_dt"], "model.dbttraining.PxLookup_multiple_lkp": ["model.dbttraining.lkp_busi_dt"], "model.dbttraining.PxModify": ["model.dbttraining.lkp_day_part"], "model.dbttraining.PxPivot": ["model.dbttraining.monthly_sales"], "model.dbttraining.PxPivot_1": ["model.dbttraining.monthly_sales"], "model.dbttraining.PxRemDup": ["model.dbttraining.i_tbc_hme_timer_detail"], "model.dbttraining.PxSequentialFile": [], "model.dbttraining.PxSort": [], "model.dbttraining.dup_remove_hme_timer_detail": ["model.dbttraining.xfm_hme"], "model.dbttraining.i_tbc_hme_timer_detail": ["model.dbttraining.dup_remove_hme_timer_detail"], "model.dbttraining.lkp_busi_dt": ["model.dbttraining.odbc_time_day_dim", "model.dbttraining.seq_hme_detail"], "model.dbttraining.lkp_day_part": ["model.dbttraining.lkp_trans_dt", "model.dbttraining.odbc_time_day_part"], "model.dbttraining.lkp_trans_dt": ["model.dbttraining.lkp_busi_dt", "model.dbttraining.odbc_time_day_dim"], "model.dbttraining.monthly_sales": [], "model.dbttraining.odbc_time_day_dim": [], "model.dbttraining.odbc_time_day_part": [], "model.dbttraining.odbc_time_minute_det": [], "model.dbttraining.PxFilter_copy": ["model.dbttraining.lkp_day_part"], "model.dbttraining.seq_hme_detail": [], "model.dbttraining.xfm_busi_dt": ["model.dbttraining.lkp_busi_dt"], "model.dbttraining.xfm_hme": ["model.dbttraining.lkp_day_part"], "model.dbttraining.xfm_hme_trans_stage": ["model.dbttraining.lkp_day_part"], "model.dbttraining.xfm_trans_dt": ["model.dbttraining.lkp_trans_dt"], "model.dbttraining.my_first_dbt_model": [], "model.dbttraining.my_second_dbt_model": ["model.dbttraining.my_first_dbt_model"], "model.dbttraining.cpout_second_DSLink13": ["model.dbttraining.Funnel_12_DSLink13"], "model.dbttraining.Funnel_12_DSLink13": ["model.dbttraining.Funnel_12_ln_out_tx_first", "model.dbttraining.Funnel_12_ln_out_tx_second"], "model.dbttraining.Funnel_12_ln_out_tx_first": ["model.dbttraining.tx_poc_ln_out_tx_first"], "model.dbttraining.Funnel_12_ln_out_tx_second": ["model.dbttraining.tx_poc_ln_out_tx_second"], "model.dbttraining.genrows_ln_in_tx": [], "model.dbttraining.jn_srcs_Lnk_pvt_seg": [], "model.dbttraining.jn_srcs_lnk_src_addr": [], "model.dbttraining.jn_srcs_Lnk_src_appl": [], "model.dbttraining.jn_srcs_Lnk_src_nas": [], "model.dbttraining.PxJoin_new": ["model.dbttraining.jn_srcs_lnk_src_addr"], "model.dbttraining.tx_poc_ln_in_tx": ["model.dbttraining.genrows_ln_in_tx"], "model.dbttraining.tx_poc_ln_out_tx_agg": ["model.dbttraining.tx_poc_ln_in_tx"], "model.dbttraining.tx_poc_ln_out_tx_first": ["model.dbttraining.tx_poc_ln_in_tx"], "model.dbttraining.tx_poc_ln_out_tx_second": ["model.dbttraining.tx_poc_ln_in_tx"], "model.dbttraining.xyz": ["model.dbttraining.tx_poc_ln_in_tx"], "model.dbttraining.xyz1": [], "snapshot.dbttraining.product_snapshot": ["model.dbttraining.stg_product"], "test.dbttraining.unique_my_first_dbt_model_id": ["model.dbttraining.my_first_dbt_model"], "test.dbttraining.not_null_my_first_dbt_model_id": ["model.dbttraining.my_first_dbt_model"], "test.dbttraining.unique_my_second_dbt_model_id": ["model.dbttraining.my_second_dbt_model"], "test.dbttraining.not_null_my_second_dbt_model_id": ["model.dbttraining.my_second_dbt_model"], "source.dbttraining.product_schema.product_src": [], "source.dbttraining.show_stopper.time_day_dim": [], "source.dbttraining.show_stopper.TIME_DAYPART_DET": [], "source.dbttraining.show_stopper.SRC_SEQ_HME_DETAIL": [], "source.dbttraining.show_stopper.monthly_emp_sales": [], "source.dbttraining.show_stopper.time_minute_dim": [], "source.dbttraining.tpch_sample.LINEITEM": [], "source.dbttraining.tpch_sample.CUSTOMER": [], "source.dbttraining.tpch_sample.ORDERS": [], "source.dbttraining.tpch_sample.PARTSUPP": [], "source.dbttraining.tpch_sample.SUPPLIER": [], "source.dbttraining.tpch_sample.PART": [], "source.dbttraining.tpch_sample.NATION": [], "source.dbttraining.tpch_sample.REGION": [], "source.dbttraining.USAA.time_day_dim": [], "source.dbttraining.USAA.TIME_DAYPART_DET": [], "source.dbttraining.USAA.SRC_SEQ_HME_DETAIL": [], "source.dbttraining.USAA.monthly_emp_sales": [], "source.dbttraining.USAA.genrows": [], "source.dbttraining.USAA.jn_srcs_lnk_src_addr": [], "source.dbttraining.USAA.jn_srcs_Lnk_pvt_seg": [], "source.dbttraining.USAA.jn_srcs_Lnk_src_nas": [], "source.dbttraining.USAA.jn_srcs_Lnk_src_appl": [], "source.dbttraining.snowflake_sample_data.store_sales": []}, "child_map": {"model.dbttraining.product": [], "model.dbttraining.stg_product": ["model.dbttraining.product", "snapshot.dbttraining.product_snapshot"], "model.dbttraining.CTransformerStage": [], "model.dbttraining.CTransformerStage_multiinput": [], "model.dbttraining.DB_input": [], "model.dbttraining.PxCopy": [], "model.dbttraining.PxDataset": [], "model.dbttraining.PxFilter": [], "model.dbttraining.PxFunnel": [], "model.dbttraining.Pxjoin": [], "model.dbttraining.PxLookup": [], "model.dbttraining.PxLookup_multiple_lkp": [], "model.dbttraining.PxModify": [], "model.dbttraining.PxPivot": [], "model.dbttraining.PxPivot_1": [], "model.dbttraining.PxRemDup": [], "model.dbttraining.PxSequentialFile": [], "model.dbttraining.PxSort": [], "model.dbttraining.dup_remove_hme_timer_detail": ["model.dbttraining.i_tbc_hme_timer_detail"], "model.dbttraining.i_tbc_hme_timer_detail": ["model.dbttraining.PxRemDup"], "model.dbttraining.lkp_busi_dt": ["model.dbttraining.CTransformerStage_multiinput", "model.dbttraining.PxLookup_multiple_lkp", "model.dbttraining.Pxjoin", "model.dbttraining.lkp_trans_dt", "model.dbttraining.xfm_busi_dt"], "model.dbttraining.lkp_day_part": ["model.dbttraining.CTransformerStage", "model.dbttraining.PxCopy", "model.dbttraining.PxFilter", "model.dbttraining.PxFilter_copy", "model.dbttraining.PxFunnel", "model.dbttraining.PxFunnel", "model.dbttraining.PxModify", "model.dbttraining.xfm_hme", "model.dbttraining.xfm_hme_trans_stage"], "model.dbttraining.lkp_trans_dt": ["model.dbttraining.PxLookup", "model.dbttraining.lkp_day_part", "model.dbttraining.xfm_trans_dt"], "model.dbttraining.monthly_sales": ["model.dbttraining.PxPivot", "model.dbttraining.PxPivot_1"], "model.dbttraining.odbc_time_day_dim": ["model.dbttraining.lkp_busi_dt", "model.dbttraining.lkp_trans_dt"], "model.dbttraining.odbc_time_day_part": ["model.dbttraining.lkp_day_part"], "model.dbttraining.odbc_time_minute_det": [], "model.dbttraining.PxFilter_copy": [], "model.dbttraining.seq_hme_detail": ["model.dbttraining.lkp_busi_dt"], "model.dbttraining.xfm_busi_dt": [], "model.dbttraining.xfm_hme": ["model.dbttraining.dup_remove_hme_timer_detail"], "model.dbttraining.xfm_hme_trans_stage": [], "model.dbttraining.xfm_trans_dt": [], "model.dbttraining.my_first_dbt_model": ["model.dbttraining.my_second_dbt_model", "test.dbttraining.not_null_my_first_dbt_model_id", "test.dbttraining.unique_my_first_dbt_model_id"], "model.dbttraining.my_second_dbt_model": ["test.dbttraining.not_null_my_second_dbt_model_id", "test.dbttraining.unique_my_second_dbt_model_id"], "model.dbttraining.cpout_second_DSLink13": [], "model.dbttraining.Funnel_12_DSLink13": ["model.dbttraining.cpout_second_DSLink13"], "model.dbttraining.Funnel_12_ln_out_tx_first": ["model.dbttraining.Funnel_12_DSLink13"], "model.dbttraining.Funnel_12_ln_out_tx_second": ["model.dbttraining.Funnel_12_DSLink13"], "model.dbttraining.genrows_ln_in_tx": ["model.dbttraining.tx_poc_ln_in_tx"], "model.dbttraining.jn_srcs_Lnk_pvt_seg": [], "model.dbttraining.jn_srcs_lnk_src_addr": ["model.dbttraining.PxJoin_new"], "model.dbttraining.jn_srcs_Lnk_src_appl": [], "model.dbttraining.jn_srcs_Lnk_src_nas": [], "model.dbttraining.PxJoin_new": [], "model.dbttraining.tx_poc_ln_in_tx": ["model.dbttraining.tx_poc_ln_out_tx_agg", "model.dbttraining.tx_poc_ln_out_tx_first", "model.dbttraining.tx_poc_ln_out_tx_second", "model.dbttraining.xyz"], "model.dbttraining.tx_poc_ln_out_tx_agg": [], "model.dbttraining.tx_poc_ln_out_tx_first": ["model.dbttraining.Funnel_12_ln_out_tx_first"], "model.dbttraining.tx_poc_ln_out_tx_second": ["model.dbttraining.Funnel_12_ln_out_tx_second"], "model.dbttraining.xyz": [], "model.dbttraining.xyz1": [], "snapshot.dbttraining.product_snapshot": [], "test.dbttraining.unique_my_first_dbt_model_id": [], "test.dbttraining.not_null_my_first_dbt_model_id": [], "test.dbttraining.unique_my_second_dbt_model_id": [], "test.dbttraining.not_null_my_second_dbt_model_id": [], "source.dbttraining.product_schema.product_src": ["model.dbttraining.stg_product"], "source.dbttraining.show_stopper.time_day_dim": [], "source.dbttraining.show_stopper.TIME_DAYPART_DET": [], "source.dbttraining.show_stopper.SRC_SEQ_HME_DETAIL": [], "source.dbttraining.show_stopper.monthly_emp_sales": [], "source.dbttraining.show_stopper.time_minute_dim": [], "source.dbttraining.tpch_sample.LINEITEM": [], "source.dbttraining.tpch_sample.CUSTOMER": [], "source.dbttraining.tpch_sample.ORDERS": [], "source.dbttraining.tpch_sample.PARTSUPP": [], "source.dbttraining.tpch_sample.SUPPLIER": [], "source.dbttraining.tpch_sample.PART": [], "source.dbttraining.tpch_sample.NATION": [], "source.dbttraining.tpch_sample.REGION": [], "source.dbttraining.USAA.time_day_dim": [], "source.dbttraining.USAA.TIME_DAYPART_DET": [], "source.dbttraining.USAA.SRC_SEQ_HME_DETAIL": [], "source.dbttraining.USAA.monthly_emp_sales": [], "source.dbttraining.USAA.genrows": [], "source.dbttraining.USAA.jn_srcs_lnk_src_addr": [], "source.dbttraining.USAA.jn_srcs_Lnk_pvt_seg": [], "source.dbttraining.USAA.jn_srcs_Lnk_src_nas": [], "source.dbttraining.USAA.jn_srcs_Lnk_src_appl": [], "source.dbttraining.snowflake_sample_data.store_sales": []}, "metadata": {"project_id": "47c85f341457a64e615b0ecf60cecb8a", "user_id": "79bf563c-5fa7-4240-8097-7482e0b848bc", "send_anonymous_usage_stats": true, "adapter_type": "snowflake"}}